{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import just_plot\n",
    "from misc import *\n",
    "from nets import *\n",
    "from buffer import ReplayBuffer\n",
    "import timeit\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib\n",
    "from environment import Environment\n",
    "\n",
    "\n",
    "amplitude=0.4\n",
    "dolinar_layers=2\n",
    "number_phases=2\n",
    "total_episodes = 10**3\n",
    "buffer_size=500\n",
    "batch_size=64\n",
    "ep_guess=0.01\n",
    "noise_displacement=0.5\n",
    "lr_actor=0.01\n",
    "lr_critic=0.001\n",
    "tau=0.005\n",
    "\n",
    "\n",
    "exper = np.load(\"example_buffer/2_sample.npy\")\n",
    "env = Environment(amplitude=amplitude, dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "# buffer = ReplayBuffer(buffer_size=buffer_size)\n",
    "\n",
    "critic = Critic(nature=\"primary\",valreg=0.01, dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "critic_target = Critic(nature=\"target\", dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "actor = Actor(nature=\"primary\", dolinar_layers = dolinar_layers)\n",
    "actor_target = Actor(nature=\"target\", dolinar_layers = dolinar_layers)\n",
    "\n",
    "optimizer_critic = tf.keras.optimizers.Adam(lr=lr_critic)\n",
    "optimizer_actor = tf.keras.optimizers.Adam(lr=lr_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = exper.astype(np.float32)\n",
    "targeted_experience = actor_target.process_sequence_of_experiences_tf(experiences)\n",
    "sequences, zeroed_rews = critic_target.process_sequence_tf(targeted_experience)\n",
    "labels_critic = critic_target.give_td_errors_tf( sequences, zeroed_rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def critic_grad_tf(critic, experiences):\n",
    "    with tf.GradientTape() as tape:\n",
    "        unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "        to_stack = []\n",
    "        actions_wathed_index = []\n",
    "        for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "            actions_wathed_index.append(index)\n",
    "            to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        actions_indexed = tf.concat(to_stack,axis=1)\n",
    "        tape.watch(actions_indexed)\n",
    "\n",
    "\n",
    "        index_actions=0\n",
    "        watched_exps=[tf.ones((experiences.shape[0],1,1))*actor.pad_value]\n",
    "        watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "        for index in range(0,experiences.shape[-1]-1): \n",
    "            if index in actions_wathed_index:\n",
    "                watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "                index_actions+=1\n",
    "            else:\n",
    "                \n",
    "                watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))\n",
    "\n",
    "        dq_da = tape.gradient(qvals, actions_indexed)\n",
    "    return dq_da\n",
    "dq_da = critic_grad_tf(critic, experiences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1), dtype=float32, numpy=array([[[0.08953033]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_outcome_actor = np.reshape(np.array([actor.pad_value]),(1,1,1)).astype(np.float32)\n",
    "actor(context_outcome_actor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def actor_grad_tf(actor, dq_da, experiences, optimizer_actor):\n",
    "    unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "    actions_per_episode={}\n",
    "    context_outcome_actor = np.reshape(np.array([actor.pad_value]),(1,1,1)).astype(np.float32)\n",
    "    finns = [tf.multiply(actor(context_outcome_actor).numpy(), tf.ones((experiences.shape[0],1,1)))]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(actor.trainable_variables)\n",
    "        for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "            actions_per_episode[str(index)] = []\n",
    "            for k in tf.unstack(unstacked_exp[index]):\n",
    "                actions_per_episode[str(index)].append(actor(tf.reshape(k, (1,1,1))))\n",
    "            finns.append(tf.concat(actions_per_episode[str(index)], axis=0))\n",
    "        final_preds = tf.concat(finns, axis=1)\n",
    "        da_dtheta=tape.gradient(final_preds, actor.trainable_variables, output_gradients=-dq_da)\n",
    "        optimizer_actor.apply_gradients(zip(da_dtheta, actor.trainable_variables))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 ms ± 5.22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit actor_grad_tf(actor, dq_da, experiences, optimizer_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15, 1, 1), dtype=float32, numpy=\n",
       "array([[[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]],\n",
       "\n",
       "       [[-1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(actor(context_outcome_actor), tf.ones((experiences.shape[0],1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def actor_grad_tf(actor, dq_da, experiences, optimizer_actor):\n",
    "    unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "    actions_per_episode={}\n",
    "    context_outcome_actor = np.reshape(np.array([actor.pad_value]),(1,1,1)).astype(np.float32)\n",
    "    finns = [tf.multiply(actor(context_outcome_actor), tf.ones((experiences.shape[0],1,1)))]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(actor.trainable_variables)\n",
    "        for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "            actions_per_episode[str(index)] = []\n",
    "            for k in tf.unstack(unstacked_exp[index]):\n",
    "                actions_per_episode[str(index)].append(actor(tf.reshape(k, (1,1,1))))\n",
    "            finns.append(tf.concat(actions_per_episode[str(index)], axis=0))\n",
    "        final_preds = tf.concat(finns, axis=1)\n",
    "        da_dtheta=tape.gradient(final_preds, actor.trainable_variables, output_gradients=-dq_da)\n",
    "        optimizer_actor.apply_gradients(zip(da_dtheta, actor.trainable_variables))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 ms ± 1.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit actor_grad_tf(actor, dq_da, experiences, optimizer_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
