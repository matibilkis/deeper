{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib\n",
    "from environment import Environment\n",
    "from plots import just_plot\n",
    "from misc import *\n",
    "from nets import *\n",
    "from buffer import ReplayBuffer\n",
    "\n",
    "\n",
    "amplitude=0.4\n",
    "tau = 0.1\n",
    "lr_critic = 0.005\n",
    "lr_actor=10**-3\n",
    "noise_displacement = .25\n",
    "ep_guess=0.01\n",
    "dolinar_layers=1\n",
    "number_phases=2\n",
    "buffer_size = 10**7\n",
    "\n",
    "\n",
    "env = Environment(amplitude=amplitude, dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "buffer = ReplayBuffer(buffer_size=buffer_size)\n",
    "\n",
    "critic = Critic(nature=\"primary\",valreg=0.0, dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "critic_target = Critic(nature=\"target\", valreg=0.0,dolinar_layers = dolinar_layers, number_phases=number_phases, tau = tau)\n",
    "actor = Actor(nature=\"primary\",valreg=0.0, dolinar_layers = dolinar_layers)\n",
    "actor_target = Actor(nature=\"target\",valreg=0.0, dolinar_layers = dolinar_layers)\n",
    "\n",
    "optimizer_critic = tf.keras.optimizers.Adam(lr=lr_critic)\n",
    "optimizer_actor = tf.keras.optimizers.SGD(lr=lr_actor)\n",
    "\n",
    "policy_evaluator = PolicyEvaluator(amplitude = amplitude, dolinar_layers=dolinar_layers, number_phases = number_phases)\n",
    "\n",
    "expes = np.load(\"buffers/1L-stoch.npy\")\n",
    "\n",
    "for k in tqdm(expes):\n",
    "    buffer.add(tuple(k))\n",
    "    \n",
    "    \n",
    "def plot(critic, episode = 1, last_episode=False, max_episode=10**4, history_betas =[]):\n",
    "\n",
    "    betas = np.arange(.1,1.1,.05)\n",
    "    inps = np.stack([np.ones(len(betas))*critic.pad_value, betas], axis=1)\n",
    "    inps = np.reshape(inps, (len(betas),1,2))\n",
    "    ax3.plot(betas, np.squeeze(critic(inps)), alpha=min(episode/max_episode,1), linewidth=5,label=\"RNN - \"+str(episode))\n",
    "\n",
    "    for outcome in [0.,1.]:\n",
    "       for guess_index in [0.,1.]:\n",
    "            m=[]\n",
    "            for k in tf.unstack(inps):\n",
    "                m.append(tf.concat([k, np.reshape(np.array([outcome,guess_index]), (1,2))], axis=0))\n",
    "            axes[str(outcome)].plot(betas, np.squeeze(critic(tf.stack(m, axis=0)))[:,1], alpha=min(episode/max_episode,1), linewidth=5,label=\"RNN\" +str(episode))\n",
    "            \n",
    "            \n",
    "    if last_episode:\n",
    "        betas = np.arange(.1,1.1,.05)\n",
    "        inps = np.stack([np.ones(len(betas))*critic.pad_value, betas], axis=1)\n",
    "        inps = np.reshape(inps, (len(betas),1,2))\n",
    "        ax3.plot(betas, np.squeeze(critic(inps)), linewidth=8,c=\"black\",label=\"RNN\")\n",
    "\n",
    "\n",
    "        for outcome in [0.,1.]:\n",
    "           for guess_index in [0.,1.]:\n",
    "                m=[]\n",
    "                for k in tf.unstack(inps):\n",
    "                    m.append(tf.concat([k, np.reshape(np.array([outcome,guess_index]), (1,2))], axis=0))\n",
    "                axes[str(outcome)].plot(betas, np.squeeze(critic(tf.stack(m, axis=0)))[:,1],c=\"black\", linewidth=8,label=\"RNN\")\n",
    "\n",
    "\n",
    "        ax1.plot(betas,[qval(b, 0, -1) for b in betas],c=\"red\", linewidth=5, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax1.plot(betas,[qval(b, 0, 1) for b in betas],c=\"blue\",  linewidth=5,label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "        ax2.plot(betas,[qval(b, 1, -1) for b in betas],c=\"red\", linewidth=5, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax2.plot(betas,[qval(b, 1, 1) for b in betas],c=\"blue\",  linewidth=5,label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "        ax3.plot(betas,ps_maxlik(betas), '--', linewidth=5, color=\"red\", label=\"P*\")\n",
    "        ax4.plot(np.arange(1,len(history_betas)+1), history_betas, alpha=0.75, c=\"red\", linewidth=7)\n",
    "        for ax in [ax1, ax2, ax3]:\n",
    "            ax.set_xlabel(r'$\\beta$', size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32.\n",
    "\n",
    "experiences = buffer.sample(batch_size).astype(np.float32)\n",
    "dq_da = critic_grad_tf(critic, experiences)\n",
    "context_outcome_actor = np.reshape(np.array([actor.pad_value]),(1,1,1)).astype(np.float32)\n",
    "actor.reset_states_workaround(new_batch_size=int(batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def monster_gradient(actor, dq_da, experiences, optimizer_actor):\n",
    "    actor.lstm.stateful=False\n",
    "    actor.reset_states_workaround(new_batch_size=experiences.shape[0])\n",
    "    finns = [tf.ones((experiences.shape[0], 1,1))*actor.pad_value]\n",
    "    unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "    for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "        finns.append(tf.reshape(unstacked_exp[index], (experiences.shape[0], 1,1)))\n",
    "    final_preds = tf.concat(finns, axis=1)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(actor.trainable_variables)\n",
    "        final_predss = actor(final_preds)\n",
    "            \n",
    "    da_dtheta1 = tape.jacobian(final_predss, actor.trainable_variables)\n",
    "\n",
    "    variables = actor.trainable_variables\n",
    "    grad_j=[]\n",
    "    for k in range(len(da_dtheta1)):\n",
    "        onnns = tf.ones(len(tf.shape(da_dtheta1[k]))-1)\n",
    "        multip = tf.reshape(dq_da,tf.cast(tf.concat([tf.Variable([batch_size]),onnns], axis=0), np.int32))*da_dtheta1[k]\n",
    "        multip = tf.reshape(tf.math.reduce_mean(multip, axis=0), variables[k].shape)\n",
    "        grad_j.append(multip)\n",
    "    #optimizer_actor.apply_gradients(zip(grad_j, actor.trainable_variables))\n",
    "    return grad_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def monster_gradient0(actor, dq_da, experiences, optimizer_actor):\n",
    "    actor.lstm.stateful=False\n",
    "    actor.reset_states_workaround(new_batch_size=experiences.shape[0])\n",
    "    finns = [tf.ones((experiences.shape[0], 1,1))*actor.pad_value]\n",
    "    unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "    for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "        finns.append(tf.reshape(unstacked_exp[index], (experiences.shape[0], 1,1)))\n",
    "    final_preds = tf.concat(finns, axis=1)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(actor.trainable_variables)\n",
    "        final_predss = actor(final_preds)\n",
    "            \n",
    "    da_dtheta1 = tape.gradient(final_predss, actor.trainable_variables, output_gradients=-dq_da)\n",
    "    return da_dtheta1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.lstm.stateful=False\n",
    "actor.reset_states_workaround(new_batch_size=experiences.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p1 = monster_gradient(actor, dq_da, experiences, optimizer_actor)\n",
    "p2 = monster_gradient0(actor, dq_da, experiences, optimizer_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1000), dtype=float32, numpy=\n",
       " array([[ 5.67119463e-10, -8.85343410e-10, -2.05919115e-10,\n",
       "          3.42286754e-10,  5.44583378e-10, -3.10943077e-11,\n",
       "         -2.75303547e-11,  1.09889298e-09,  3.14531456e-10,\n",
       "         -2.67724514e-12, -4.50114807e-10, -9.67857905e-10,\n",
       "         -5.25133973e-12,  4.52457988e-10, -1.48777532e-10,\n",
       "         -1.95119199e-10,  1.10279585e-09, -7.78936970e-10,\n",
       "         -7.75363662e-11,  5.95646699e-10,  3.07072062e-10,\n",
       "         -2.98392283e-10,  5.07517695e-10, -2.94453420e-11,\n",
       "         -4.27998713e-11, -1.16005427e-09,  1.65353176e-10,\n",
       "          4.90927611e-11,  1.71218109e-10, -8.80522599e-11,\n",
       "         -8.72051931e-10, -2.72250861e-10,  4.00835226e-10,\n",
       "         -5.68753988e-10,  6.95558611e-10,  3.53939267e-10,\n",
       "          5.15326781e-10,  2.22251245e-10, -1.03235212e-10,\n",
       "          8.97226071e-10, -4.21958163e-11, -5.63887215e-10,\n",
       "          6.11491080e-10, -1.16133314e-09,  1.42135522e-11,\n",
       "         -3.94663385e-10,  3.48425705e-10,  1.89342347e-10,\n",
       "         -5.67638769e-10,  6.84183876e-10,  4.31954472e-10,\n",
       "          4.96354347e-11,  1.65257558e-10,  4.74584538e-10,\n",
       "          2.66857370e-10,  5.99500838e-10, -1.57182080e-11,\n",
       "         -6.90856927e-10, -3.78904158e-10, -8.28423580e-11,\n",
       "          4.28500652e-10, -4.36891745e-10, -5.47964507e-10,\n",
       "          3.74203724e-10, -9.17330448e-12, -1.23948896e-09,\n",
       "          1.67332384e-10,  7.17266579e-10, -3.11988080e-09,\n",
       "          4.56899185e-10,  6.74095849e-11, -1.03590980e-09,\n",
       "         -2.94693908e-10,  6.38791658e-11,  2.71592748e-10,\n",
       "          5.43682876e-10,  2.09841478e-10, -4.68738881e-10,\n",
       "          3.09900688e-10, -8.85439916e-11, -9.39101366e-11,\n",
       "          1.02712983e-09,  1.30157829e-11,  1.32353489e-10,\n",
       "         -1.54452562e-09,  5.49352543e-11, -7.99516120e-10,\n",
       "         -2.07020803e-10,  4.62394872e-10,  5.27136779e-10,\n",
       "          1.73724590e-10, -2.73475687e-10,  2.57596652e-11,\n",
       "         -8.09663794e-11,  1.92322842e-11, -2.70048733e-10,\n",
       "         -7.46693984e-10,  3.69744062e-11, -1.59616209e-10,\n",
       "          6.62187027e-10,  8.03479894e-10, -3.28608862e-10,\n",
       "         -5.77089043e-10,  2.20423096e-10,  6.00139643e-12,\n",
       "          1.16871707e-10,  5.68250114e-10,  8.17399759e-10,\n",
       "          9.52502521e-10,  7.98299649e-10,  3.75194181e-10,\n",
       "         -2.09418403e-11, -5.98795388e-11, -5.10199105e-10,\n",
       "         -6.59266364e-10,  9.61831392e-10,  3.50317345e-11,\n",
       "          6.66791761e-11, -7.54322507e-11, -6.30591634e-10,\n",
       "         -6.21355398e-11,  6.73954115e-10, -1.13235697e-11,\n",
       "         -1.98723121e-10,  2.36256376e-10,  2.91265345e-11,\n",
       "         -4.65508521e-10, -5.44463988e-11,  3.72467335e-11,\n",
       "         -6.03263967e-11, -1.36056999e-10,  1.15460663e-09,\n",
       "          4.05540906e-10, -3.08675363e-10, -1.69517816e-10,\n",
       "          2.06935857e-10, -5.74190417e-10, -3.62598146e-10,\n",
       "          9.34032407e-10,  2.58571803e-10,  7.24290905e-11,\n",
       "          5.62327573e-10,  1.05578957e-09,  8.79998241e-10,\n",
       "         -6.93829549e-10, -3.20649098e-11, -8.61437796e-11,\n",
       "         -4.97735908e-10, -2.31510255e-10,  2.84665874e-10,\n",
       "          1.08144294e-09,  3.53585550e-10, -1.72104719e-09,\n",
       "         -4.35749270e-10, -5.99754246e-10, -6.95736524e-11,\n",
       "          1.36467129e-10, -3.76936642e-11, -7.29946936e-11,\n",
       "          5.83609827e-10, -2.06152553e-10,  4.10585212e-11,\n",
       "          7.35662364e-10,  7.16841378e-11, -7.53764134e-11,\n",
       "          1.45944618e-10,  4.87770602e-10, -5.06254261e-10,\n",
       "         -1.57606497e-10,  9.72700219e-12, -1.66301795e-09,\n",
       "          2.29367957e-13, -2.38239539e-10,  9.55171497e-10,\n",
       "         -5.71916126e-10,  9.96726226e-12, -1.34639022e-10,\n",
       "         -1.47802146e-10,  1.46119350e-09, -8.75712947e-10,\n",
       "         -3.17151694e-10,  1.44414536e-10, -1.13268328e-09,\n",
       "         -1.96489949e-10,  1.11759026e-10, -1.56208588e-10,\n",
       "          1.76926238e-10,  5.96874355e-11,  1.88909471e-10,\n",
       "         -3.05855841e-10,  2.04332912e-10,  2.66282163e-10,\n",
       "         -2.95527075e-10, -5.02373587e-10,  1.61826344e-10,\n",
       "         -1.02204363e-10, -7.13563514e-11,  3.53551799e-10,\n",
       "          9.99654942e-11,  1.87956636e-10,  2.84706148e-10,\n",
       "         -2.54652549e-10,  7.23152094e-10,  3.46330298e-10,\n",
       "          4.86869045e-10, -2.08147544e-09, -1.52360430e-10,\n",
       "          1.52405241e-10, -7.44414141e-10, -3.29196642e-10,\n",
       "          5.79427695e-12, -1.34501876e-09,  5.09513487e-10,\n",
       "         -2.58304836e-11, -7.52384766e-10, -2.36515030e-10,\n",
       "         -3.59433122e-10,  4.27657271e-10, -2.65765604e-10,\n",
       "         -8.34615654e-10,  5.72008885e-10,  9.97115758e-12,\n",
       "          1.47474116e-10,  2.70726289e-11, -3.71708775e-10,\n",
       "          4.48097948e-10,  6.31130037e-10, -1.62724237e-10,\n",
       "          1.46737400e-10,  3.19141547e-10, -2.78143980e-10,\n",
       "          2.63486066e-10,  7.44388995e-10,  4.93176888e-11,\n",
       "         -9.82593340e-10,  6.12341178e-10,  3.37938739e-11,\n",
       "          3.11244863e-10,  1.57810737e-10, -1.44303189e-11,\n",
       "         -1.60680003e-09, -5.08867060e-10, -3.37465229e-11,\n",
       "          7.23505067e-12,  1.22698018e-10, -1.43094162e-10,\n",
       "         -5.23488919e-10,  2.83972429e-10,  9.90518015e-11,\n",
       "          2.74808453e-12,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00, -1.53840451e-09,\n",
       "          4.24761915e-09,  6.76858958e-10,  3.70468078e-09,\n",
       "          6.13396667e-09, -5.54867541e-10,  4.66224170e-10,\n",
       "         -3.67804853e-09, -5.19785415e-09,  9.65860836e-10,\n",
       "          5.94111871e-09, -5.80747139e-09,  7.66523581e-11,\n",
       "         -2.75705547e-09, -3.05469983e-09, -2.59570099e-09,\n",
       "         -5.77476733e-09, -2.25453234e-09,  2.37898456e-09,\n",
       "          2.61759103e-09, -3.94273147e-09, -1.21827581e-09,\n",
       "         -6.18050366e-09,  1.75477377e-09, -1.03433639e-09,\n",
       "         -7.84968535e-09,  4.27347890e-09, -1.03732090e-09,\n",
       "         -5.25613197e-09, -2.10382245e-09,  2.82496937e-09,\n",
       "          1.33952649e-09, -3.16295701e-09, -2.77826873e-09,\n",
       "          2.26913577e-09, -2.09704432e-09,  1.55038893e-09,\n",
       "          3.16969007e-09,  7.95341681e-10,  3.33684524e-09,\n",
       "          1.38557013e-10, -7.09840409e-09,  6.81757806e-09,\n",
       "         -6.01189543e-09, -2.68550931e-10,  2.69096856e-09,\n",
       "         -3.97101285e-09,  8.00692179e-10,  4.03912326e-09,\n",
       "          5.09123899e-09,  4.47008031e-09, -3.05919845e-10,\n",
       "          3.12447890e-09,  6.73692568e-09,  5.72745051e-09,\n",
       "         -3.18538329e-09,  2.69582801e-10, -3.38726913e-09,\n",
       "          1.67819947e-09, -6.97523206e-10,  4.44645121e-09,\n",
       "          1.89191707e-09,  1.52731650e-09,  1.60233360e-09,\n",
       "          4.88904472e-11, -9.62692592e-09,  7.40447537e-10,\n",
       "          3.16042570e-09,  1.23067405e-08,  3.77551501e-09,\n",
       "          3.32088956e-09, -4.59159688e-09,  3.16251270e-09,\n",
       "          3.89066335e-10,  1.10416021e-09,  3.70252695e-09,\n",
       "         -9.32407818e-10,  1.99109507e-09,  5.71234215e-09,\n",
       "          2.76662721e-10,  5.69086445e-10,  8.71043149e-09,\n",
       "          1.23088470e-10, -6.17577045e-10,  4.51394477e-09,\n",
       "          7.44922790e-09, -6.76218104e-09, -2.07518114e-09,\n",
       "          1.83709981e-09,  5.32087041e-09,  3.02177194e-09,\n",
       "         -1.35041323e-09,  9.71976388e-10,  4.34705694e-09,\n",
       "         -1.83354154e-09, -6.67600775e-09, -2.41004683e-09,\n",
       "         -2.92779218e-10, -3.19256577e-09,  3.63191188e-09,\n",
       "         -3.03656544e-09, -2.31068165e-09, -3.67223651e-09,\n",
       "          1.47843982e-09,  8.64523009e-10,  1.40481105e-09,\n",
       "          4.97127139e-09, -5.04708675e-09, -3.90879373e-09,\n",
       "          2.28565278e-09,  1.32687072e-09,  2.63827044e-10,\n",
       "          3.36846040e-09,  3.63520702e-09, -2.93687541e-09,\n",
       "         -4.64310324e-09, -8.95710006e-10,  3.36640937e-10,\n",
       "         -8.72189654e-10, -2.04167061e-09, -5.16765430e-09,\n",
       "          1.97751393e-09,  1.15580892e-10,  3.92517263e-09,\n",
       "         -1.50767820e-09, -1.07165765e-09,  1.67609182e-09,\n",
       "          1.67788428e-09, -1.92183075e-10, -3.18038179e-10,\n",
       "         -3.70590358e-09, -8.09837619e-09,  3.15078674e-09,\n",
       "         -1.51478741e-09,  9.30181987e-10,  1.97986849e-09,\n",
       "          2.54599186e-09,  1.07096265e-09,  3.29925043e-09,\n",
       "          1.65437397e-09,  5.93031935e-09,  4.16307433e-09,\n",
       "         -4.16809165e-09,  5.67370684e-09, -4.06672074e-09,\n",
       "          3.67191111e-10,  1.30469568e-09,  2.63993893e-09,\n",
       "          1.03549569e-09,  1.58809044e-09, -4.11227452e-09,\n",
       "          5.29153033e-09, -6.49065157e-09,  2.54846011e-09,\n",
       "          2.85425417e-09,  5.09243370e-10, -9.55525614e-09,\n",
       "         -1.63321556e-09,  2.00006323e-09,  3.99810229e-09,\n",
       "         -1.70746339e-09,  1.85559179e-10,  6.45975851e-09,\n",
       "         -9.10457654e-10,  4.61103156e-10, -1.81954884e-09,\n",
       "          1.15630545e-08, -4.43146808e-09,  9.32643296e-10,\n",
       "          3.28551492e-11,  6.69836320e-09,  1.42766864e-12,\n",
       "         -1.74753356e-09,  4.59009408e-09, -2.21256524e-09,\n",
       "          2.17597260e-10,  1.80050808e-09, -3.84638277e-09,\n",
       "          6.66056410e-09,  3.23290683e-09, -1.86181981e-09,\n",
       "          1.19837340e-09,  6.47683818e-09, -3.30159655e-09,\n",
       "         -2.45579135e-09,  8.46988535e-10,  4.11416190e-09,\n",
       "         -8.94019303e-10, -1.70827874e-09, -6.38047482e-09,\n",
       "         -1.62642955e-09,  3.69620867e-09, -6.68632438e-09,\n",
       "         -6.82377044e-09,  7.46792128e-10, -6.68694988e-10,\n",
       "          2.62373900e-10,  9.43361478e-09,  8.46732795e-10,\n",
       "         -1.75985737e-09,  4.56107863e-09, -7.39242534e-09,\n",
       "         -2.77518231e-09,  2.82087753e-09, -2.01285655e-09,\n",
       "         -1.02763575e-08, -6.34962638e-10, -2.50215471e-09,\n",
       "          6.00555827e-09, -1.92623628e-09, -4.60732286e-11,\n",
       "         -7.77373721e-09, -2.86652324e-09, -3.94760225e-10,\n",
       "         -5.63788127e-09,  2.30647212e-09, -4.43368320e-09,\n",
       "          1.57950353e-09,  9.31169419e-10,  3.35000983e-09,\n",
       "         -1.50004986e-09, -6.04926242e-09, -5.59064928e-09,\n",
       "          2.96507641e-09, -1.67835390e-09, -1.87473947e-09,\n",
       "         -5.98858607e-09, -1.44151113e-09,  5.76819215e-09,\n",
       "         -1.72026149e-09,  1.13288601e-09, -9.35970745e-10,\n",
       "          1.04888889e-08, -2.50251864e-09,  3.55220275e-09,\n",
       "         -2.09927653e-09, -4.25715074e-10, -6.20115470e-09,\n",
       "         -2.20101892e-09, -8.36994016e-11, -6.95465685e-09,\n",
       "         -1.99307970e-09, -2.03490336e-09, -5.34834677e-11,\n",
       "         -2.64730993e-09,  6.75404233e-10, -3.67276587e-09,\n",
       "          5.34105205e-09, -2.81736662e-10,  8.75385875e-10,\n",
       "          4.97470676e-10, -8.99833208e-10, -2.76642431e-10,\n",
       "          3.09672399e-10,  6.63863686e-10, -2.25644572e-11,\n",
       "         -1.83869846e-11,  7.59672325e-10,  3.80586063e-10,\n",
       "         -1.95971754e-12, -5.75151149e-10, -1.02727471e-09,\n",
       "         -5.00900666e-12,  4.70246952e-10, -1.33216965e-10,\n",
       "         -2.18842042e-10,  1.06300357e-09, -8.27473368e-10,\n",
       "         -8.15116655e-11,  5.06844344e-10,  3.07494752e-10,\n",
       "         -3.10811044e-10,  5.12031972e-10, -3.59347170e-11,\n",
       "         -4.08214122e-11, -1.04074638e-09,  2.44594095e-10,\n",
       "          3.71629220e-11,  1.36039180e-10, -5.84489124e-11,\n",
       "         -1.06036036e-09, -3.48769985e-10,  4.01578992e-10,\n",
       "         -3.99346500e-10,  5.61855729e-10,  2.96911717e-10,\n",
       "          4.91699736e-10,  1.99078407e-10, -6.91722235e-11,\n",
       "          8.41701653e-10, -4.01735277e-11, -5.60252678e-10,\n",
       "          9.15069687e-10, -1.41201062e-09,  2.32045251e-11,\n",
       "         -3.27927213e-10,  5.01754860e-10,  2.22306673e-10,\n",
       "         -4.52256399e-10,  7.59868668e-10,  4.94631502e-10,\n",
       "          3.88448579e-11,  1.74735948e-10,  4.62451272e-10,\n",
       "          4.28012736e-10,  5.47721590e-10, -1.53731194e-11,\n",
       "         -8.75572337e-10, -3.05295234e-10, -9.36559996e-11,\n",
       "          3.59263702e-10, -4.84977614e-10, -5.87380478e-10,\n",
       "          3.75998510e-10, -1.02720939e-11, -1.16645404e-09,\n",
       "          1.60197883e-10,  7.96258504e-10, -2.90016855e-09,\n",
       "          6.04611972e-10,  7.64016211e-11, -9.69429759e-10,\n",
       "         -2.81339757e-10,  7.06430886e-11,  2.32702566e-10,\n",
       "          5.14302934e-10,  1.86800561e-10, -4.47953202e-10,\n",
       "          3.23708504e-10, -6.81219317e-11, -1.08297281e-10,\n",
       "          1.55131930e-09,  1.49894142e-11,  1.40617226e-10,\n",
       "         -1.51583401e-09,  6.77853329e-11, -5.87495275e-10,\n",
       "         -2.57899424e-10,  4.37338804e-10,  4.69434325e-10,\n",
       "          1.68368999e-10, -2.43094517e-10,  2.59406212e-11,\n",
       "         -1.28138514e-10,  2.89392087e-11, -2.47562471e-10,\n",
       "         -7.93970500e-10,  4.79863024e-11, -1.41091361e-10,\n",
       "          9.49901935e-10,  1.15533982e-09, -2.28018979e-10,\n",
       "         -8.47757198e-10,  1.60412891e-10,  4.52095609e-12,\n",
       "          1.06255109e-10,  7.65881303e-10,  9.01103359e-10,\n",
       "          1.37679124e-09,  7.31369854e-10,  3.35533573e-10,\n",
       "         -3.36640472e-11, -6.21961579e-11, -4.37339442e-10,\n",
       "         -8.23172475e-10,  6.69385269e-10,  4.09045055e-11,\n",
       "          7.10242976e-11, -8.72770883e-11, -8.05441602e-10,\n",
       "         -6.21829532e-11,  6.39804876e-10, -9.76221621e-12,\n",
       "         -1.52071356e-10,  1.71000492e-10,  4.05248717e-11,\n",
       "         -3.76829790e-10, -6.00531222e-11,  3.15147422e-11,\n",
       "         -5.93363900e-11, -1.47371698e-10,  1.25122424e-09,\n",
       "          3.71850745e-10, -2.34161857e-10, -1.66868547e-10,\n",
       "          2.33482983e-10, -8.02705014e-10, -3.08736980e-10,\n",
       "          9.49508916e-10,  2.36412501e-10,  6.11313708e-11,\n",
       "          6.49197696e-10,  1.23596622e-09,  9.38823241e-10,\n",
       "         -7.47691464e-10, -3.95789235e-11, -8.20329013e-11,\n",
       "         -3.90286026e-10, -1.98498024e-10,  3.33160194e-10,\n",
       "          1.56223190e-09,  3.63158392e-10, -1.36935951e-09,\n",
       "         -4.43610371e-10, -9.64692548e-10, -4.66559708e-11,\n",
       "          9.60918914e-11, -6.44423612e-11, -6.03937664e-11,\n",
       "          5.96971417e-10, -1.36793021e-10,  2.97264088e-11,\n",
       "          5.58683322e-10,  7.96985256e-11, -5.70805382e-11,\n",
       "          1.24735999e-10,  3.85568161e-10, -6.09256090e-10,\n",
       "         -1.83292728e-10,  1.11824924e-11, -1.47862600e-09,\n",
       "          2.81918260e-13, -3.05653780e-10,  7.72166109e-10,\n",
       "         -3.38427453e-10,  1.03624661e-11, -1.54758456e-10,\n",
       "         -1.32405142e-10,  1.41877610e-09, -7.94289301e-10,\n",
       "         -3.39586637e-10,  1.29546956e-10, -8.80953310e-10,\n",
       "         -2.29592068e-10,  1.13394918e-10, -1.51446758e-10,\n",
       "          2.30397937e-10,  6.28212690e-11,  2.49160359e-10,\n",
       "         -4.14719037e-10,  2.23004393e-10,  1.98442041e-10,\n",
       "         -3.97312128e-10, -3.97060912e-10,  1.52889618e-10,\n",
       "         -1.04671972e-10, -7.55532303e-11,  3.62642860e-10,\n",
       "          1.39733822e-10,  2.66317274e-10,  4.42164388e-10,\n",
       "         -2.03285278e-10,  4.67484995e-10,  2.87643687e-10,\n",
       "          6.36142750e-10, -2.10732432e-09, -1.90460675e-10,\n",
       "          1.88282875e-10, -6.34922115e-10, -3.01788705e-10,\n",
       "          5.03426771e-12, -1.64046099e-09,  7.91006594e-10,\n",
       "         -2.96405712e-11, -6.78728962e-10, -2.11844320e-10,\n",
       "         -2.90506202e-10,  4.07873568e-10, -2.38073672e-10,\n",
       "         -8.45485737e-10,  5.69665537e-10,  1.25268745e-11,\n",
       "          1.55525676e-10,  2.75047242e-11, -5.15532950e-10,\n",
       "          3.58469199e-10,  6.14341467e-10, -1.92509300e-10,\n",
       "          1.83291882e-10,  3.05336118e-10, -3.36188827e-10,\n",
       "          2.15262516e-10,  7.85364995e-10,  4.69092959e-11,\n",
       "         -8.34244118e-10,  6.91372903e-10,  2.32420194e-11,\n",
       "          4.13536622e-10,  1.34189923e-10, -1.94005680e-11,\n",
       "         -2.39742959e-09, -4.90984808e-10, -3.55820096e-11,\n",
       "          6.87552142e-12,  1.67786993e-10, -1.34126002e-10,\n",
       "         -3.34504202e-10,  3.26120048e-10,  9.92811736e-11,\n",
       "          2.38217649e-12]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(250, 1000), dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1000,), dtype=float32, numpy=\n",
       " array([-8.10170889e-11,  1.26477634e-10,  2.94170209e-11, -4.88981113e-11,\n",
       "        -7.77976225e-11,  4.44204309e-12,  3.93290782e-12, -1.56984717e-10,\n",
       "        -4.49330642e-11,  3.82463565e-13,  6.43021192e-11,  1.38265385e-10,\n",
       "         7.50191467e-13, -6.46368722e-11,  2.12539309e-11,  2.78741717e-11,\n",
       "        -1.57542285e-10,  1.11276696e-10,  1.10766231e-11, -8.50923845e-11,\n",
       "        -4.38674375e-11,  4.26274641e-11, -7.25025248e-11,  4.20647805e-12,\n",
       "         6.11426751e-12,  1.65722047e-10, -2.36218840e-11, -7.01325022e-12,\n",
       "        -2.44597294e-11,  1.25788928e-11,  1.24578847e-10,  3.88929826e-11,\n",
       "        -5.72621707e-11,  8.12505549e-11, -9.93655228e-11, -5.05627380e-11,\n",
       "        -7.36181116e-11, -3.17501823e-11,  1.47478904e-11, -1.28175179e-10,\n",
       "         6.02797369e-12,  8.05553055e-11, -8.73558725e-11,  1.65904707e-10,\n",
       "        -2.03050749e-12,  5.63804871e-11, -4.97751111e-11, -2.70489065e-11,\n",
       "         8.10912587e-11, -9.77405587e-11, -6.17077778e-11, -7.09077502e-12,\n",
       "        -2.36082265e-11, -6.77977882e-11, -3.81224878e-11, -8.56429649e-11,\n",
       "         2.24545816e-12,  9.86938586e-11,  5.41291734e-11,  1.18346227e-11,\n",
       "        -6.12143738e-11,  6.24131025e-11,  7.82806459e-11, -5.34576723e-11,\n",
       "         1.31047213e-12,  1.77069817e-10, -2.39046248e-11, -1.02466639e-10,\n",
       "         4.45697201e-10, -6.52713023e-11, -9.62994268e-12,  1.47987150e-10,\n",
       "         4.20991228e-11, -9.12559524e-12, -3.87989606e-11, -7.76689754e-11,\n",
       "        -2.99773539e-11,  6.69626854e-11, -4.42715309e-11,  1.26491422e-11,\n",
       "         1.34157321e-11, -1.46732793e-10, -1.85939762e-12, -1.89076376e-11,\n",
       "         2.20646473e-10, -7.84789421e-12,  1.14216608e-10,  2.95744054e-11,\n",
       "        -6.60564103e-11, -7.53052412e-11, -2.48177954e-11,  3.90679503e-11,\n",
       "        -3.67995304e-12,  1.15666261e-11, -2.74746892e-12,  3.85783801e-11,\n",
       "         1.06670596e-10, -5.28205778e-12,  2.28023104e-11, -9.45981557e-11,\n",
       "        -1.14782857e-10,  4.69441118e-11,  8.24412830e-11, -3.14890093e-11,\n",
       "        -8.57342355e-13, -1.66959571e-11, -8.11785916e-11, -1.16771384e-10,\n",
       "        -1.36071793e-10, -1.14042796e-10, -5.35991772e-11,  2.99169110e-12,\n",
       "         8.55421897e-12,  7.28855865e-11,  9.41808992e-11, -1.37404477e-10,\n",
       "        -5.00453368e-12, -9.52559559e-12,  1.07760372e-11,  9.00845093e-11,\n",
       "         8.87650717e-12, -9.62791583e-11,  1.61765273e-12,  2.83890151e-11,\n",
       "        -3.37509083e-11, -4.16093332e-12,  6.65012281e-11,  7.77805771e-12,\n",
       "        -5.32096242e-12,  8.61805852e-12,  1.94367127e-11, -1.64943809e-10,\n",
       "        -5.79344107e-11,  4.40964765e-11,  2.42168247e-11, -2.95622658e-11,\n",
       "         8.20272045e-11,  5.17997346e-11, -1.33433209e-10, -3.69388409e-11,\n",
       "        -1.03470132e-11, -8.03325115e-11, -1.50827101e-10, -1.25714050e-10,\n",
       "         9.91185259e-11,  4.58070170e-12,  1.23062541e-11,  7.11051426e-11,\n",
       "         3.30728916e-11, -4.06665430e-11, -1.54491822e-10, -5.05122298e-11,\n",
       "         2.45863968e-10,  6.22498789e-11,  8.56792068e-11,  9.93909382e-12,\n",
       "        -1.94953047e-11,  5.38480892e-12,  1.04278131e-11, -8.33728295e-11,\n",
       "         2.94503588e-11, -5.86550340e-12, -1.05094634e-10, -1.02405922e-11,\n",
       "         1.07680601e-11, -2.08492269e-11, -6.96815314e-11,  7.23220442e-11,\n",
       "         2.25152119e-11, -1.38957183e-12,  2.37573988e-10, -3.27668461e-14,\n",
       "         3.40342199e-11, -1.36453099e-10,  8.17022977e-11, -1.42389453e-12,\n",
       "         1.92341473e-11,  2.11145858e-11, -2.08741940e-10,  1.25101859e-10,\n",
       "         4.53073863e-11, -2.06306448e-11,  1.61811842e-10,  2.80699942e-11,\n",
       "        -1.59655743e-11,  2.23155140e-11, -2.52751795e-11, -8.52677737e-12,\n",
       "        -2.69870654e-11,  4.36936806e-11, -2.91904174e-11, -3.80403070e-11,\n",
       "         4.22181630e-11,  7.17676543e-11, -2.31180457e-11,  1.46006211e-11,\n",
       "         1.01937651e-11, -5.05073899e-11, -1.42807866e-11, -2.68509468e-11,\n",
       "        -4.06723093e-11,  3.63789381e-11, -1.03307432e-10, -4.94757568e-11,\n",
       "        -6.95527039e-11,  2.97353614e-10,  2.17657767e-11, -2.17721778e-11,\n",
       "         1.06344877e-10,  4.70280863e-11, -8.27753881e-13,  1.92145549e-10,\n",
       "        -7.27876578e-11,  3.69006865e-12,  1.07483550e-10,  3.37878614e-11,\n",
       "         5.13475963e-11, -6.10939077e-11,  3.79665188e-11,  1.19230792e-10,\n",
       "        -8.17155510e-11, -1.42445116e-12, -2.10677309e-11, -3.86751872e-12,\n",
       "         5.31012630e-11, -6.40139886e-11, -9.01614339e-11,  2.32463250e-11,\n",
       "        -2.09624887e-11, -4.55916450e-11,  3.97348543e-11, -3.76408731e-11,\n",
       "        -1.06341283e-10, -7.04538554e-12,  1.40370479e-10, -8.74773309e-11,\n",
       "        -4.82769727e-12, -4.44635613e-11, -2.25443882e-11,  2.06147426e-12,\n",
       "         2.29542857e-10,  7.26952942e-11,  4.82093055e-12, -1.03357871e-12,\n",
       "        -1.75282844e-11,  2.04420213e-11,  7.47841233e-11, -4.05674938e-11,\n",
       "        -1.41502582e-11, -3.92583454e-13,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.19772062e-10, -6.06802664e-10, -9.66941249e-11, -5.29240096e-10,\n",
       "        -8.76280826e-10,  7.92667945e-11, -6.66034450e-11,  5.25435473e-10,\n",
       "         7.42550521e-10, -1.37980113e-10, -8.48731252e-10,  8.29638636e-10,\n",
       "        -1.09503370e-11,  3.93865052e-10,  4.36385650e-10,  3.70814518e-10,\n",
       "         8.24966817e-10,  3.22076033e-10, -3.39854922e-10, -3.73941600e-10,\n",
       "         5.63247338e-10,  1.74039408e-10,  8.82929230e-10, -2.50681975e-10,\n",
       "         1.47762386e-10,  1.12138365e-09, -6.10497042e-10,  1.48188711e-10,\n",
       "         7.50875861e-10,  3.00546005e-10, -4.03567124e-10, -1.91360955e-10,\n",
       "         4.51851029e-10,  3.96895572e-10, -3.24162253e-10,  2.99577724e-10,\n",
       "        -2.21484150e-10, -4.52812815e-10, -1.13620224e-10, -4.76692186e-10,\n",
       "        -1.97938593e-11,  1.01405795e-09, -9.73939707e-10,  8.58842275e-10,\n",
       "         3.83644158e-11, -3.84424076e-10,  5.67287550e-10, -1.14384585e-10,\n",
       "        -5.77017600e-10, -7.27319649e-10, -6.38583020e-10,  4.37028330e-11,\n",
       "        -4.46354204e-10, -9.62418034e-10, -8.18207224e-10,  4.55054688e-10,\n",
       "        -3.85118222e-11,  4.83895590e-10, -2.39742781e-10,  9.96461802e-11,\n",
       "        -6.35207331e-10, -2.70273887e-10, -2.18188079e-10, -2.28904812e-10,\n",
       "        -6.98434930e-12,  1.37527523e-09, -1.05778213e-10, -4.51489346e-10,\n",
       "        -1.75810599e-09, -5.39359224e-10, -4.74412787e-10,  6.55942356e-10,\n",
       "        -4.51787524e-10, -5.55809114e-11, -1.57737212e-10, -5.28932453e-10,\n",
       "         1.33201117e-10, -2.84442109e-10, -8.16048951e-10, -3.95232493e-11,\n",
       "        -8.12980586e-11, -1.24434707e-09, -1.75840661e-11,  8.82252951e-11,\n",
       "        -6.44849452e-10, -1.06417530e-09,  9.66025926e-10,  2.96454528e-10,\n",
       "        -2.62442845e-10, -7.60124241e-10, -4.31681774e-10,  1.92916169e-10,\n",
       "        -1.38853762e-10, -6.21008189e-10,  2.61934502e-10,  9.53715551e-10,\n",
       "         3.44292372e-10,  4.18256055e-11,  4.56080868e-10, -5.18844523e-10,\n",
       "         4.33795055e-10,  3.30097366e-10,  5.24605304e-10, -2.11205720e-10,\n",
       "        -1.23503291e-10, -2.00687300e-10, -7.10181636e-10,  7.21012361e-10,\n",
       "         5.58399105e-10, -3.26521865e-10, -1.89552971e-10, -3.76895841e-11,\n",
       "        -4.81208573e-10, -5.19315257e-10,  4.19553531e-10,  6.63300470e-10,\n",
       "         1.27958574e-10, -4.80915620e-11,  1.24598540e-10,  2.91667190e-10,\n",
       "         7.38236361e-10, -2.82501994e-10, -1.65115560e-11, -5.60739122e-10,\n",
       "         2.15382628e-10,  1.53093926e-10, -2.39441716e-10, -2.39697762e-10,\n",
       "         2.74547208e-11,  4.54340177e-11,  5.29414734e-10,  1.15691101e-09,\n",
       "        -4.50112447e-10,  2.16398191e-10, -1.32883135e-10, -2.82838392e-10,\n",
       "        -3.63713143e-10, -1.52994659e-10, -4.71321482e-10, -2.36339115e-10,\n",
       "        -8.47188542e-10, -5.94724880e-10,  5.95441585e-10, -8.10529588e-10,\n",
       "         5.80960002e-10, -5.24558764e-11, -1.86385088e-10, -3.77134157e-10,\n",
       "        -1.47927989e-10, -2.26870078e-10,  5.87467797e-10, -7.55933038e-10,\n",
       "         9.27236010e-10, -3.64065778e-10, -4.07750639e-10, -7.27490498e-11,\n",
       "         1.36503653e-09,  2.33316505e-10, -2.85723362e-10, -5.71157566e-10,\n",
       "         2.43923381e-10, -2.65084517e-11, -9.22822874e-10,  1.30065361e-10,\n",
       "        -6.58718774e-11,  2.59935545e-10, -1.65186487e-09,  6.33066932e-10,\n",
       "        -1.33234729e-10, -4.69359230e-12, -9.56909219e-10, -2.03952659e-13,\n",
       "         2.49647664e-10, -6.55727694e-10,  3.16080745e-10, -3.10853288e-11,\n",
       "        -2.57215416e-10,  5.49483348e-10, -9.51509316e-10, -4.61843785e-10,\n",
       "         2.65974215e-10, -1.71196210e-10, -9.25262644e-10,  4.71656603e-10,\n",
       "         3.50827312e-10, -1.20998336e-10, -5.87737359e-10,  1.27717045e-10,\n",
       "         2.44039872e-10,  9.11496434e-10,  2.32347086e-10, -5.28029676e-10,\n",
       "         9.55189483e-10,  9.74824110e-10, -1.06684613e-10,  9.55278634e-11,\n",
       "        -3.74819897e-11, -1.34765921e-09, -1.20961824e-10,  2.51408200e-10,\n",
       "        -6.51582732e-10,  1.05606057e-09,  3.96454536e-10, -4.02982453e-10,\n",
       "         2.87551011e-10,  1.46805101e-09,  9.07089404e-11,  3.57450625e-10,\n",
       "        -8.57936944e-10,  2.75176604e-10,  6.58188998e-12,  1.11053389e-09,\n",
       "         4.09503376e-10,  5.63943232e-11,  8.05411515e-10, -3.29496069e-10,\n",
       "         6.33383179e-10, -2.25643393e-10, -1.33024203e-10, -4.78572793e-10,\n",
       "         2.14292833e-10,  8.64180227e-10,  7.98664190e-10, -4.23582336e-10,\n",
       "         2.39764875e-10,  2.67819933e-10,  8.55512439e-10,  2.05930176e-10,\n",
       "        -8.24027513e-10,  2.45751669e-10, -1.61840874e-10,  1.33710085e-10,\n",
       "        -1.49841284e-09,  3.57502750e-10, -5.07457520e-10,  2.99896608e-10,\n",
       "         6.08164352e-11,  8.85879037e-10,  3.14431259e-10,  1.19570560e-11,\n",
       "         9.93522375e-10,  2.84725576e-10,  2.90700491e-10,  7.64049587e-12,\n",
       "         3.78187148e-10, -9.64863051e-11,  5.24680910e-10, -7.63007491e-10,\n",
       "         4.02481035e-11, -1.25055161e-10, -7.10672354e-11,  1.28547617e-10,\n",
       "         3.95203488e-11, -4.42389216e-11, -9.48376516e-11,  3.22349352e-12,\n",
       "         2.62671200e-12, -1.08524613e-10, -5.43694360e-11,  2.79959649e-13,\n",
       "         8.21644558e-11,  1.46753554e-10,  7.15572350e-13, -6.71781450e-11,\n",
       "         1.90309955e-11,  3.12631449e-11, -1.51857624e-10,  1.18210469e-10,\n",
       "         1.16445256e-11, -7.24063309e-11, -4.39278232e-11,  4.44015796e-11,\n",
       "        -7.31474326e-11,  5.13353032e-12,  5.83163118e-12,  1.48678070e-10,\n",
       "        -3.49420146e-11, -5.30898762e-12, -1.94341696e-11,  8.34984339e-12,\n",
       "         1.51480051e-10,  4.98242836e-11, -5.73684295e-11,  5.70494867e-11,\n",
       "        -8.02651001e-11, -4.24159562e-11, -7.02428254e-11, -2.84397731e-11,\n",
       "         9.88174386e-12, -1.20243107e-10,  5.73907501e-12,  8.00360958e-11,\n",
       "        -1.30724251e-10,  2.01715797e-10, -3.31493231e-12,  4.68467487e-11,\n",
       "        -7.16792736e-11, -3.17580892e-11,  6.46080550e-11, -1.08552660e-10,\n",
       "        -7.06616363e-11, -5.54926504e-12, -2.49622788e-11, -6.60644664e-11,\n",
       "        -6.11446796e-11, -7.82459514e-11,  2.19616035e-12,  1.25081764e-10,\n",
       "         4.36136058e-11,  1.33794278e-11, -5.13233900e-11,  6.92825242e-11,\n",
       "         8.39114958e-11, -5.37140783e-11,  1.46744194e-12,  1.66636288e-10,\n",
       "        -2.28854106e-11, -1.13751231e-10,  4.14309781e-10, -8.63731309e-11,\n",
       "        -1.09145202e-11,  1.38489969e-10,  4.01913988e-11, -1.00918683e-11,\n",
       "        -3.32432207e-11, -7.34718467e-11, -2.66857925e-11,  6.39933037e-11,\n",
       "        -4.62440711e-11,  9.73170589e-12,  1.54710394e-11, -2.21617044e-10,\n",
       "        -2.14134504e-12, -2.00881724e-11,  2.16547724e-10, -9.68361676e-12,\n",
       "         8.39278994e-11,  3.68427754e-11, -6.24769680e-11, -6.70620504e-11,\n",
       "        -2.40527129e-11,  3.47277866e-11, -3.70580216e-12,  1.83055012e-11,\n",
       "        -4.13417304e-12,  3.53660608e-11,  1.13424332e-10, -6.85518699e-12,\n",
       "         2.01559117e-11, -1.35700257e-10, -1.65048530e-10,  3.25741413e-11,\n",
       "         1.21108179e-10, -2.29161273e-11, -6.45850940e-13, -1.51792971e-11,\n",
       "        -1.09411612e-10, -1.28729055e-10, -1.96684488e-10, -1.04481396e-10,\n",
       "        -4.79333552e-11,  4.80914917e-12,  8.88516691e-12,  6.24770652e-11,\n",
       "         1.17596072e-10, -9.56264720e-11, -5.84350146e-12, -1.01463282e-11,\n",
       "         1.24681567e-11,  1.15063084e-10,  8.88328040e-12, -9.14006995e-11,\n",
       "         1.39460232e-12,  2.17244781e-11, -2.44286449e-11, -5.78926620e-12,\n",
       "         5.38328236e-11,  8.57901770e-12, -4.50210659e-12,  8.47662739e-12,\n",
       "         2.10530985e-11, -1.78746309e-10, -5.31215315e-11,  3.34516928e-11,\n",
       "         2.38383636e-11, -3.33547252e-11,  1.14672154e-10,  4.41052958e-11,\n",
       "        -1.35644121e-10, -3.37732134e-11, -8.73305421e-12, -9.27425359e-11,\n",
       "        -1.76566581e-10, -1.34117606e-10,  1.06813065e-10,  5.65413298e-12,\n",
       "         1.17189852e-11,  5.57551540e-11,  2.83568603e-11, -4.75943243e-11,\n",
       "        -2.23176033e-10, -5.18797574e-11,  1.95622796e-10,  6.33729041e-11,\n",
       "         1.37813233e-10,  6.66513979e-12, -1.37274124e-11,  9.20605085e-12,\n",
       "         8.62767930e-12, -8.52816359e-11,  1.95418612e-11, -4.24663082e-12,\n",
       "        -7.98119140e-11, -1.13855028e-11,  8.15436260e-12, -1.78194317e-11,\n",
       "        -5.50811688e-11,  8.70365932e-11,  2.61846760e-11, -1.59749893e-12,\n",
       "         2.11232268e-10, -4.02740348e-14,  4.36648218e-11, -1.10309421e-10,\n",
       "         4.83467884e-11, -1.48035262e-12,  2.21083481e-11,  1.89150206e-11,\n",
       "        -2.02682315e-10,  1.13469886e-10,  4.85123677e-11, -1.85067101e-11,\n",
       "         1.25850483e-10,  3.27988782e-11, -1.61992746e-11,  2.16352509e-11,\n",
       "        -3.29139840e-11, -8.97446787e-12, -3.55943330e-11,  5.92455668e-11,\n",
       "        -3.18577630e-11, -2.83488684e-11,  5.67588684e-11,  5.67229839e-11,\n",
       "        -2.18413759e-11,  1.49531394e-11,  1.07933211e-11, -5.18061150e-11,\n",
       "        -1.99619748e-11, -3.80453204e-11, -6.31663402e-11,  2.90407542e-11,\n",
       "        -6.67835717e-11, -4.10919666e-11, -9.08775555e-11,  3.01046382e-10,\n",
       "         2.72086711e-11, -2.68975502e-11,  9.07031533e-11,  4.31126697e-11,\n",
       "        -7.19181171e-13,  2.34351566e-10, -1.13000928e-10,  4.23436850e-12,\n",
       "         9.69612654e-11,  3.02634723e-11,  4.15008895e-11, -5.82676615e-11,\n",
       "         3.40105236e-11,  1.20783689e-10, -8.13808118e-11, -1.78955353e-12,\n",
       "        -2.22179514e-11, -3.92924712e-12,  7.36475603e-11, -5.12098905e-11,\n",
       "        -8.77630676e-11,  2.75013241e-11, -2.61845528e-11, -4.36194483e-11,\n",
       "         4.80269678e-11, -3.07517935e-11, -1.12195003e-10, -6.70132829e-12,\n",
       "         1.19177709e-10, -9.87675705e-11, -3.32028805e-12, -5.90766672e-11,\n",
       "        -1.91699885e-11,  2.77150980e-12,  3.42489870e-10,  7.01406849e-11,\n",
       "         5.08314484e-12, -9.82217237e-13, -2.39695746e-11,  1.91608569e-11,\n",
       "         4.77863270e-11, -4.65885872e-11, -1.41830263e-11, -3.40310923e-13],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(250, 30), dtype=float32, numpy=\n",
       " array([[-1.21399912e-08,  9.25671717e-09,  1.10085034e-08, ...,\n",
       "         -6.01381300e-09, -1.20894246e-08,  1.22223893e-08],\n",
       "        [-1.17237029e-08,  8.93929819e-09,  1.06310125e-08, ...,\n",
       "         -5.80759396e-09, -1.16748682e-08,  1.18032757e-08],\n",
       "        [-1.10840137e-08,  8.45153902e-09,  1.00509467e-08, ...,\n",
       "         -5.49070966e-09, -1.10378435e-08,  1.11592451e-08],\n",
       "        ...,\n",
       "        [ 3.13798454e-09, -2.39270648e-09, -2.84551338e-09, ...,\n",
       "          1.55446978e-09,  3.12491277e-09, -3.15928284e-09],\n",
       "        [-1.08502451e-08,  8.27329050e-09,  9.83896431e-09, ...,\n",
       "         -5.37490807e-09, -1.08050484e-08,  1.09238920e-08],\n",
       "        [ 1.32424557e-10, -1.00973487e-10, -1.20082153e-10, ...,\n",
       "          6.55994287e-11,  1.31872957e-10, -1.33323394e-10]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       " array([ 1.14215645e-07, -8.70891910e-08, -1.03570351e-07, -6.01503274e-08,\n",
       "         5.85165161e-08,  4.78780535e-08,  1.12763345e-07, -4.94486443e-08,\n",
       "        -7.39868833e-09, -6.79468357e-08, -5.97209180e-08, -1.17230670e-08,\n",
       "         7.56260263e-08,  6.38312940e-08, -1.93583349e-09, -1.88686915e-08,\n",
       "        -9.23964336e-08,  7.06589987e-08, -2.89236475e-08,  4.85501737e-08,\n",
       "        -1.14618274e-07, -3.24926361e-08, -1.05146540e-07, -4.91733942e-08,\n",
       "         1.03630043e-07,  5.09604661e-08, -6.96248463e-08,  5.65792284e-08,\n",
       "         1.13739908e-07, -1.14990883e-07], dtype=float32)>,\n",
       " <tf.Tensor: shape=(30, 1), dtype=float32, numpy=\n",
       " array([[-2.3665605e-05],\n",
       "        [-2.3792867e-05],\n",
       "        [-2.3654871e-05],\n",
       "        [-2.3632667e-05],\n",
       "        [-2.3582277e-05],\n",
       "        [-2.3572615e-05],\n",
       "        [-2.3604340e-05],\n",
       "        [-2.3483177e-05],\n",
       "        [-2.3571092e-05],\n",
       "        [-2.3655586e-05],\n",
       "        [-2.3518529e-05],\n",
       "        [-2.3571760e-05],\n",
       "        [-2.3672483e-05],\n",
       "        [-2.3543094e-05],\n",
       "        [-2.3613711e-05],\n",
       "        [-2.3535744e-05],\n",
       "        [-2.3514594e-05],\n",
       "        [-2.3678467e-05],\n",
       "        [-2.3600231e-05],\n",
       "        [-2.3697638e-05],\n",
       "        [-2.3648288e-05],\n",
       "        [-2.3534725e-05],\n",
       "        [-2.3598815e-05],\n",
       "        [-2.3683135e-05],\n",
       "        [-2.3480350e-05],\n",
       "        [-2.3674254e-05],\n",
       "        [-2.3483208e-05],\n",
       "        [-2.3633509e-05],\n",
       "        [-2.3459734e-05],\n",
       "        [-2.3660246e-05]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-4.7221863e-05], dtype=float32)>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30, 1), dtype=float32, numpy=\n",
       "array([[-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125],\n",
       "       [-0.03125]], dtype=float32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[-2]/p2[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def monster_gradient2(actor, dq_da, experiences, optimizer_actor):\n",
    "    finns = [tf.ones((experiences.shape[0], 1,1))*actor.pad_value]\n",
    "    unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "    for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "        finns.append(tf.reshape(unstacked_exp[index], (experiences.shape[0], 1,1)))\n",
    "    final_preds = tf.concat(finns, axis=1)\n",
    "\n",
    "    with tf.GradientTape() as gg:\n",
    "        gg.watch(actor.trainable_variables)\n",
    "        predictions = actor(final_preds)\n",
    "            \n",
    "    da_dtheta1 = predictions\n",
    "    return gg.jacobian(da_dtheta1, actor.trainable_variables)\n",
    "#tape.jacobian(da_dtheta1, actor.trainable_variables)\n",
    "#https://github.com/tensorflow/tensorflow/issues/37053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(32, 1, 1, 1, 1000), dtype=float32, numpy=\n",
      "array([[[[[-1.2009596e-05,  1.8748457e-05,  4.3606419e-06, ...,\n",
      "           -6.9060748e-06, -2.1024257e-06, -5.0446108e-08]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[-1.2009596e-05,  1.8748457e-05,  4.3606419e-06, ...,\n",
      "           -6.9060748e-06, -2.1024257e-06, -5.0446108e-08]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[-1.2009596e-05,  1.8748457e-05,  4.3606419e-06, ...,\n",
      "           -6.9060748e-06, -2.1024257e-06, -5.0446108e-08]]]],\n",
      "\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "\n",
      "       [[[[-1.2009596e-05,  1.8748457e-05,  4.3606419e-06, ...,\n",
      "           -6.9060748e-06, -2.1024257e-06, -5.0446108e-08]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[-1.2009596e-05,  1.8748457e-05,  4.3606419e-06, ...,\n",
      "           -6.9060748e-06, -2.1024257e-06, -5.0446108e-08]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[-1.2009595e-05,  1.8748455e-05,  4.3606433e-06, ...,\n",
      "           -6.9060757e-06, -2.1024280e-06, -5.0446125e-08]]]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(32, 1, 1, 250, 1000), dtype=float32, numpy=\n",
      "array([[[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.],\n",
      "          [0., 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)>, <tf.Tensor: shape=(32, 1, 1, 1000), dtype=float32, numpy=\n",
      "array([[[[ 1.7156565e-06, -2.6783509e-06, -6.2294885e-07, ...,\n",
      "           9.8658211e-07,  3.0034653e-07,  7.2065869e-09]]],\n",
      "\n",
      "\n",
      "       [[[ 1.7156565e-06, -2.6783509e-06, -6.2294885e-07, ...,\n",
      "           9.8658211e-07,  3.0034653e-07,  7.2065869e-09]]],\n",
      "\n",
      "\n",
      "       [[[ 1.7156565e-06, -2.6783509e-06, -6.2294885e-07, ...,\n",
      "           9.8658211e-07,  3.0034653e-07,  7.2065869e-09]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 1.7156565e-06, -2.6783509e-06, -6.2294885e-07, ...,\n",
      "           9.8658211e-07,  3.0034653e-07,  7.2065869e-09]]],\n",
      "\n",
      "\n",
      "       [[[ 1.7156565e-06, -2.6783509e-06, -6.2294885e-07, ...,\n",
      "           9.8658211e-07,  3.0034653e-07,  7.2065869e-09]]],\n",
      "\n",
      "\n",
      "       [[[ 1.7156564e-06, -2.6783507e-06, -6.2294902e-07, ...,\n",
      "           9.8658222e-07,  3.0034684e-07,  7.2065891e-09]]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(32, 1, 1, 250, 30), dtype=float32, numpy=\n",
      "array([[[[[ 2.5708225e-04, -1.9602470e-04, -2.3312132e-04, ...,\n",
      "            1.2735136e-04,  2.5601141e-04, -2.5882717e-04],\n",
      "          [ 2.4826673e-04, -1.8930288e-04, -2.2512741e-04, ...,\n",
      "            1.2298439e-04,  2.4723259e-04, -2.4995182e-04],\n",
      "          [ 2.3472038e-04, -1.7897382e-04, -2.1284365e-04, ...,\n",
      "            1.1627391e-04,  2.3374267e-04, -2.3631353e-04],\n",
      "          ...,\n",
      "          [-6.6451459e-05,  5.0669103e-05,  6.0257957e-05, ...,\n",
      "           -3.2918197e-05, -6.6174660e-05,  6.6902496e-05],\n",
      "          [ 2.2977000e-04, -1.7519915e-04, -2.0835464e-04, ...,\n",
      "            1.1382163e-04,  2.2881290e-04, -2.3132954e-04],\n",
      "          [-2.8042862e-06,  2.1382625e-06,  2.5429172e-06, ...,\n",
      "           -1.3891649e-06, -2.7926051e-06,  2.8233201e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[ 2.5708225e-04, -1.9602470e-04, -2.3312132e-04, ...,\n",
      "            1.2735136e-04,  2.5601141e-04, -2.5882717e-04],\n",
      "          [ 2.4826673e-04, -1.8930288e-04, -2.2512741e-04, ...,\n",
      "            1.2298439e-04,  2.4723259e-04, -2.4995182e-04],\n",
      "          [ 2.3472038e-04, -1.7897382e-04, -2.1284365e-04, ...,\n",
      "            1.1627391e-04,  2.3374267e-04, -2.3631353e-04],\n",
      "          ...,\n",
      "          [-6.6451459e-05,  5.0669103e-05,  6.0257957e-05, ...,\n",
      "           -3.2918197e-05, -6.6174660e-05,  6.6902496e-05],\n",
      "          [ 2.2977000e-04, -1.7519915e-04, -2.0835464e-04, ...,\n",
      "            1.1382163e-04,  2.2881290e-04, -2.3132954e-04],\n",
      "          [-2.8042862e-06,  2.1382625e-06,  2.5429172e-06, ...,\n",
      "           -1.3891649e-06, -2.7926051e-06,  2.8233201e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[ 2.5708225e-04, -1.9602470e-04, -2.3312132e-04, ...,\n",
      "            1.2735136e-04,  2.5601141e-04, -2.5882717e-04],\n",
      "          [ 2.4826673e-04, -1.8930288e-04, -2.2512741e-04, ...,\n",
      "            1.2298439e-04,  2.4723259e-04, -2.4995182e-04],\n",
      "          [ 2.3472038e-04, -1.7897382e-04, -2.1284365e-04, ...,\n",
      "            1.1627391e-04,  2.3374267e-04, -2.3631353e-04],\n",
      "          ...,\n",
      "          [-6.6451459e-05,  5.0669103e-05,  6.0257957e-05, ...,\n",
      "           -3.2918197e-05, -6.6174660e-05,  6.6902496e-05],\n",
      "          [ 2.2977000e-04, -1.7519915e-04, -2.0835464e-04, ...,\n",
      "            1.1382163e-04,  2.2881290e-04, -2.3132954e-04],\n",
      "          [-2.8042862e-06,  2.1382625e-06,  2.5429172e-06, ...,\n",
      "           -1.3891649e-06, -2.7926051e-06,  2.8233201e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "\n",
      "       [[[[ 2.5708225e-04, -1.9602470e-04, -2.3312132e-04, ...,\n",
      "            1.2735136e-04,  2.5601141e-04, -2.5882717e-04],\n",
      "          [ 2.4826673e-04, -1.8930288e-04, -2.2512741e-04, ...,\n",
      "            1.2298439e-04,  2.4723259e-04, -2.4995182e-04],\n",
      "          [ 2.3472038e-04, -1.7897382e-04, -2.1284365e-04, ...,\n",
      "            1.1627391e-04,  2.3374267e-04, -2.3631353e-04],\n",
      "          ...,\n",
      "          [-6.6451459e-05,  5.0669103e-05,  6.0257957e-05, ...,\n",
      "           -3.2918197e-05, -6.6174660e-05,  6.6902496e-05],\n",
      "          [ 2.2977000e-04, -1.7519915e-04, -2.0835464e-04, ...,\n",
      "            1.1382163e-04,  2.2881290e-04, -2.3132954e-04],\n",
      "          [-2.8042862e-06,  2.1382625e-06,  2.5429172e-06, ...,\n",
      "           -1.3891649e-06, -2.7926051e-06,  2.8233201e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[ 2.5708225e-04, -1.9602470e-04, -2.3312132e-04, ...,\n",
      "            1.2735136e-04,  2.5601141e-04, -2.5882717e-04],\n",
      "          [ 2.4826673e-04, -1.8930288e-04, -2.2512741e-04, ...,\n",
      "            1.2298439e-04,  2.4723259e-04, -2.4995182e-04],\n",
      "          [ 2.3472038e-04, -1.7897382e-04, -2.1284365e-04, ...,\n",
      "            1.1627391e-04,  2.3374267e-04, -2.3631353e-04],\n",
      "          ...,\n",
      "          [-6.6451459e-05,  5.0669103e-05,  6.0257957e-05, ...,\n",
      "           -3.2918197e-05, -6.6174660e-05,  6.6902496e-05],\n",
      "          [ 2.2977000e-04, -1.7519915e-04, -2.0835464e-04, ...,\n",
      "            1.1382163e-04,  2.2881290e-04, -2.3132954e-04],\n",
      "          [-2.8042862e-06,  2.1382625e-06,  2.5429172e-06, ...,\n",
      "           -1.3891649e-06, -2.7926051e-06,  2.8233201e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[ 2.5708225e-04, -1.9602470e-04, -2.3312132e-04, ...,\n",
      "            1.2735136e-04,  2.5601141e-04, -2.5882717e-04],\n",
      "          [ 2.4826673e-04, -1.8930288e-04, -2.2512741e-04, ...,\n",
      "            1.2298439e-04,  2.4723259e-04, -2.4995182e-04],\n",
      "          [ 2.3472038e-04, -1.7897382e-04, -2.1284365e-04, ...,\n",
      "            1.1627391e-04,  2.3374267e-04, -2.3631353e-04],\n",
      "          ...,\n",
      "          [-6.6451459e-05,  5.0669103e-05,  6.0257957e-05, ...,\n",
      "           -3.2918197e-05, -6.6174660e-05,  6.6902496e-05],\n",
      "          [ 2.2977000e-04, -1.7519915e-04, -2.0835464e-04, ...,\n",
      "            1.1382163e-04,  2.2881290e-04, -2.3132954e-04],\n",
      "          [-2.8042862e-06,  2.1382625e-06,  2.5429172e-06, ...,\n",
      "           -1.3891649e-06, -2.7926051e-06,  2.8233201e-06]]]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(32, 1, 1, 30), dtype=float32, numpy=\n",
      "array([[[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.4186850e-03,  1.8442424e-03,  2.1932553e-03,\n",
      "           1.2737721e-03, -1.2391737e-03, -1.0138886e-03,\n",
      "          -2.3879302e-03,  1.0471483e-03,  1.5667816e-04,\n",
      "           1.4388748e-03,  1.2646787e-03,  2.4825329e-04,\n",
      "          -1.6014929e-03, -1.3517223e-03,  4.0994139e-05,\n",
      "           3.9957237e-04,  1.9566314e-03, -1.4963089e-03,\n",
      "           6.1250100e-04, -1.0281217e-03,  2.4272115e-03,\n",
      "           6.8807969e-04,  2.2266335e-03,  1.0413195e-03,\n",
      "          -2.1945192e-03, -1.0791632e-03,  1.4744090e-03,\n",
      "          -1.1981489e-03, -2.4086102e-03,  2.4351017e-03]]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(32, 1, 1, 30, 1), dtype=float32, numpy=\n",
      "array([[[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.5004567 ],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.50045663],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]],\n",
      "\n",
      "\n",
      "\n",
      "       [[[[0.5011541 ],\n",
      "          [0.50384915],\n",
      "          [0.5009269 ],\n",
      "          [0.50045663],\n",
      "          [0.49938968],\n",
      "          [0.4991849 ],\n",
      "          [0.49985677],\n",
      "          [0.49729097],\n",
      "          [0.49915275],\n",
      "          [0.500942  ],\n",
      "          [0.49803963],\n",
      "          [0.49916685],\n",
      "          [0.50129986],\n",
      "          [0.49855983],\n",
      "          [0.5000552 ],\n",
      "          [0.49840423],\n",
      "          [0.4979563 ],\n",
      "          [0.5014266 ],\n",
      "          [0.4997698 ],\n",
      "          [0.50183254],\n",
      "          [0.5007875 ],\n",
      "          [0.49838263],\n",
      "          [0.49973977],\n",
      "          [0.5015254 ],\n",
      "          [0.49723113],\n",
      "          [0.5013373 ],\n",
      "          [0.49729168],\n",
      "          [0.5004746 ],\n",
      "          [0.49679458],\n",
      "          [0.5010407 ]]]]], dtype=float32)>, <tf.Tensor: shape=(32, 1, 1, 1), dtype=float32, numpy=\n",
      "array([[[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]],\n",
      "\n",
      "\n",
      "       [[[0.9999928]]]], dtype=float32)>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1), dtype=float32, numpy=array([[[0.00268058]]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.lstm.stateful=False\n",
    "actor.reset_states_workaround(new_batch_size=experiences.shape[0])\n",
    "\n",
    "print(monster_gradient2(actor, dq_da, experiences, optimizer_actor))\n",
    "actor.reset_states_workaround(new_batch_size=int(1))\n",
    "actor(context_outcome_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    }
   ],
   "source": [
    "finns = [tf.ones((experiences.shape[0], 1,1))*actor.pad_value]\n",
    "unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "    finns.append(tf.reshape(unstacked_exp[index], (experiences.shape[0], 1,1)))\n",
    "final_preds = tf.concat(finns, axis=1)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as gg:\n",
    "    gg.watch(actor.trainable_variables)\n",
    "    predictions = actor(final_preds)\n",
    "    pp=[]\n",
    "    for k in tf.unstack(predictions):\n",
    "        pp.append(gg.gradient(k, actor.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ev = []\n",
    "history_betas = []\n",
    "total_episodes = 10**3\n",
    "batch_size = 128.           \n",
    "\n",
    "context_outcome_actor = np.reshape(np.array([actor.pad_value]),(1,1,1)).astype(np.float32)\n",
    "history_betas.append(np.squeeze(actor(context_outcome_actor)[0]))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "\n",
    "ax1 = plt.subplot2grid((2,2),(0,0))\n",
    "ax2 = plt.subplot2grid((2,2),(0,1))\n",
    "ax3 = plt.subplot2grid((2,2),(1,0))\n",
    "ax4 = plt.subplot2grid((2,2),(1,1))\n",
    "\n",
    "axes = {\"0.0\":ax1, \"1.0\":ax2}\n",
    "\n",
    "\n",
    "for k in tqdm(range(10**3)):\n",
    "    experiences = buffer.sample(batch_size).astype(np.float32)\n",
    "    samples, zerolabs = critic_target.process_sequence_tf(experiences)\n",
    "    labels_critic = critic_target.give_td_errors_tf( samples, zerolabs)\n",
    "    loss_critic = step_critic_tf(samples ,labels_critic, critic, optimizer_critic)\n",
    "    critic_target.update_target_parameters(critic)\n",
    "    #loss_ev.append(loss_critic.numpy())\n",
    "    #### actor ####\n",
    "    \n",
    "    actor.lstm.stateful=False\n",
    "    actor.reset_states_workaround(new_batch_size=int(batch_size))\n",
    "    \n",
    "    dq_da = critic_grad_tf(critic, experiences)\n",
    "    monster_gradient(actor, -dq_da, experiences, optimizer_actor)\n",
    "    \n",
    "    actor.reset_states_workaround(new_batch_size=1)\n",
    "\n",
    "    context_outcome_actor = np.reshape(np.array([actor.pad_value]),(1,1,1)).astype(np.float32)\n",
    "    history_betas.append(np.squeeze(actor(context_outcome_actor)[0]))\n",
    "    \n",
    "    if k%int(total_episodes/10)==1:\n",
    "        plot(critic, episode=k, last_episode=False, max_episode = total_episodes)\n",
    "plot(critic, episode=k, last_episode=True, history_betas=history_betas)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let0s analyze critic graddient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_actor.learning_rate.assign(tf.Variable(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor(nature=\"primary\")\n",
    "actor(context_outcome_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "for k in tqdm(range(10**2)):\n",
    "    experiences = buffer.sample(batch_size).astype(np.float32)\n",
    "    \n",
    "    actor.lstm.stateful=False\n",
    "    actor.reset_states_workaround(new_batch_size=int(batch_size))\n",
    "    \n",
    "    dq_da = critic_grad_tf(critic, experiences)\n",
    "    monster_gradient(actor, -dq_da, experiences, optimizer_actor)\n",
    "    \n",
    "    actor.reset_states_workaround(new_batch_size=1)\n",
    "\n",
    "    context_outcome_actor = np.reshape(np.array([actor.pad_value]),(1,1,1)).astype(np.float32)\n",
    "    history_betas.append(np.squeeze(actor(context_outcome_actor)[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_grad_tf(critic, experiences):\n",
    "    with tf.GradientTape() as tape:\n",
    "        unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "        to_stack = []\n",
    "        actions_wathed_index = []\n",
    "        for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "            actions_wathed_index.append(index)\n",
    "            to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        actions_indexed = tf.concat(to_stack,axis=1)\n",
    "        tape.watch(actions_indexed)\n",
    "\n",
    "        index_actions=0\n",
    "        watched_exps=[tf.ones((experiences.shape[0],1,1))*critic.pad_value]\n",
    "        watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "        for index in range(0,experiences.shape[-1]-1):\n",
    "            if index in actions_wathed_index:\n",
    "                watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "                index_actions+=1\n",
    "            else:\n",
    "                watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))\n",
    "\n",
    "        dq_da = tape.gradient(qvals, actions_indexed)\n",
    "        #tf.print(\"dq_da mean\", tf.math.reduce_mean(dq_da))\n",
    "        return dq_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_grad_tf(critic, experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = experiences[:5]\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "    to_stack = []\n",
    "    actions_wathed_index = []\n",
    "    for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "        actions_wathed_index.append(index)\n",
    "        to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "    actions_indexed = tf.concat(to_stack,axis=1)\n",
    "    tape.watch(actions_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = experiences[:5]\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "    to_stack = []\n",
    "    actions_wathed_index = []\n",
    "    for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "        actions_wathed_index.append(index)\n",
    "        to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "    actions_indexed = tf.concat(to_stack,axis=1)\n",
    "    tape.watch(actions_indexed)\n",
    "\n",
    "    index_actions=0\n",
    "    watched_exps=[tf.ones((experiences.shape[0],1,1))*critic.pad_value]\n",
    "    watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "    for index in range(0,experiences.shape[-1]-1):\n",
    "        if index in actions_wathed_index:\n",
    "            watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "            index_actions+=1\n",
    "        else:\n",
    "            watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "    qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic(critic.process_sequence(experiences)[0]) - qvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = experiences[:5]\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "    to_stack = []\n",
    "    actions_wathed_index = []\n",
    "    for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "        actions_wathed_index.append(index)\n",
    "        to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "    actions_indexed = tf.concat(to_stack,axis=1)\n",
    "    tape.watch(actions_indexed)\n",
    "\n",
    "    index_actions=0\n",
    "    watched_exps=[tf.ones((experiences.shape[0],1,1))*critic.pad_value]\n",
    "    watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "    for index in range(0,experiences.shape[-1]-1):\n",
    "        if index in actions_wathed_index:\n",
    "            watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "            index_actions+=1\n",
    "        else:\n",
    "            watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "    qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))\n",
    "    dq_da = tape.gradient(qvals, actions_indexed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale, it makes what we want, \\grad_a Q(s,a).\n",
    "\n",
    "Let's look the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in da_dtheta1:\n",
    "    print(k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_actor.apply_gradients(zip(grad_j, actor.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo junto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.reset_states_workaround(new_batch_size=1)\n",
    "actor(context_outcome_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def give_gradients_actions(experiences, actor):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(actor.trainable_variables)\n",
    "        finns = [tf.ones((experiences.shape[0], 1,1))*actor.pad_value]\n",
    "        unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "        for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "            finns.append(tf.reshape(unstacked_exp[index], (experiences.shape[0], 1,1)))\n",
    "        final_preds = tf.concat(finns, axis=1)\n",
    "        finalss = actor(final_preds)\n",
    "    return tape.jacobian(finalss, actor.trainable_variables)\n",
    "\n",
    "def apply_grads_J(da_dtheta1, dq_da, actor, optimizer_actor):\n",
    "    variables = actor.trainable_variables\n",
    "    grad_j=[]\n",
    "    for k in range(len(da_dtheta1)):\n",
    "        onnns = tf.ones(len(tf.shape(da_dtheta1[k]))-1)\n",
    "        multip = tf.reshape(dq_da,tf.cast(tf.concat([tf.Variable([batch_size]),onnns], axis=0), np.int32))*da_dtheta1[k]\n",
    "        multip = tf.reshape(tf.math.reduce_mean(multip, axis=0), variables[k].shape)\n",
    "        grad_j.append(multip)\n",
    "    optimizer_actor.apply_gradients(zip(grad_j, actor.trainable_variables))\n",
    "    return\n",
    "\n",
    "def gradeame_J(experiences, actor, dq_da, optimizer_actor):\n",
    "    gg = give_gradients_actions(experiences, actor)\n",
    "    apply_grads_J(gg, dq_da, actor, optimizer_actor)\n",
    "    return\n",
    "\n",
    "\n",
    "gradeame_J(experiences, actor, dq_da, optimizer_actor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
