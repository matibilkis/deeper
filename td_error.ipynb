{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self,nature, valreg=0.01, seed_val=0.3, pad_value=-7., dolinar_layers=2, tau=0.01, number_phases=2):\n",
    "        '''\n",
    "        dolinar_layers= number of photodetections\n",
    "        pad_value: value not considered by the lstm\n",
    "        valreg: regularisation value\n",
    "        seed_val: interval of random parameter inizialitaion.\n",
    "        nature: primary or target\n",
    "        '''\n",
    "        super(Critic,self).__init__()\n",
    "\n",
    "        self.pad_value = pad_value\n",
    "        self.number_phases = number_phases\n",
    "        self.nature = nature\n",
    "        self.dolinar_layers = dolinar_layers\n",
    "        self.mask = tf.keras.layers.Masking(mask_value=pad_value,\n",
    "                                  input_shape=(self.dolinar_layers, 2)) #(beta1, pad), (n1, beta2), (n2, guess). In general i will have (layer+1)\n",
    "        self.lstm = tf.keras.layers.LSTM(500, return_sequences=True)\n",
    "\n",
    "        self.tau = tau\n",
    "        self.l1 = Dense(250,kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg))\n",
    "\n",
    "        self.l2 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l3 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l4 = Dense(1, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "\n",
    "\n",
    "    def update_target_parameters(self,primary_net):\n",
    "        #### only\n",
    "        # for i,j in zip(self.get_weights(), primary_net.get_weights()):\n",
    "        #     tf.assign(i, tau*j + (i-tau)*i )\n",
    "        prim_weights = primary_net.get_weights()\n",
    "        targ_weights = self.get_weights()\n",
    "        weights = []\n",
    "        for i in tf.range(len(prim_weights)):\n",
    "            weights.append(self.tau * prim_weights[i] + (1 - self.tau) * targ_weights[i])\n",
    "        self.set_weights(weights)\n",
    "        return\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feat = self.mask(inputs)\n",
    "        feat= self.lstm(feat)\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l1(feat))\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        feat = tf.nn.relu(self.l3(feat))\n",
    "        feat = tf.nn.sigmoid(self.l4(feat))\n",
    "        return feat\n",
    "\n",
    "\n",
    "    def process_sequence(self,sample_buffer):\n",
    "        \"\"\"\"\n",
    "        sample_buffer: array of shape (N,2*self.layers +1), N>1 (+1 for the reward)\n",
    "\n",
    "        gets data obtained from N experiments: data.shape = (N, 2L+1),\n",
    "        where +1 accounts for the guess and 2L for (beta, outcome).\n",
    "\n",
    "        [[a0, o1, a1, o2, a2, o3, a4]\n",
    "         [same but other experiment]\n",
    "        ]\n",
    "\n",
    "        and returns an array of shape (experiments, self.layers, 2 ), as accepted by an RNN\n",
    "        \"\"\"\n",
    "        rr = np.ones(sample_buffer.shape)*self.pad_value\n",
    "        rr[:,1:] = sample_buffer[:,:-1]\n",
    "        rr = np.reshape(rr, (sample_buffer.shape[0],self.dolinar_layers+1,2))\n",
    "        #padded_data[:,selff.dolinar_layers] = data[:,[selff.dolinar_layers+1, selff.dolinar_layers+2]]\n",
    "        rewards_obtained = np.zeros((sample_buffer.shape[0], self.dolinar_layers+1))\n",
    "        rewards_obtained[:,-1] = sample_buffer[:,-1]\n",
    "        return rr, rewards_obtained\n",
    "\n",
    "\n",
    "    # def pad_single_sequence(self, seq):\n",
    "    #     \"\"\"\"\n",
    "    #     input: [a0, o1, a1, o2, a2, o3, a4]\n",
    "    #\n",
    "    #     output: [[a0, pad], [o1, a1], [...]]\n",
    "    #\n",
    "    #     the cool thing is that then you can put this to predict the greedy guess/action.\n",
    "    #     \"\"\"\n",
    "    #     padded_data = np.ones((1,self.dolinar_layers+1, 2))*self.pad_value\n",
    "    #     padded_data[0][0][0] = seq[0]\n",
    "    #     #padded_data[0][0] = data[0]\n",
    "    #     for k in range(1,self.dolinar_layers+1):\n",
    "    #         padded_data[0][k] = seq[k:(k+2)]\n",
    "    #     return padded_data\n",
    "\n",
    "    def give_td_error_Kennedy_guess(self,batched_input,sequential_rews_with_zeros):\n",
    "        # this function takes as input the actions as given by the target actor (but the first one!)\n",
    "        #and outpus the correspoindg TD-errors for DDPG! To obtain them from sample of buffer\n",
    "        #you call the method targeted_sequence from the actor_target and then the process_sequence\n",
    "        #of this critic network.\n",
    "        #### PROBLEM HERE!!!\n",
    "        if self.nature != \"target\":\n",
    "            raise AttributeError(\"I'm not the target!\")\n",
    "            return\n",
    "        b = batched_input.copy()\n",
    "        ll = sequential_rews_with_zeros.copy()\n",
    "        for k in range(self.dolinar_layers):\n",
    "            ll[:,k] = np.squeeze(self(b))[:,k+1] + ll[:,k]\n",
    "\n",
    "        preds1 = self(b)\n",
    "        b[:,-1][:,-1] = -b[:,1][:,1]\n",
    "        preds2 = self(b)\n",
    "        both = tf.concat([preds1,preds2],2)\n",
    "        maxs = np.squeeze(tf.math.reduce_max(both,axis=2).numpy())\n",
    "        ll[:,-2] = maxs[:,-1] # This is the last befre the guess.. so the label is max_g Q(h-L, g)\n",
    "        ll = np.expand_dims(ll,axis=1)\n",
    "        return ll\n",
    "\n",
    "\n",
    "    def give_favourite_guess(self,hL):\n",
    "        \"\"\"\n",
    "        hL is history (a_0, o1, a_1 ,... o_L)\n",
    "\n",
    "        outputs: index of the guessed phase, as to be input in env.give_reward, input_network_guess which is this index\n",
    "        divided by number_phases (clipped input of the network) ///is this relevant/important? ///\n",
    "\n",
    "        \"\"\"\n",
    "        rr = np.random.randn(self.number_phases,2*self.dolinar_layers+1)\n",
    "        rr[:,:-1] = hL\n",
    "        rr[:,-1] = np.arange(self.number_phases)/self.number_phases #just to keep the value in [0,1], don't know if it's important\n",
    "        batched_all_guesses = np.reshape(rr[:,[-2,-1]],(self.number_phases, 1, 2))\n",
    "        predsq = self(batched_all_guesses)\n",
    "        guess = np.squeeze(tf.argmax(predsq, axis=0))\n",
    "        input_netork_guess = guess/self.number_phases\n",
    "        return guess, input_netork_guess\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### ACTOR CLASSS ####\n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, nature, valreg=0.01, seed_val=0.1, pad_value = -7.,\n",
    "                 dolinar_layers=2,tau=0.01):\n",
    "        super(Actor,self).__init__()\n",
    "        self.dolinar_layers = dolinar_layers\n",
    "        self.pad_value = pad_value\n",
    "        self.nature = nature\n",
    "        self.tau = tau\n",
    "\n",
    "        if nature == \"primary\":\n",
    "            self.lstm = tf.keras.layers.LSTM(500, return_sequences=True, stateful=True)\n",
    "            self.mask = tf.keras.layers.Masking(mask_value=pad_value,\n",
    "                                  input_shape=(1,1))#CHECK\n",
    "        elif nature == \"target\":\n",
    "            self.lstm = tf.keras.layers.LSTM(500, return_sequences=True, stateful=False)\n",
    "            self.mask = tf.keras.layers.Masking(mask_value=pad_value,\n",
    "                                  input_shape=(self.dolinar_layers, 1)) #'cause i feed altoghether.\n",
    "        else:\n",
    "            print(\"Hey! the character is either primary or target\")\n",
    "        self.l1 = Dense(250,kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg), dtype='float32')\n",
    "\n",
    "        self.l2 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val), dtype='float32')\n",
    "\n",
    "        self.l3 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val), dtype='float32')\n",
    "\n",
    "        self.l4 = Dense(1, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val), dtype='float32')\n",
    "\n",
    "\n",
    "\n",
    "    def update_target_parameters(self,primary_net):\n",
    "        #### only\n",
    "        # for i,j in zip(self.get_weights(), primary_net.get_weights()):\n",
    "        #     tf.assign(i, tau*j + (i-tau)*i )\n",
    "        prim_weights = primary_net.get_weights()\n",
    "        targ_weights = self.get_weights()\n",
    "        weights = []\n",
    "        for i in tf.range(len(prim_weights)):\n",
    "            weights.append(self.tau * prim_weights[i] + (1 - self.tau) * targ_weights[i])\n",
    "        self.set_weights(weights)\n",
    "        return\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feat = self.mask(inputs)\n",
    "        feat= self.lstm(feat)\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l1(feat))\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        feat = tf.nn.relu(self.l3(feat))\n",
    "        feat = tf.nn.tanh(self.l4(feat))\n",
    "\n",
    "        return feat\n",
    "\n",
    "    def process_sequence_of_experiences(self, experiences):\n",
    "\n",
    "        export = experiences.copy()\n",
    "        for index in range(1,2*self.dolinar_layers-1,2): # I consider from first outcome to last one (but guess)\n",
    "            export[:,index+1] = np.squeeze(self(np.reshape(np.array(export[:,index]),\n",
    "                                                                 (experiences.shape[0],1,1))))\n",
    "        return export\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Critic(nature=\"target\", dolinar_layers = 2, number_phases=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = np.load(\"tutorials_functions/expe_2L.npy\")[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbl, rr= critic.process_sequence(experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-7.        ,  0.69102163],\n",
       "        [ 0.        ,  0.83695079],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.98145692],\n",
       "        [ 0.        ,  0.04985608],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.69588898],\n",
       "        [ 0.        ,  0.30091034],\n",
       "        [ 0.        ,  1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.65480695],\n",
       "        [ 0.        ,  0.72952473],\n",
       "        [ 1.        , -1.        ]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_td_error_Kennedy_guess(self,batched_input,sequential_rews_with_zeros):\n",
    "    # this function takes as input the actions as given by the target actor (but the first one!)\n",
    "    #and outpus the correspoindg TD-errors for DDPG! To obtain them from sample of buffer\n",
    "    #you call the method targeted_sequence from the actor_target and then the process_sequence\n",
    "    #of this critic network.\n",
    "    #### PROBLEM HERE!!!\n",
    "    if self.nature != \"target\":\n",
    "        raise AttributeError(\"I'm not the target!\")\n",
    "        return\n",
    "    b = batched_input.copy()\n",
    "    ll = sequential_rews_with_zeros.copy()\n",
    "    for k in range(critic.dolinar_layers):\n",
    "        ll[:,k] = np.squeeze(self(b))[:,k+1] + ll[:,k]\n",
    "\n",
    "    b[:,-1][:,-1] = 0.\n",
    "    all_preds = self(b)\n",
    "    for phase in np.arange(1,self.number_phases)/self.number_phases:\n",
    "        b[:,-1][:,-1] = phase\n",
    "        all_preds = tf.concat([all_preds,self(b)],2)\n",
    "    \n",
    "    maxs = np.squeeze(tf.math.reduce_max(all_preds,axis=2).numpy())\n",
    "    ll[:,-2] = maxs[:,-1] # This is the last befre the guess.. so the label is max_g Q(h-L, g)\n",
    "    ll = np.expand_dims(ll,axis=1)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer critic_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(\n",
      "[[[0.91868687 0.91868687 0.91868687 0.91868687 0.91868687]\n",
      "  [0.902943   0.902943   0.902943   0.902943   0.902943  ]\n",
      "  [0.874516   0.874516   0.8746257  0.8753706  0.8757279 ]]\n",
      "\n",
      " [[0.9197762  0.9197762  0.9197762  0.9197762  0.9197762 ]\n",
      "  [0.8991058  0.8991058  0.8991058  0.8991058  0.8991058 ]\n",
      "  [0.87335885 0.87335885 0.8744581  0.8745884  0.8748841 ]]\n",
      "\n",
      " [[0.9186969  0.9186969  0.9186969  0.9186969  0.9186969 ]\n",
      "  [0.8995613  0.8995613  0.8995613  0.8995613  0.8995613 ]\n",
      "  [0.8737294  0.8737294  0.87464744 0.8747986  0.8753229 ]]\n",
      "\n",
      " [[0.91854936 0.91854936 0.91854936 0.91854936 0.91854936]\n",
      "  [0.9021792  0.9021792  0.9021792  0.9021792  0.9021792 ]\n",
      "  [0.8512894  0.8512894  0.8516716  0.85206467 0.8523009 ]]], shape=(4, 3, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.90294302, 0.87572789, 1.        ]],\n",
       "\n",
       "       [[0.89910579, 0.87488413, 1.        ]],\n",
       "\n",
       "       [[0.89956129, 0.87532288, 0.        ]],\n",
       "\n",
       "       [[0.90217918, 0.85230088, 0.        ]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_td_error_Kennedy_guess(critic,bbl,rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,2):\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
