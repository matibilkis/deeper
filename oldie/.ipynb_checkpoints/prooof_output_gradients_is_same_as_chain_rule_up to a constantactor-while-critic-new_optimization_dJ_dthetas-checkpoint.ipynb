{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 535028.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib\n",
    "from environment import Environment\n",
    "from plots import just_plot\n",
    "from misc import *\n",
    "from nets import *\n",
    "from buffer import ReplayBuffer\n",
    "\n",
    "\n",
    "amplitude=0.4\n",
    "tau = 0.1\n",
    "lr_critic = 0.005\n",
    "lr_actor=10**-3\n",
    "noise_displacement = .25\n",
    "ep_guess=0.01\n",
    "dolinar_layers=1\n",
    "number_phases=2\n",
    "buffer_size = 10**7\n",
    "\n",
    "\n",
    "env = Environment(amplitude=amplitude, dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "buffer = ReplayBuffer(buffer_size=buffer_size)\n",
    "\n",
    "critic = Critic(nature=\"primary\",valreg=0.0, dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "critic_target = Critic(nature=\"target\", valreg=0.0,dolinar_layers = dolinar_layers, number_phases=number_phases, tau = tau)\n",
    "actor = Actor(nature=\"primary\",valreg=0.0, dolinar_layers = dolinar_layers)\n",
    "actor_target = Actor(nature=\"target\",valreg=0.0, dolinar_layers = dolinar_layers)\n",
    "\n",
    "optimizer_critic = tf.keras.optimizers.Adam(lr=lr_critic)\n",
    "optimizer_actor = tf.keras.optimizers.SGD(lr=lr_actor)\n",
    "\n",
    "policy_evaluator = PolicyEvaluator(amplitude = amplitude, dolinar_layers=dolinar_layers, number_phases = number_phases)\n",
    "\n",
    "expes = np.load(\"buffers/1L-stoch.npy\")\n",
    "\n",
    "for k in tqdm(expes):\n",
    "    buffer.add(tuple(k))\n",
    "\n",
    "def plot(critic, episode = 1, last_episode=False, max_episode=10**4, history_betas =[]):\n",
    "\n",
    "    betas = np.arange(.1,1.1,.05)\n",
    "    inps = np.stack([np.ones(len(betas))*critic.pad_value, betas], axis=1)\n",
    "    inps = np.reshape(inps, (len(betas),1,2))\n",
    "    ax3.plot(betas, np.squeeze(critic(inps)), alpha=min(episode/max_episode,1), linewidth=5,label=\"RNN - \"+str(episode))\n",
    "\n",
    "    for outcome in [0.,1.]:\n",
    "       for guess_index in [0.,1.]:\n",
    "            m=[]\n",
    "            for k in tf.unstack(inps):\n",
    "                m.append(tf.concat([k, np.reshape(np.array([outcome,guess_index]), (1,2))], axis=0))\n",
    "            axes[str(outcome)].plot(betas, np.squeeze(critic(tf.stack(m, axis=0)))[:,1], alpha=min(episode/max_episode,1), linewidth=5,label=\"RNN\" +str(episode))\n",
    "            \n",
    "            \n",
    "    if last_episode:\n",
    "        betas = np.arange(.1,1.1,.05)\n",
    "        inps = np.stack([np.ones(len(betas))*critic.pad_value, betas], axis=1)\n",
    "        inps = np.reshape(inps, (len(betas),1,2))\n",
    "        ax3.plot(betas, np.squeeze(critic(inps)), linewidth=8,c=\"black\",label=\"RNN\")\n",
    "\n",
    "\n",
    "        for outcome in [0.,1.]:\n",
    "           for guess_index in [0.,1.]:\n",
    "                m=[]\n",
    "                for k in tf.unstack(inps):\n",
    "                    m.append(tf.concat([k, np.reshape(np.array([outcome,guess_index]), (1,2))], axis=0))\n",
    "                axes[str(outcome)].plot(betas, np.squeeze(critic(tf.stack(m, axis=0)))[:,1],c=\"black\", linewidth=8,label=\"RNN\")\n",
    "\n",
    "\n",
    "        ax1.plot(betas,[qval(b, 0, -1) for b in betas],c=\"red\", linewidth=5, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax1.plot(betas,[qval(b, 0, 1) for b in betas],c=\"blue\",  linewidth=5,label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "        ax2.plot(betas,[qval(b, 1, -1) for b in betas],c=\"red\", linewidth=5, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax2.plot(betas,[qval(b, 1, 1) for b in betas],c=\"blue\",  linewidth=5,label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "        ax3.plot(betas,ps_maxlik(betas), '--', linewidth=5, color=\"red\", label=\"P*\")\n",
    "        ax4.plot(np.arange(1,len(history_betas)+1), history_betas, alpha=0.75, c=\"red\", linewidth=7)\n",
    "        for ax in [ax1, ax2, ax3]:\n",
    "            ax.set_xlabel(r'$\\beta$', size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_ev = []\n",
    "history_betas = []\n",
    "total_episodes = 10**3\n",
    "batch_size = 128.           \n",
    "\n",
    "context_outcome_actor = np.reshape(np.array([actor.pad_value]),(1,1,1)).astype(np.float32)\n",
    "history_betas.append(np.squeeze(actor(context_outcome_actor)[0]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(-0.02568209, dtype=float32)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "varactor = actor.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def give_gradients_actions(experiences, actor):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(actor.trainable_variables)\n",
    "        finns = [tf.ones((experiences.shape[0], 1,1))*actor.pad_value]\n",
    "        unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "        for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "            finns.append(tf.reshape(unstacked_exp[index], (experiences.shape[0], 1,1)))\n",
    "        final_preds = tf.concat(finns, axis=1)\n",
    "        finalss = actor(final_preds)\n",
    "    return tape.jacobian(finalss, actor.trainable_variables)\n",
    "\n",
    "def apply_grads_J(da_dtheta1, dq_da, actor, optimizer_actor):\n",
    "    variables = actor.trainable_variables\n",
    "    grad_j=[]\n",
    "    for k in range(len(da_dtheta1)):\n",
    "        onnns = tf.ones(len(tf.shape(da_dtheta1[k]))-1)\n",
    "        multip = tf.reshape(dq_da,tf.cast(tf.concat([tf.Variable([batch_size]),onnns], axis=0), np.int32))*da_dtheta1[k]\n",
    "        multip = tf.reshape(tf.math.reduce_mean(multip, axis=0), variables[k].shape)\n",
    "        grad_j.append(multip)\n",
    "    optimizer_actor.apply_gradients(zip(grad_j, actor.trainable_variables))\n",
    "    return\n",
    "\n",
    "def gradeame_J(experiences, actor, dq_da, optimizer_actor):\n",
    "    gg = give_gradients_actions(experiences, actor)\n",
    "    apply_grads_J(gg, dq_da, actor, optimizer_actor)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   8862\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8863\u001b[0;31m         tld.op_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   8864\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-baf6ceeefe2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradeame_J\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdq_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_actor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-e1a224c970be>\u001b[0m in \u001b[0;36mgradeame_J\u001b[0;34m(experiences, actor, dq_da, optimizer_actor)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgradeame_J\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdq_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_actor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgive_gradients_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mapply_grads_J\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdq_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_actor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e1a224c970be>\u001b[0m in \u001b[0;36mapply_grads_J\u001b[0;34m(da_dtheta1, dq_da, actor, optimizer_actor)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgrad_j\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda_dtheta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0monnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda_dtheta1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmultip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdq_da\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0monnns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mda_dtheta1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmultip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_v2\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m   \"\"\"\n\u001b[0;32m--> 576\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m   \"\"\"\n\u001b[0;32m--> 602\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   8866\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8867\u001b[0m         return shape_eager_fallback(\n\u001b[0;32m-> 8868\u001b[0;31m             input, out_type=out_type, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   8869\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8870\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape_eager_fallback\u001b[0;34m(input, out_type, name, ctx)\u001b[0m\n\u001b[1;32m   8894\u001b[0m     \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8895\u001b[0m   \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8896\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8897\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8898\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[1;32m    261\u001b[0m       ret.append(\n\u001b[1;32m    262\u001b[0m           ops.convert_to_tensor(\n\u001b[0;32m--> 263\u001b[0;31m               t, dtype, preferred_dtype=default_dtype, ctx=ctx))\n\u001b[0m\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                          as_ref=False):\n\u001b[1;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "gradeame_J(experiences, actor, dq_da, optimizer_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Got error while pfor was converting op name: \"loop_body/StatefulPartitionedCall\"\n",
      "op: \"StatefulPartitionedCall\"\n",
      "input: \"loop_body/zeros\"\n",
      "input: \"gradient_tape/actor/dense_8/Tensordot/Reshape_1\"\n",
      "input: \"loop_body/zeros_1\"\n",
      "input: \"loop_body/zeros_2\"\n",
      "input: \"loop_body/zeros_3\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:5\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:6\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:7\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:8\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:9\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:10\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:11\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:12\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:13\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:14\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:15\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:16\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:17\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:18\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:19\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:20\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:21\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:22\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:23\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "      i: 7\n",
      "      i: 8\n",
      "      i: 9\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003GPU\\020\\000\\n\\007\\n\\003CPU\\020\\0012\\002J\\0008\\001\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference___backward_standard_lstm_15201_15514\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "with inputs (<tf.Tensor 'loop_body/zeros:0' shape=(128, 250) dtype=float32>, <tf.Tensor 'gradient_tape/actor/dense_8/Tensordot/Reshape_1:0' shape=(128, 1, 250) dtype=float32>, <tf.Tensor 'loop_body/zeros_1:0' shape=(128, 250) dtype=float32>, <tf.Tensor 'loop_body/zeros_2:0' shape=(128, 250) dtype=float32>, <tf.Tensor 'loop_body/zeros_3:0' shape=() dtype=float32>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:5' shape=(3,) dtype=int32>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:6' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:7' shape=() dtype=resource>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:8' shape=() dtype=resource>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:9' shape=() dtype=resource>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:10' shape=() dtype=int32>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:11' shape=() dtype=int32>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:12' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:13' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:14' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:15' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:16' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:17' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:18' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:19' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:20' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:21' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:22' shape=() dtype=variant>, <tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:23' shape=(3,) dtype=int32>)\n",
      ", converted inputs [WrappedTensor(t=<tf.Tensor 'loop_body/zeros:0' shape=(128, 250) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradient_tape/actor/dense_8/Tensordot/Reshape_1/pfor/Reshape:0' shape=(128, 128, 1, 250) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_1:0' shape=(128, 250) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_2:0' shape=(128, 250) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_3:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:5' shape=(3,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:6' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:7' shape=() dtype=resource>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:8' shape=() dtype=resource>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:9' shape=() dtype=resource>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:10' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:11' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:12' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:13' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:14' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:15' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:16' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:17' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:18' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:19' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:20' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:21' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:22' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'actor/lstm_2/StatefulPartitionedCall:23' shape=(3,) dtype=int32>, is_stacked=False, is_sparse_stacked=False)]\n",
      "in user code:\n",
      "\n",
      "    /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n",
      "        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n",
      "    /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper  **\n",
      "        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n",
      "    /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/platform/flags.py:85 __getattr__\n",
      "        wrapped(_sys.argv)\n",
      "    /home/cooper-cooper/.local/lib/python3.6/site-packages/absl/flags/_flagvalues.py:633 __call__\n",
      "        name, value, suggestions=suggestions)\n",
      "\n",
      "    UnrecognizedFlagError: Unknown command line flag 'f'\n",
      "\n",
      "Here are the pfor conversion stack traces:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:name: \"loop_body/StatefulPartitionedCall\"\n",
      "op: \"StatefulPartitionedCall\"\n",
      "input: \"loop_body/zeros\"\n",
      "input: \"gradient_tape/actor/dense_8/Tensordot/Reshape_1\"\n",
      "input: \"loop_body/zeros_1\"\n",
      "input: \"loop_body/zeros_2\"\n",
      "input: \"loop_body/zeros_3\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:5\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:6\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:7\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:8\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:9\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:10\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:11\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:12\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:13\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:14\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:15\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:16\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:17\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:18\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:19\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:20\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:21\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:22\"\n",
      "input: \"actor/lstm_2/StatefulPartitionedCall:23\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "      i: 7\n",
      "      i: 8\n",
      "      i: 9\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003GPU\\020\\000\\n\\007\\n\\003CPU\\020\\0012\\002J\\0008\\001\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference___backward_standard_lstm_15201_15514\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "created at:\n",
      "    File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "    File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n",
      "    self.io_loop.start()\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "    File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "    File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n",
      "    return runner(coro)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"<ipython-input-6-aa8d74db4b84>\", line 26, in <module>\n",
      "    gradeame_esta(experiences, dq_da, actor, optimizer_actor)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 627, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 506, in _initialize\n",
      "    *args, **kwds))\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2446, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 441, in wrapped_fn\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 964, in wrapper\n",
      "    user_requested=True,\n",
      "    File \"<ipython-input-5-4e9bffdcfaaa>\", line 13, in gradeame_esta\n",
      "    da_dtheta1 = tape.jacobian(final_predss, actor.trainable_variables)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1132, in jacobian\n",
      "    parallel_iterations=parallel_iterations)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 198, in pfor\n",
      "    outputs = f()\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 183, in f\n",
      "    return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 237, in _pfor_impl\n",
      "    loop_fn_outputs = loop_fn(loop_var)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1122, in loop_fn\n",
      "    unconnected_gradients=unconnected_gradients)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1048, in gradient\n",
      "    unconnected_gradients=unconnected_gradients)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\", line 77, in imperative_grad\n",
      "    compat.as_str(unconnected_gradients.value))\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 841, in _backward_function\n",
      "    return self._rewrite_forward_and_call_backward(call_op, *args)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 796, in _rewrite_forward_and_call_backward\n",
      "    cleaned_doutputs, remapped_captures)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1760, in _call_flat\n",
      "    flat_outputs = forward_function.call(ctx, args_with_tangents)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 627, in call\n",
      "    executor_type=executor_type)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 1180, in partitioned_call\n",
      "    op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3258, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 595, in _create_op_internal\n",
      "    compute_device)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3327, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "    File \"/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1791, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    <ipython-input-5-4e9bffdcfaaa>:13 gradeame_esta  *\n        da_dtheta1 = tape.jacobian(final_predss, actor.trainable_variables)\n    /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n    /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper  **\n        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n    /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/platform/flags.py:85 __getattr__\n        wrapped(_sys.argv)\n    /home/cooper-cooper/.local/lib/python3.6/site-packages/absl/flags/_flagvalues.py:633 __call__\n        name, value, suggestions=suggestions)\n\n    UnrecognizedFlagError: Unknown command line flag 'f'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aa8d74db4b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdq_da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic_grad_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mgradeame_esta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdq_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_actor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states_workaround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    <ipython-input-5-4e9bffdcfaaa>:13 gradeame_esta  *\n        da_dtheta1 = tape.jacobian(final_predss, actor.trainable_variables)\n    /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n    /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper  **\n        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n    /home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow/python/platform/flags.py:85 __getattr__\n        wrapped(_sys.argv)\n    /home/cooper-cooper/.local/lib/python3.6/site-packages/absl/flags/_flagvalues.py:633 __call__\n        name, value, suggestions=suggestions)\n\n    UnrecognizedFlagError: Unknown command line flag 'f'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "\n",
    "ax1 = plt.subplot2grid((2,2),(0,0))\n",
    "ax2 = plt.subplot2grid((2,2),(0,1))\n",
    "ax3 = plt.subplot2grid((2,2),(1,0))\n",
    "ax4 = plt.subplot2grid((2,2),(1,1))\n",
    "\n",
    "axes = {\"0.0\":ax1, \"1.0\":ax2}\n",
    "\n",
    "\n",
    "for k in tqdm(range(10**2)):\n",
    "    experiences = buffer.sample(batch_size).astype(np.float32)\n",
    "    samples, zerolabs = critic_target.process_sequence_tf(experiences)\n",
    "    labels_critic = critic_target.give_td_errors_tf( samples, zerolabs)\n",
    "    loss_critic = step_critic_tf(samples ,labels_critic, critic, optimizer_critic)\n",
    "    critic_target.update_target_parameters(critic)\n",
    "    loss_ev.append(loss_critic.numpy())\n",
    "    #### actor ####\n",
    "    \n",
    "    actor.lstm.stateful=False\n",
    "    actor.reset_states_workaround(new_batch_size=int(batch_size))\n",
    "    \n",
    "    dq_da = critic_grad_tf(critic, experiences)\n",
    "\n",
    "    gradeame_esta(experiences, dq_da, actor, optimizer_actor)    \n",
    "    \n",
    "    actor.reset_states_workaround(new_batch_size=1)\n",
    "    actor.lstm.stateful=True\n",
    "\n",
    "    context_outcome_actor = np.reshape(np.array([actor.pad_value]),(1,1,1)).astype(np.float32)\n",
    "    history_betas.append(np.squeeze(actor(context_outcome_actor)[0]))\n",
    "    \n",
    "    if k%int(total_episodes/10)==1:\n",
    "        plot(critic, episode=k, last_episode=False, max_episode = total_episodes)\n",
    "plot(critic, episode=k, last_episode=True, history_betas=history_betas)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let0s analyze critic graddient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dq_da = critic_grad_tf(critic, experiences)\n",
    "actor_grad_tf(actor, dq_da, experiences, optimizer_actor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_grad_tf(critic, experiences):\n",
    "    with tf.GradientTape() as tape:\n",
    "        unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "        to_stack = []\n",
    "        actions_wathed_index = []\n",
    "        for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "            actions_wathed_index.append(index)\n",
    "            to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        actions_indexed = tf.concat(to_stack,axis=1)\n",
    "        tape.watch(actions_indexed)\n",
    "\n",
    "        index_actions=0\n",
    "        watched_exps=[tf.ones((experiences.shape[0],1,1))*critic.pad_value]\n",
    "        watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "        for index in range(0,experiences.shape[-1]-1):\n",
    "            if index in actions_wathed_index:\n",
    "                watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "                index_actions+=1\n",
    "            else:\n",
    "                watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))\n",
    "\n",
    "        dq_da = tape.gradient(qvals, actions_indexed)\n",
    "        #tf.print(\"dq_da mean\", tf.math.reduce_mean(dq_da))\n",
    "        return dq_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_grad_tf(critic, experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = experiences[:5]\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "    to_stack = []\n",
    "    actions_wathed_index = []\n",
    "    for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "        actions_wathed_index.append(index)\n",
    "        to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "    actions_indexed = tf.concat(to_stack,axis=1)\n",
    "    tape.watch(actions_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = experiences[:5]\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "    to_stack = []\n",
    "    actions_wathed_index = []\n",
    "    for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "        actions_wathed_index.append(index)\n",
    "        to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "    actions_indexed = tf.concat(to_stack,axis=1)\n",
    "    tape.watch(actions_indexed)\n",
    "\n",
    "    index_actions=0\n",
    "    watched_exps=[tf.ones((experiences.shape[0],1,1))*critic.pad_value]\n",
    "    watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "    for index in range(0,experiences.shape[-1]-1):\n",
    "        if index in actions_wathed_index:\n",
    "            watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "            index_actions+=1\n",
    "        else:\n",
    "            watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "    qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic(critic.process_sequence(experiences)[0]) - qvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = experiences[:5]\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "    to_stack = []\n",
    "    actions_wathed_index = []\n",
    "    for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "        actions_wathed_index.append(index)\n",
    "        to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "    actions_indexed = tf.concat(to_stack,axis=1)\n",
    "    tape.watch(actions_indexed)\n",
    "\n",
    "    index_actions=0\n",
    "    watched_exps=[tf.ones((experiences.shape[0],1,1))*critic.pad_value]\n",
    "    watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "    for index in range(0,experiences.shape[-1]-1):\n",
    "        if index in actions_wathed_index:\n",
    "            watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "            index_actions+=1\n",
    "        else:\n",
    "            watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "    qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))\n",
    "    dq_da = tape.gradient(qvals, actions_indexed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale, it makes what we want, \\grad_a Q(s,a).\n",
    "\n",
    "Let's look the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.reset_states_workaround(new_batch_size=len(experiences))\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(actor.trainable_variables)\n",
    "    finns = [tf.ones((experiences.shape[0], 1,1))*actor.pad_value]\n",
    "    unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "    for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "        finns.append(tf.reshape(unstacked_exp[index], (experiences.shape[0], 1,1)))\n",
    "    final_preds = tf.concat(finns, axis=1)\n",
    "    final_predss = actor(final_preds)\n",
    "    \n",
    "da_dtheta1 = tape.jacobian(final_predss, actor.trainable_variables)\n",
    "    \n",
    "variables = actor.trainable_variables\n",
    "grad_j=[]\n",
    "for k in range(len(da_dtheta1)):\n",
    "    onnns = tf.ones(len(tf.shape(da_dtheta1[k]))-1)\n",
    "    multip = tf.reshape(dq_da,tf.cast(tf.concat([tf.Variable([batch_size]),onnns], axis=0), np.int32))*da_dtheta1[k]\n",
    "    multip = tf.reshape(tf.math.reduce_mean(multip, axis=0), variables[k].shape)\n",
    "    grad_j.append(multip)\n",
    "optimizer_actor.apply_gradients(zip(grad_j, actor.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in da_dtheta1:\n",
    "    print(k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_actor.apply_gradients(zip(grad_j, actor.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo junto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.reset_states_workaround(new_batch_size=1)\n",
    "actor(context_outcome_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
