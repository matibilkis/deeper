{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import *\n",
    "import tensorflow as tf \n",
    "import misc\n",
    "from buffer import ReplayBuffer\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from misc import Prob, ps_maxlik, qval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:00<00:00, 532651.29it/s]\n"
     ]
    }
   ],
   "source": [
    "critic = Critic(nature=\"primary\", dolinar_layers = 1)\n",
    "critic_target = Critic(nature=\"target\", dolinar_layers = 1, tau=0.01)\n",
    "optimizer_critic = tf.keras.optimizers.Adam(lr=0.01)\n",
    "experiences = np.load(\"buffers/2L_probs-0-2.npy\")\n",
    "buffer = ReplayBuffer(buffer_size=10**7)\n",
    "for k in tqdm(experiences):\n",
    "    buffer.add(tuple(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 10**4\n",
    "evolution_loss=[]\n",
    "history_predictions={\"final_episode_info\":total_episodes}\n",
    "bbbs = np.arange(0,2.05,.05)\n",
    "inps = np.stack([np.ones(len(bbbs))*critic.pad_value, bbbs], axis=1)\n",
    "inps = np.reshape(inps, (len(bbbs),1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in tqdm(range(total_episodes)):\n",
    "\n",
    "    sampled_dataset = buffer.sample(128).astype(np.float32)\n",
    "    batched_sampled_dataset, rews_per_layer = critic.process_sequence_tf(sampled_dataset)\n",
    "    td_errors = critic_target.give_td_errors_tf(batched_sampled_dataset, rews_per_layer)\n",
    "    loss = critic.step_critic_tf(batched_sampled_dataset, td_errors, optimizer_critic)\n",
    "    evolution_loss.append(loss.numpy())\n",
    "    critic_target.update_target_parameters(critic)\n",
    "#     if iteration%(int(total_episodes/5)) == 0:\n",
    "#         history_predictions[str(iteration)] = {\"[]\":[], \"00\":[],\"01\":[],\"11\":[],\"10\":[]}\n",
    "#         history_predictions[str(iteration)][\"[]\"] = np.squeeze(critic(inps))\n",
    "#         for outcome in [0.,1.]:\n",
    "#            for guess_index in [0.,1.]:\n",
    "#                 m=[]\n",
    "#                 for k in tf.unstack(inps):\n",
    "#                     m.append(tf.concat([k, np.reshape(np.array([outcome,guess_index]), (1,2))], axis=0))\n",
    "#                 history_predictions[str(iteration)][str(outcome)+str(guess_index)] = np.squeeze(critic(tf.stack(m, axis=0)))[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
