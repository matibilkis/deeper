{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib\n",
    "from environment import Environment\n",
    "from plots import just_plot\n",
    "from misc import *\n",
    "from nets import *\n",
    "from buffer import ReplayBuffer\n",
    "import timeit\n",
    "\n",
    "amplitude=0.4\n",
    "dolinar_layers=2\n",
    "number_phases=2\n",
    "total_episodes = 10**3\n",
    "buffer_size=500\n",
    "batch_size=64\n",
    "ep_guess=0.01\n",
    "noise_displacement=0.5\n",
    "lr_actor=0.01\n",
    "lr_critic=0.001\n",
    "tau=0.005\n",
    "\n",
    "\n",
    "exper = np.load(\"example_buffer/2_sample.npy\")\n",
    "env = Environment(amplitude=amplitude, dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "# buffer = ReplayBuffer(buffer_size=buffer_size)\n",
    "\n",
    "critic = Critic(nature=\"primary\",valreg=0.01, dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "critic_target = Critic(nature=\"target\", dolinar_layers = dolinar_layers, number_phases=number_phases)\n",
    "actor = Actor(nature=\"primary\", dolinar_layers = dolinar_layers)\n",
    "actor_target = Actor(nature=\"target\", dolinar_layers = dolinar_layers)\n",
    "\n",
    "optimizer_critic = tf.keras.optimizers.Adam(lr=lr_critic)\n",
    "optimizer_actor = tf.keras.optimizers.Adam(lr=lr_actor)\n",
    "\n",
    "policy_evaluator = PolicyEvaluator(amplitude = amplitude, dolinar_layers=dolinar_layers, number_phases = number_phases)\n",
    "\n",
    "#\n",
    "experiences = exper.astype(np.float32)\n",
    "targeted_experience = actor_target.process_sequence_of_experiences_tf(experiences)\n",
    "sequences, zeroed_rews = critic_target.process_sequence_tf(targeted_experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def give_td_error_Kennedy_guess_tf(critic,sequences,zeroed_rews):\n",
    "    if critic.nature != \"target\":\n",
    "        raise AttributeError(\"I'm not the target!\")\n",
    "\n",
    "    final_rews = tf.reshape(zeroed_rews[:,-1], (sequences.shape[0],1,1))\n",
    "    bellman_tds_noguess = critic(sequences)[:,1:-1,:]\n",
    "\n",
    "    phases = tf.range(critic.number_phases, dtype=np.float32)/critic.number_phases\n",
    "\n",
    "    unstacked = tf.unstack(tf.convert_to_tensor(sequences))\n",
    "    phases_concs = {}\n",
    "    for ph in range(critic.number_phases):\n",
    "        phases_concs[str(ph)] = []\n",
    "    stacked = {}\n",
    "\n",
    "    for episode in unstacked:\n",
    "        prefinal = episode[:-1]\n",
    "        for ph in range(critic.number_phases):\n",
    "            final = tf.expand_dims(tf.stack([tf.unstack(episode[-1])[0], phases[ph]], axis=0), axis=0)\n",
    "            phases_concs[str(ph)].append(tf.concat([prefinal, final], axis=0))\n",
    "    #\n",
    "        for ph in range(critic.number_phases):\n",
    "            stacked[str(ph)] = tf.stack(phases_concs[str(ph)], axis=0)\n",
    "\n",
    "    all_preds = tf.concat([critic(stacked[str(ph)]) for ph in range(critic.number_phases)], axis=2)\n",
    "    maxs = tf.math.reduce_max(all_preds,axis=2)[:,-1]\n",
    "    bellman_td = tf.concat([tf.reshape(bellman_tds_noguess,(sequences.shape[0],critic.dolinar_layers-1)), tf.reshape(maxs,(sequences.shape[0],1))], axis=1)\n",
    "    return tf.concat([bellman_td, tf.reshape(zeroed_rews[:,-1], (sequences.shape[0],1))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_td_error_Kennedy_guess(critic,sequences,zeroed_rews):\n",
    "    if critic.nature != \"target\":\n",
    "        raise AttributeError(\"I'm not the target!\")\n",
    "\n",
    "    final_rews = tf.reshape(zeroed_rews[:,-1], (sequences.shape[0],1,1))\n",
    "    bellman_tds_noguess = critic(sequences)[:,1:-1,:]\n",
    "\n",
    "    phases = tf.range(critic.number_phases, dtype=np.float32)/critic.number_phases\n",
    "\n",
    "    unstacked = tf.unstack(tf.convert_to_tensor(sequences))\n",
    "    phases_concs = {}\n",
    "    for ph in range(critic.number_phases):\n",
    "        phases_concs[str(ph)] = []\n",
    "    stacked = {}\n",
    "\n",
    "    for episode in unstacked:\n",
    "        prefinal = episode[:-1]\n",
    "        for ph in range(critic.number_phases):\n",
    "            final = tf.expand_dims(tf.stack([tf.unstack(episode[-1])[0], phases[ph]], axis=0), axis=0)\n",
    "            phases_concs[str(ph)].append(tf.concat([prefinal, final], axis=0))\n",
    "    #\n",
    "        for ph in range(critic.number_phases):\n",
    "            stacked[str(ph)] = tf.stack(phases_concs[str(ph)], axis=0)\n",
    "\n",
    "    all_preds = tf.concat([critic(stacked[str(ph)]) for ph in range(critic.number_phases)], axis=2)\n",
    "    maxs = tf.math.reduce_max(all_preds,axis=2)[:,-1]\n",
    "    bellman_td = tf.concat([tf.reshape(bellman_tds_noguess,(sequences.shape[0],critic.dolinar_layers-1)), tf.reshape(maxs,(sequences.shape[0],1))], axis=1)\n",
    "    return tf.concat([bellman_td, tf.reshape(zeroed_rews[:,-1], (sequences.shape[0],1))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.41 ms ± 608 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit give_td_error_Kennedy_guess_tf(critic_target,sequences,zeroed_rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.3 ms ± 1.46 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit give_td_error_Kennedy_guess(critic_target,sequences,zeroed_rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_critic = give_td_error_Kennedy_guess_tf(critic_target,sequences,zeroed_rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def step_critic_tf(labels_critic, critic):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(critic.trainable_variables)\n",
    "        preds_critic = critic(sequences)\n",
    "        loss_critic = tf.keras.losses.MSE(labels_critic, preds_critic)\n",
    "        loss_critic = tf.reduce_mean(loss_critic)\n",
    "        grads = tape.gradient(loss_critic, critic.trainable_variables)\n",
    "        optimizer_critic.apply_gradients(zip(grads, critic.trainable_variables))\n",
    "        return tf.squeeze(loss_critic)\n",
    "    \n",
    "def step_critic(labels_critic, critic):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(critic.trainable_variables)\n",
    "        preds_critic = critic(sequences)\n",
    "        loss_critic = tf.keras.losses.MSE(labels_critic, preds_critic)\n",
    "        loss_critic = tf.reduce_mean(loss_critic)\n",
    "        grads = tape.gradient(loss_critic, critic.trainable_variables)\n",
    "        optimizer_critic.apply_gradients(zip(grads, critic.trainable_variables))\n",
    "        return tf.squeeze(loss_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.4 ms ± 1.47 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit step_critic(tf.expand_dims(labels_critic, axis=2), critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.2 ms ± 937 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit step_critic_tf(tf.expand_dims(labels_critic, axis=2), critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03453873,  0.        , -0.33991995,  0.        ,  0.        ],\n",
       "       [-0.25866753,  0.        , -0.19607863,  0.        ,  0.5       ],\n",
       "       [-0.24178177,  0.        ,  0.09374991,  0.        ,  0.5       ],\n",
       "       [-0.2672065 ,  0.        ,  0.04338924,  0.        ,  0.        ],\n",
       "       [-0.1888024 ,  0.        , -0.11296402,  0.        ,  0.5       ],\n",
       "       [-0.0119067 ,  0.        ,  0.10449888,  0.        ,  0.        ],\n",
       "       [ 0.0838516 ,  0.        , -0.223578  ,  0.        ,  0.        ],\n",
       "       [ 0.09396052,  0.        , -0.00805294,  0.        ,  0.5       ],\n",
       "       [-0.18203147,  0.        , -0.11425584,  0.        ,  0.        ],\n",
       "       [-0.2001634 ,  0.        ,  0.02064468,  0.        ,  0.        ],\n",
       "       [-0.27773562,  0.        ,  0.05043116,  0.        ,  0.        ],\n",
       "       [-0.06698474,  0.        , -0.2857382 ,  0.        ,  0.        ],\n",
       "       [-0.29122508,  1.        , -0.16833827,  1.        ,  0.5       ],\n",
       "       [-0.02650449,  0.        , -0.38040155,  1.        ,  0.5       ],\n",
       "       [-0.36419973,  0.        , -0.17870723,  0.        ,  0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def process_sequence_of_experiences_tf(self, experiences):\n",
    "    self.lstm.stateful=True\n",
    "\n",
    "    unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "    to_stack = []\n",
    "    for index in range(2*self.dolinar_layers-1): # I consider from first outcome to last one (but guess)\n",
    "        if (index==0):\n",
    "            to_stack.append(unstacked_exp[index])\n",
    "        if (index%2 == 1):\n",
    "            to_stack.append(unstacked_exp[index])\n",
    "\n",
    "            to_stack.append(tf.squeeze(self(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))))\n",
    "    for index in range(2*self.dolinar_layers-1, 2*self.dolinar_layers+2):\n",
    "        to_stack.append(unstacked_exp[index])\n",
    "    self.lstm.stateful=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def critic_derivative(experiences, actor, critic):\n",
    "    actions_indexed = [0.]*(actor.dolinar_layers)\n",
    " \n",
    "    with tf.GradientTape() as tape:\n",
    "        unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "        to_stack = []\n",
    "        actions_wathed_index = []\n",
    "        for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "            actions_wathed_index.append(index)\n",
    "            to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "   \n",
    "        actions_indexed = tf.concat(to_stack,axis=1)\n",
    "    tape.watch(actions_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked_watched = tf.unstack(actions_indexed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def critic_grad(critic, experiences):\n",
    "    with tf.GradientTape() as tape:\n",
    "        unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "        to_stack = []\n",
    "        actions_wathed_index = []\n",
    "        for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "            actions_wathed_index.append(index)\n",
    "            to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        actions_indexed = tf.concat(to_stack,axis=1)\n",
    "        tape.watch(actions_indexed)\n",
    "\n",
    "\n",
    "        index_actions=0\n",
    "        watched_exps=[tf.ones((experiences.shape[0],1,1))*actor.pad_value]\n",
    "        watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "        for index in range(0,experiences.shape[-1]-1): \n",
    "            if index in actions_wathed_index:\n",
    "                watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "                index_actions+=1\n",
    "            else:\n",
    "                watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))\n",
    "\n",
    "        dq_da = tape.gradient(qvals, actions_indexed)\n",
    "        return dq_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "        ### now prepare the state acions to put them into the critic###\n",
    "        padded_data = [tf.ones((experiences.shape[0],1))*actor.pad_value]\n",
    "        watched_input_critic  = padded_data.copy()\n",
    "        ind_actions=0\n",
    "        for ind,k in enumerate(tf.unstack(tf.convert_to_tensor(experiences[:,:-1]),axis=1)):\n",
    "            if (ind%2==0)&(ind < 2*actor.dolinar_layers):\n",
    "                padded_data.append(actions_indexed[:,ind_actions]) ### i add the input of the critic the watched actions!\n",
    "                ind_actions+=1\n",
    "            else:\n",
    "                padded_data.append(tf.expand_dims(k, axis=1))\n",
    "            if ind == 0:\n",
    "                watched_input_critic = tf.stack([padded_data[0], padded_data[1]], axis=2) #importantly i put the padd first (state_action.)\n",
    "            if (ind%2 == 0)&(ind!=0):\n",
    "                intermediate = tf.stack([padded_data[ind], padded_data[ind+1]], axis=2)\n",
    "                watched_input_critic = tf.concat([watched_input_critic, intermediate], axis=1)\n",
    "\n",
    "        qvals = critic(watched_input_critic)\n",
    "        dq_da = tape.gradient(qvals, actions_indexed)\n",
    "    return dq_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.7 ms ± 1.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit critic_grad(critic, experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def critic_grad_tf(critic, experiences):\n",
    "    with tf.GradientTape() as tape:\n",
    "        unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "        to_stack = []\n",
    "        actions_wathed_index = []\n",
    "        for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "            actions_wathed_index.append(index)\n",
    "            to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        actions_indexed = tf.concat(to_stack,axis=1)\n",
    "        tape.watch(actions_indexed)\n",
    "\n",
    "\n",
    "        index_actions=0\n",
    "        watched_exps=[tf.ones((experiences.shape[0],1,1))*actor.pad_value]\n",
    "        watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "        for index in range(0,experiences.shape[-1]-1): \n",
    "            if index in actions_wathed_index:\n",
    "                watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "                index_actions+=1\n",
    "            else:\n",
    "                \n",
    "                watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))\n",
    "\n",
    "        dq_da = tape.gradient(qvals, actions_indexed)\n",
    "        return dq_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.76 ms ± 414 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit critic_grad_tf(critic, experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(actor.trainable_variables)\n",
    "    pads = np.ones(len(experiences)).astype(np.float32)*actor.pad_value\n",
    "    news = np.random.rand(experiences.shape[0], experiences.shape[1]+1).astype(np.float32)\n",
    "    news[:,1:] = experiences\n",
    "    news[:,0] = pads\n",
    "    instances_actor = [i for i in range(0,2*actor.dolinar_layers,2)]\n",
    "    actionss = actor(np.reshape(news[:,instances_actor], (experiences.shape[0],actor.dolinar_layers,1)).astype(np.float32))\n",
    "    da_dtheta = tape.gradient(actionss, actor.trainable_variables, output_gradients=-dq_da)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def actor_grad(actor, dq_da, experiences, optimizer_actor):\n",
    "    with tf.GradientTape() as tape:\n",
    "        unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "        states_to_act=[tf.ones((experiences.shape[0],1,1))*actor.pad_value]\n",
    "\n",
    "        to_stack = [] \n",
    "        actions_wathed_index = []\n",
    "        for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "            states_to_act.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        actor_thinks = actor(tf.concat(states_to_act, axis=1))\n",
    "        da_dtheta = tape.gradient(actor_thinks, actor.trainable_variables, output_gradients=-dq_da)\n",
    "        optimizer_actor.apply_gradients(zip(da_dtheta, actor.trainable_variables))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.8 ms ± 1.59 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit actor_grad(actor, dq_da, experiences, optimizer_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def actor_grad_tf(actor, dq_da, experiences, optimizer_actor):\n",
    "    with tf.GradientTape() as tape:\n",
    "        unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "        states_to_act=[tf.ones((experiences.shape[0],1,1))*actor.pad_value]\n",
    "\n",
    "        to_stack = [] \n",
    "        actions_wathed_index = []\n",
    "        for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "            states_to_act.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        actor_thinks = actor(tf.concat(states_to_act, axis=1))\n",
    "        da_dtheta = tape.gradient(actor_thinks, actor.trainable_variables, output_gradients=-dq_da)\n",
    "        optimizer_actor.apply_gradients(zip(da_dtheta, actor.trainable_variables))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.3 ms ± 1.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit actor_grad_tf(actor, dq_da, experiences, optimizer_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def give_favourite_guess(critic,hL):\n",
    "    \"\"\"\n",
    "    hL is history (a_0, o1, a_1 ,... o_L)\n",
    "\n",
    "    outputs: index of the guessed phase, as to be input in env.give_reward, input_network_guess which is this index\n",
    "    divided by number_phases (clipped input of the network) ///is this relevant/important? ///\n",
    "\n",
    "    \"\"\"\n",
    "    rr = np.random.randn(critic.number_phases,2*critic.dolinar_layers+1)\n",
    "    rr[:,:-1] = hL\n",
    "    rr[:,-1] = np.arange(critic.number_phases)/critic.number_phases #just to keep the value in [0,1], don't know if it's important\n",
    "    batched_all_guesses = np.reshape(rr[:,[-2,-1]],(critic.number_phases, 1, 2))\n",
    "    predsq = critic(batched_all_guesses)\n",
    "    guess = np.squeeze(tf.argmax(predsq, axis=0))\n",
    "    input_netork_guess = guess/critic.number_phases\n",
    "    return guess, input_netork_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03453873  0.         -0.33991995  0.        ]\n",
      "(2, 5)\n",
      "[[ 0.96573334  1.01835113 -0.91168154  0.01426141]\n",
      " [ 1.47215528  0.08182511 -2.42702058 -1.47019343]]\n",
      "WARNING:tensorflow:Layer critic_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(1), 0.5)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_favourite_guess(critic,experiences[0][:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hL = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.81085874,  0.28084616, -0.44515616,  1.18289177,  0.66911348],\n",
       "       [-0.88281727, -1.83059495, -0.12088185,  1.75615889, -2.37419247]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr = np.random.randn(critic.number_phases,2*critic.dolinar_layers+1)\n",
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03453873,  0.        , -0.33991995,  0.        ,  0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiences[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
