{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self,nature, valreg=0.01, seed_val=0.3, pad_value=-7., dolinar_layers=2, tau=0.01):\n",
    "        '''\n",
    "        dolinar_layers= number of photodetections\n",
    "        pad_value: value not considered by the lstm\n",
    "        valreg: regularisation value\n",
    "        seed_val: interval of random parameter inizialitaion.\n",
    "        '''\n",
    "        super(Critic,self).__init__()\n",
    "\n",
    "        self.pad_value = pad_value\n",
    "        self.nature = nature\n",
    "        self.dolinar_layers = dolinar_layers\n",
    "        self.mask = tf.keras.layers.Masking(mask_value=pad_value,\n",
    "                                  input_shape=(self.dolinar_layers, 2)) #(beta1, pad), (n1, beta2), (n2, guess). In general i will have (layer+1)\n",
    "        self.lstm = tf.keras.layers.LSTM(500, return_sequences=True)\n",
    "\n",
    "        self.tau = tau\n",
    "        self.l1 = Dense(250,kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg))\n",
    "\n",
    "        self.l2 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l3 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l4 = Dense(1, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "\n",
    "\n",
    "    def update_target_parameters(self,primary_net):\n",
    "        #### only\n",
    "        # for i,j in zip(self.get_weights(), primary_net.get_weights()):\n",
    "        #     tf.assign(i, tau*j + (i-tau)*i )\n",
    "        prim_weights = primary_net.get_weights()\n",
    "        targ_weights = self.get_weights()\n",
    "        weights = []\n",
    "        for i in tf.range(len(prim_weights)):\n",
    "            weights.append(self.tau * prim_weights[i] + (1 - self.tau) * targ_weights[i])\n",
    "        self.set_weights(weights)\n",
    "        return\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feat = self.mask(inputs)\n",
    "        feat= self.lstm(feat)\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l1(feat))\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        feat = tf.nn.relu(self.l3(feat))\n",
    "        feat = tf.nn.sigmoid(self.l4(feat))\n",
    "        return feat\n",
    "\n",
    "\n",
    "    def process_sequence(self,sample_buffer):\n",
    "        \"\"\"\"\n",
    "        sample_buffer: array of shape (N,2*self.layers +1), N>1 (+1 for the reward)\n",
    "\n",
    "        gets data obtained from N experiments: data.shape = (N, 2L+1),\n",
    "        where +1 accounts for the guess and 2L for (beta, outcome).\n",
    "\n",
    "        [[a0, o1, a1, o2, a2, o3, a4]\n",
    "         [same but other experiment]\n",
    "        ]\n",
    "\n",
    "        and returns an array of shape (experiments, self.layers, 2 ), as accepted by an RNN\n",
    "        \"\"\"\n",
    "        rr = np.ones(experiences.shape)*self.pad_value\n",
    "        rr[:,1:] = experiences[:,:-1]\n",
    "        rr = np.reshape(rr, (experiences.shape[0],self.dolinar_layers+1,2))\n",
    "        #padded_data[:,selff.dolinar_layers] = data[:,[selff.dolinar_layers+1, selff.dolinar_layers+2]]\n",
    "        rewards_obtained = np.zeros((experiences.shape[0], self.dolinar_layers+1))\n",
    "        rewards_obtained[:,-1] = sample_buffer[:,-1]\n",
    "        return rr, rewards_obtained\n",
    "\n",
    "\n",
    "    def pad_single_sequence(self, seq):\n",
    "        \"\"\"\"\n",
    "        input: [a0, o1, a1, o2, a2, o3, a4]\n",
    "\n",
    "        output: [[a0, pad], [o1, a1], [...]]\n",
    "\n",
    "        the cool thing is that then you can put this to predict the greedy guess/action.\n",
    "        \"\"\"\n",
    "        padded_data = np.ones((1,self.dolinar_layers+1, 2))*self.pad_value\n",
    "        padded_data[0][0][0] = seq[0]\n",
    "        #padded_data[0][0] = data[0]\n",
    "        for k in range(1,self.dolinar_layers+1):\n",
    "            padded_data[0][k] = seq[k:(k+2)]\n",
    "        return padded_data\n",
    "\n",
    "    def give_td_error_Kennedy_guess(self,batched_input,sequential_rews_with_zeros):\n",
    "        # this function takes as input the actions as given by the target actor (but the first one!)\n",
    "        #and outpus the correspoindg TD-errors for DDPG! To obtain them from sample of buffer\n",
    "        #you call the method targeted_sequence from the actor_target and then the process_sequence\n",
    "        #of this critic network.\n",
    "        if self.nature != \"target\":\n",
    "            raise AttributeError(\"I'm not the target!\")\n",
    "            return\n",
    "        b = batched_input.copy()\n",
    "        ll = sequential_rews_with_zeros.copy()\n",
    "        for k in range(self.dolinar_layers):\n",
    "            ll[:,k] = np.squeeze(self(b))[:,k+1] + ll[:,k]\n",
    "\n",
    "        preds1 = self(b)\n",
    "        b[:,-1][:,-1] = -b[:,1][:,1]\n",
    "        preds2 = self(b)\n",
    "        both = tf.concat([preds1,preds2],2)\n",
    "        maxs = np.squeeze(tf.math.reduce_max(both,axis=2).numpy())\n",
    "        ll[:,-2] = maxs[:,-1] # This is the last befre the guess.. so the label is max_g Q(h-L, g)\n",
    "        ll = np.expand_dims(ll,axis=1)\n",
    "        return ll\n",
    "\n",
    "\n",
    "    def give_favourite_guess(self,sequence_with_plus):\n",
    "        \"\"\"\"\n",
    "            important !! the 1!\n",
    "        sequence should be [[beta, pad], [outcome, 1]] \"\"\"\n",
    "        pred_1 = self(sequence_with_plus)\n",
    "        sequence_with_plus[:,1][:,1] = -sequence_with_plus[:,1][:,1]\n",
    "        pred_2 = self(sequence_with_plus)\n",
    "        both = tf.concat([pred_1,pred_2],2)\n",
    "        maxs = np.squeeze(tf.argmax(both,axis=2).numpy())[1]\n",
    "\n",
    "        guess = (-1)**maxs\n",
    "        return  guess\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### ACTOR CLASSS ####\n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, nature, valreg=0.01, seed_val=0.1, pad_value = -7.,\n",
    "                 dolinar_layers=2,tau=0.01):\n",
    "        super(Actor,self).__init__()\n",
    "        self.dolinar_layers = dolinar_layers\n",
    "        self.pad_value = pad_value\n",
    "        self.nature = nature\n",
    "        self.tau = tau\n",
    "\n",
    "        if nature == \"primary\":\n",
    "            self.lstm = tf.keras.layers.LSTM(500, return_sequences=True, stateful=True)\n",
    "            self.mask = tf.keras.layers.Masking(mask_value=pad_value,\n",
    "                                  input_shape=(1,1))#CHECK\n",
    "        elif nature == \"target\":\n",
    "            self.lstm = tf.keras.layers.LSTM(500, return_sequences=True, stateful=False)\n",
    "            self.mask = tf.keras.layers.Masking(mask_value=pad_value,\n",
    "                                  input_shape=(self.dolinar_layers, 1)) #'cause i feed altoghether.\n",
    "        else:\n",
    "            print(\"Hey! the character is either primary or target\")\n",
    "        self.l1 = Dense(250,kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg), dtype='float32')\n",
    "\n",
    "        self.l2 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val), dtype='float32')\n",
    "\n",
    "        self.l3 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val), dtype='float32')\n",
    "\n",
    "        self.l4 = Dense(1, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val), dtype='float32')\n",
    "\n",
    "\n",
    "\n",
    "    def update_target_parameters(self,primary_net):\n",
    "        #### only\n",
    "        # for i,j in zip(self.get_weights(), primary_net.get_weights()):\n",
    "        #     tf.assign(i, tau*j + (i-tau)*i )\n",
    "        prim_weights = primary_net.get_weights()\n",
    "        targ_weights = self.get_weights()\n",
    "        weights = []\n",
    "        for i in tf.range(len(prim_weights)):\n",
    "            weights.append(self.tau * prim_weights[i] + (1 - self.tau) * targ_weights[i])\n",
    "        self.set_weights(weights)\n",
    "        return\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feat = self.mask(inputs)\n",
    "        feat= self.lstm(feat)\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l1(feat))\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        feat = tf.nn.relu(self.l3(feat))\n",
    "        feat = tf.nn.sigmoid(self.l4(feat))\n",
    "\n",
    "        return feat\n",
    "\n",
    "    def process_sequence_of_experiences(self, experiences):\n",
    "\n",
    "        export = experiences.copy()\n",
    "        for index in range(1,2*self.dolinar_layers-1,2): # I consider from first outcome to last one (but guess)\n",
    "            export[:,index+1] = np.squeeze(self(np.reshape(np.array(export[:,index]),\n",
    "                                                                 (experiences.shape[0],1,1))))\n",
    "        return export\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_step(experiences, critic, critic_target, actor, actor_target, optimizer_critic, optimizer_actor):\n",
    "    experiences = experiences.astype(np.float32)\n",
    "    targeted_experience = actor_target.process_sequence_of_experiences(experiences)\n",
    "    sequences, zeroed_rews = critic_target.process_sequence(targeted_experience)\n",
    "    labels_critic = critic_target.give_td_error_Kennedy_guess( sequences, zeroed_rews)\n",
    "    #\n",
    "    ###### train the critic ######\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(critic.trainable_variables)\n",
    "        preds_critic = critic(sequences)\n",
    "        loss_critic = tf.keras.losses.MSE(labels_critic, preds_critic)\n",
    "        loss_critic = tf.reduce_mean(loss_critic)\n",
    "        grads = tape.gradient(loss_critic, critic.trainable_variables)\n",
    "        optimizer_critic.apply_gradients(zip(grads, critic.trainable_variables))\n",
    "        loss_critic = np.squeeze(loss_critic.numpy())\n",
    "    #\n",
    "    #\n",
    "    actor.lstm.reset_states()\n",
    "    actor.lstm.stateful=False ### this is because the mask has trouble with differing the batch_size\n",
    "\n",
    "    actions_indexed = [0.]*(actor.dolinar_layers)\n",
    "    with tf.GradientTape() as tape:\n",
    "        ##### get the actions only ######\n",
    "        actions_with_outcomes = experiences.copy()\n",
    "        act_ind=0\n",
    "        for ind in range(len(experiences)): #experiences.shape[0] = 2L +2\n",
    "            if (ind%2 == 0)&(ind < 2*actor.dolinar_layers):\n",
    "                ac = tf.convert_to_tensor(np.reshape(experiences[:,ind], (len(experiences),1,1)))\n",
    "                actions_indexed[act_ind] = ac\n",
    "                act_ind+=1\n",
    "        actions_indexed = tf.concat(actions_indexed,axis=1)\n",
    "        tape.watch(actions_indexed) ####watch the ations\n",
    "\n",
    "        ### now prepare the state acions to put them into the critic###\n",
    "        padded_data = [tf.ones((experiences.shape[0],1))*actor.pad_value]\n",
    "        watched_input_critic  = padded_data.copy()\n",
    "        ind_actions=0\n",
    "        for ind,k in enumerate(tf.unstack(tf.convert_to_tensor(experiences[:,:-1]),axis=1)):\n",
    "            if (ind%2==0)&(ind < 2*actor.dolinar_layers):\n",
    "                padded_data.append(actions_indexed[:,ind_actions]) ### i add the input of the critic the watched actions!\n",
    "                ind_actions+=1\n",
    "            else:\n",
    "                padded_data.append(tf.expand_dims(k, axis=1))\n",
    "            if ind == 0:\n",
    "                watched_input_critic = tf.stack([padded_data[0], padded_data[1]], axis=2) #importantly i put the padd first (state_action.)\n",
    "            if (ind%2 == 0)&(ind!=0):\n",
    "                intermediate = tf.stack([padded_data[ind], padded_data[ind+1]], axis=2)\n",
    "                watched_input_critic = tf.concat([watched_input_critic, intermediate], axis=1)\n",
    "\n",
    "        qvals = critic(watched_input_critic)\n",
    "        dq_da = tape.gradient(qvals, actions_indexed)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        pads = np.ones(len(experiences)).astype(np.float32)*actor.pad_value\n",
    "        news = np.random.rand(experiences.shape[0], experiences.shape[1]+1).astype(np.float32)\n",
    "        news[:,1:] = experiences\n",
    "        news[:,0] = pads\n",
    "        instances_actor = [i for i in range(0,2*actor.dolinar_layers,2)]\n",
    "        actionss = actor(np.reshape(news[:,instances_actor], (experiences.shape[0],actor.dolinar_layers,1)).astype(np.float32))\n",
    "\n",
    "        da_dtheta = tape.gradient(actionss, actor.trainable_variables, output_gradients=-dq_da)\n",
    "\n",
    "    #\n",
    "    optimizer_actor.apply_gradients(zip(da_dtheta, actor.trainable_variables))\n",
    "    actor.lstm.stateful=True\n",
    "    return loss_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 0.4\n",
    "lr_critic = lr_actor = 0.01\n",
    "\n",
    "critic = Critic(nature=\"primary\",valreg=0.01)\n",
    "critic_target = Critic(nature=\"target\")\n",
    "actor = Actor(nature=\"primary\")\n",
    "actor_target = Actor(nature=\"target\")\n",
    "\n",
    "optimizer_critic = tf.keras.optimizers.Adam(lr=lr_critic)\n",
    "optimizer_actor = tf.keras.optimizers.Adam(lr=lr_actor) #0.001 works well\n",
    "\n",
    "experiences = np.load(\"expe_2L.npy\")\n",
    "\n",
    "input_actor = np.reshape(np.array([actor.pad_value]),(1,1,1))\n",
    "beta_would_do = np.squeeze(actor(input_actor))\n",
    "    \n",
    "#new_loss = optimization_step(experiences,critic, critic_target, actor, actor_target, optimizer_critic, optimizer_actor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69102163,  0.        ,  0.83695079,  0.        , -1.        ,\n",
       "         1.        ],\n",
       "       [ 0.98145692,  0.        ,  0.04985608,  0.        , -1.        ,\n",
       "         1.        ],\n",
       "       [ 0.69588898,  0.        ,  0.30091034,  0.        ,  1.        ,\n",
       "         0.        ],\n",
       "       [ 0.65480695,  0.        ,  0.72952473,  1.        , -1.        ,\n",
       "         0.        ],\n",
       "       [ 0.07486903,  0.        ,  0.39324444,  1.        ,  1.        ,\n",
       "         1.        ]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiences = experiences[:5]\n",
    "experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer actor_39 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiences = experiences.astype(np.float32)\n",
    "experiences = experiences[:5]\n",
    "targeted_experience = actor_target.process_sequence_of_experiences(experiences)\n",
    "sequences, zeroed_rews = critic_target.process_sequence(targeted_experience)\n",
    "labels_critic = critic_target.give_td_error_Kennedy_guess( sequences, zeroed_rews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "targeted_experience = $(a^{target}_0, o_1, a^{target}_1, o_2, guess^{(targ = prim)}, reward)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6910216 ,  0.        ,  0.5089872 ,  0.        , -1.        ,\n",
       "         1.        ],\n",
       "       [ 0.98145694,  0.        ,  0.5089872 ,  0.        , -1.        ,\n",
       "         1.        ],\n",
       "       [ 0.695889  ,  0.        ,  0.5089872 ,  0.        ,  1.        ,\n",
       "         0.        ],\n",
       "       [ 0.654807  ,  0.        ,  0.5089872 ,  1.        , -1.        ,\n",
       "         0.        ],\n",
       "       [ 0.07486903,  0.        ,  0.5089872 ,  1.        ,  1.        ,\n",
       "         1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targeted_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-7.        ,  0.69102162],\n",
       "        [ 0.        ,  0.83695078],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.98145694],\n",
       "        [ 0.        ,  0.04985608],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.695889  ],\n",
       "        [ 0.        ,  0.30091032],\n",
       "        [ 0.        ,  1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.65480697],\n",
       "        [ 0.        ,  0.72952473],\n",
       "        [ 1.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.07486903],\n",
       "        [ 0.        ,  0.39324445],\n",
       "        [ 1.        ,  1.        ]]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences, zeroed_rews = critic_target.process_sequence(targeted_experience)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\texttt{labels_critic = critic_target.give_td_error_Kennedy_guess( sequences, zeroed_rews)}$\n",
    "\n",
    "this gives $r_{t+1} + Q(s_{t+1}, a^{target}(s_{t+1}))$, but for the last time-step that gives\n",
    "$max_guess Q(h_L, g)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5973852 , 0.61283683, 1.        ]],\n",
       "\n",
       "       [[0.60361261, 0.61038331, 1.        ]],\n",
       "\n",
       "       [[0.60347774, 0.61117616, 0.        ]],\n",
       "\n",
       "       [[0.59924107, 0.61901563, 0.        ]],\n",
       "\n",
       "       [[0.60647486, 0.61481086, 1.        ]]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-7.        ,  0.69102162],\n",
       "        [ 0.        ,  0.83695078],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.98145694],\n",
       "        [ 0.        ,  0.04985608],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.695889  ],\n",
       "        [ 0.        ,  0.30091032],\n",
       "        [ 0.        ,  1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.65480697],\n",
       "        [ 0.        ,  0.72952473],\n",
       "        [ 1.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.07486903],\n",
       "        [ 0.        ,  0.39324445],\n",
       "        [ 1.        ,  1.        ]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to here we processed the sample from the buffer (whose form is mandatorily (a_0, o_1, a_1, o_2, a_3, ..., o_L, g=a_L+1, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3, 1), dtype=float64, numpy=\n",
       "array([[[0.48384659],\n",
       "        [0.44745938],\n",
       "        [0.46690037]],\n",
       "\n",
       "       [[0.4811861 ],\n",
       "        [0.44813932],\n",
       "        [0.46690939]],\n",
       "\n",
       "       [[0.48382078],\n",
       "        [0.44667874],\n",
       "        [0.46415958]],\n",
       "\n",
       "       [[0.48403872],\n",
       "        [0.44678101],\n",
       "        [0.46208075]],\n",
       "\n",
       "       [[0.48350252],\n",
       "        [0.44920999],\n",
       "        [0.45986259]]])>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_critic = critic(sequences)\n",
    "preds_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float64, numpy=\n",
       "array([[0.09864795, 0.1183762 , 0.10750632],\n",
       "       [0.10028268, 0.11834842, 0.10781938],\n",
       "       [0.08820658, 0.08372241, 0.08548918],\n",
       "       [0.08859461, 0.08417403, 0.08565338],\n",
       "       [0.09971124, 0.11850851, 0.11241751]])>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_critic = tf.keras.losses.MSE(labels_critic, preds_critic)\n",
    "loss_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.09983055987304452>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_critic = tf.reduce_mean(loss_critic)\n",
    "loss_critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it comes the actor optimziation step.\n",
    "\n",
    "<br> \n",
    "<br>\n",
    "Firstly, we'll predict the actor's output on a batch, so we need to set stateful=False. We also reset the states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.lstm.reset_states()\n",
    "actor.lstm.stateful=False ### this is because the mask has trouble with differing the batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to tape.watch the actions that would be output by the actor for each state (it's just a reshape of experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_indexed = [0.]*(actor.dolinar_layers)\n",
    "with tf.GradientTape() as tape:\n",
    "    ##### get the actions only ######\n",
    "    actions_with_outcomes = experiences.copy()\n",
    "    act_ind=0\n",
    "    for ind in range(len(experiences)): #experiences.shape[0] = 2L +2\n",
    "        if (ind%2 == 0)&(ind < 2*actor.dolinar_layers):\n",
    "            ac = tf.convert_to_tensor(np.reshape(experiences[:,ind], (len(experiences),1,1)))\n",
    "            actions_indexed[act_ind] = ac\n",
    "            act_ind+=1\n",
    "    actions_indexed = tf.concat(actions_indexed,axis=1)\n",
    "    tape.watch(actions_indexed) ####watch the ations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare them with experiences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6910216 ,  0.        ,  0.8369508 ,  0.        , -1.        ,\n",
       "         1.        ],\n",
       "       [ 0.98145694,  0.        ,  0.04985608,  0.        , -1.        ,\n",
       "         1.        ],\n",
       "       [ 0.695889  ,  0.        ,  0.30091032,  0.        ,  1.        ,\n",
       "         0.        ],\n",
       "       [ 0.654807  ,  0.        ,  0.72952473,  1.        , -1.        ,\n",
       "         0.        ],\n",
       "       [ 0.07486903,  0.        ,  0.39324445,  1.        ,  1.        ,\n",
       "         1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2, 1), dtype=float32, numpy=\n",
       "array([[[0.6910216 ],\n",
       "        [0.8369508 ]],\n",
       "\n",
       "       [[0.98145694],\n",
       "        [0.04985608]],\n",
       "\n",
       "       [[0.695889  ],\n",
       "        [0.30091032]],\n",
       "\n",
       "       [[0.654807  ],\n",
       "        [0.72952473]],\n",
       "\n",
       "       [[0.07486903],\n",
       "        [0.39324445]]], dtype=float32)>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to merge this watched variables (actions) to the inputs of the critic, in a tensor of shape (batch_size, L+1, 2),\n",
    "\n",
    "to obtain Q(h_l, a_l), {h_l, a_l} in buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       " array([[-7.],\n",
       "        [-7.],\n",
       "        [-7.],\n",
       "        [-7.],\n",
       "        [-7.]], dtype=float32)>]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now prepare the state acions to put them into the critic###\n",
    "padded_data = [tf.ones((experiences.shape[0],1))*actor.pad_value]\n",
    "watched_input_critic  = padded_data.copy()\n",
    "watched_input_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       " array([0.6910216 , 0.98145694, 0.695889  , 0.654807  , 0.07486903],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       " array([0.8369508 , 0.04985608, 0.30091032, 0.72952473, 0.39324445],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float32, numpy=array([-1., -1.,  1., -1.,  1.], dtype=float32)>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.unstack(tf.convert_to_tensor(experiences[:,:-1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_actions=0\n",
    "for ind,k in enumerate(tf.unstack(tf.convert_to_tensor(experiences[:,:-1]),axis=1)): #notice we get rid of the rewards here\n",
    "    if (ind%2==0)&(ind < 2*actor.dolinar_layers):\n",
    "        padded_data.append(actions_indexed[:,ind_actions]) ### i add the input of the critic the watched actions!\n",
    "        ind_actions+=1\n",
    "    else:\n",
    "        padded_data.append(tf.expand_dims(k, axis=1))\n",
    "    if ind == 0:\n",
    "        watched_input_critic = tf.stack([padded_data[0], padded_data[1]], axis=2) #importantly i put the padd first (state_action.)\n",
    "    if (ind%2 == 0)&(ind!=0):\n",
    "        intermediate = tf.stack([padded_data[ind], padded_data[ind+1]], axis=2)\n",
    "        watched_input_critic = tf.concat([watched_input_critic, intermediate], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3, 2), dtype=float32, numpy=\n",
       "array([[[-7.        ,  0.6910216 ],\n",
       "        [ 0.        ,  0.8369508 ],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.98145694],\n",
       "        [ 0.        ,  0.04985608],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.695889  ],\n",
       "        [ 0.        ,  0.30091032],\n",
       "        [ 0.        ,  1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.654807  ],\n",
       "        [ 0.        ,  0.72952473],\n",
       "        [ 1.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.07486903],\n",
       "        [ 0.        ,  0.39324445],\n",
       "        [ 1.        ,  1.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watched_input_critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice this is just the same as sequences, but now the tape is watching the actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3, 2), dtype=float32, numpy=\n",
       "array([[[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watched_input_critic - sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-7.        ,  0.69102162],\n",
       "        [ 0.        ,  0.83695078],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.98145694],\n",
       "        [ 0.        ,  0.04985608],\n",
       "        [ 0.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.695889  ],\n",
       "        [ 0.        ,  0.30091032],\n",
       "        [ 0.        ,  1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.65480697],\n",
       "        [ 0.        ,  0.72952473],\n",
       "        [ 1.        , -1.        ]],\n",
       "\n",
       "       [[-7.        ,  0.07486903],\n",
       "        [ 0.        ,  0.39324445],\n",
       "        [ 1.        ,  1.        ]]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer critic_38 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer actor_38 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiences = experiences.astype(np.float32)\n",
    "targeted_experience = actor_target.process_sequence_of_experiences(experiences)\n",
    "sequences, zeroed_rews = critic_target.process_sequence(targeted_experience)\n",
    "labels_critic = critic_target.give_td_error_Kennedy_guess( sequences, zeroed_rews)\n",
    "#\n",
    "###### train the critic ######\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(critic.trainable_variables)\n",
    "    preds_critic = critic(sequences)\n",
    "    loss_critic = tf.keras.losses.MSE(labels_critic, preds_critic)\n",
    "    loss_critic = tf.reduce_mean(loss_critic)\n",
    "    grads = tape.gradient(loss_critic, critic.trainable_variables)\n",
    "    optimizer_critic.apply_gradients(zip(grads, critic.trainable_variables))\n",
    "    loss_critic = np.squeeze(loss_critic.numpy())\n",
    "#\n",
    "#\n",
    "#actor.lstm.reset_states()\n",
    "actor.lstm.stateful=False ### this is because the mask has trouble with differing the batch_size\n",
    "\n",
    "actions_indexed = [0.]*(actor.dolinar_layers)\n",
    "with tf.GradientTape() as tape:\n",
    "    ##### get the actions only ######\n",
    "    actions_with_outcomes = experiences.copy()\n",
    "    act_ind=0\n",
    "    for ind in range(len(experiences)): #experiences.shape[0] = 2L +2\n",
    "        if (ind%2 == 0)&(ind < 2*actor.dolinar_layers):\n",
    "            ac = tf.convert_to_tensor(np.reshape(experiences[:,ind], (len(experiences),1,1)))\n",
    "            actions_indexed[act_ind] = ac\n",
    "            act_ind+=1\n",
    "    actions_indexed = tf.concat(actions_indexed,axis=1)\n",
    "    tape.watch(actions_indexed) ####watch the ations\n",
    "\n",
    "    ### now prepare the state acions to put them into the critic###\n",
    "    padded_data = [tf.ones((experiences.shape[0],1))*actor.pad_value]\n",
    "    watched_input_critic  = padded_data.copy()\n",
    "    ind_actions=0\n",
    "    for ind,k in enumerate(tf.unstack(tf.convert_to_tensor(experiences[:,:-1]),axis=1)):\n",
    "        if (ind%2==0)&(ind < 2*actor.dolinar_layers):\n",
    "            padded_data.append(actions_indexed[:,ind_actions]) ### i add the input of the critic the watched actions!\n",
    "            ind_actions+=1\n",
    "        else:\n",
    "            padded_data.append(tf.expand_dims(k, axis=1))\n",
    "        if ind == 0:\n",
    "            watched_input_critic = tf.stack([padded_data[0], padded_data[1]], axis=2) #importantly i put the padd first (state_action.)\n",
    "        if (ind%2 == 0)&(ind!=0):\n",
    "            intermediate = tf.stack([padded_data[ind], padded_data[ind+1]], axis=2)\n",
    "            watched_input_critic = tf.concat([watched_input_critic, intermediate], axis=1)\n",
    "\n",
    "    qvals = critic(watched_input_critic)\n",
    "    dq_da = tape.gradient(qvals, actions_indexed)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "\n",
    "    pads = np.ones(len(experiences)).astype(np.float32)*actor.pad_value\n",
    "    news = np.random.rand(experiences.shape[0], experiences.shape[1]+1).astype(np.float32)\n",
    "    news[:,1:] = experiences\n",
    "    news[:,0] = pads\n",
    "    instances_actor = [i for i in range(0,2*actor.dolinar_layers,2)]\n",
    "    actionss = actor(np.reshape(news[:,instances_actor], (experiences.shape[0],actor.dolinar_layers,1)).astype(np.float32))\n",
    "\n",
    "    da_dtheta = tape.gradient(actionss, actor.trainable_variables, output_gradients=-dq_da)\n",
    "\n",
    "#\n",
    "optimizer_actor.apply_gradients(zip(da_dtheta, actor.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 2000), dtype=float64, numpy=array([[0., 0., 0., ..., 0., 0., 0.]])>,\n",
       " <tf.Tensor: shape=(500, 2000), dtype=float64, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])>,\n",
       " <tf.Tensor: shape=(2000,), dtype=float64, numpy=array([0., 0., 0., ..., 0., 0., 0.])>,\n",
       " <tf.Tensor: shape=(500, 250), dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(250,), dtype=float32, numpy=\n",
       " array([-2.17598850e-09, -8.45104875e-10,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.65575287e-09,  0.00000000e+00,\n",
       "         0.00000000e+00, -8.67704630e-10,  6.37694675e-10, -6.47290721e-10,\n",
       "        -6.60121680e-10,  1.83249838e-09,  0.00000000e+00,  6.47941145e-10,\n",
       "         9.47576906e-10,  0.00000000e+00,  0.00000000e+00,  1.15715659e-09,\n",
       "         0.00000000e+00, -1.39868561e-09,  1.73384496e-09,  3.78555159e-10,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.03272974e-10,\n",
       "         1.28564193e-09,  0.00000000e+00,  5.34083222e-10,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.29958688e-09,  1.81500898e-10,\n",
       "         5.18787346e-10,  0.00000000e+00,  2.08305506e-09,  0.00000000e+00,\n",
       "         1.50385193e-09,  3.18767845e-10,  1.41460843e-09,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -4.32524988e-10,  0.00000000e+00,  0.00000000e+00,\n",
       "        -2.64306022e-09,  6.89374530e-11,  0.00000000e+00,  5.75953951e-10,\n",
       "        -2.19277638e-10,  4.76164275e-10, -2.31634645e-09,  0.00000000e+00,\n",
       "        -5.05735065e-10,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -2.66616590e-10,  0.00000000e+00,  2.12692450e-11,  0.00000000e+00,\n",
       "        -9.77197767e-10,  5.42566547e-10, -8.75245432e-10,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.58693991e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.12867320e-10,  0.00000000e+00,\n",
       "         3.10866266e-09,  2.18752882e-09, -9.49971546e-10,  1.49582652e-10,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -2.76198109e-09,  0.00000000e+00, -1.91179250e-09,  1.28046673e-09,\n",
       "         0.00000000e+00,  3.01693936e-09,  9.88869209e-10, -1.07205711e-09,\n",
       "         7.58249685e-10, -1.45806214e-10, -8.04407430e-10, -3.66323194e-09,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.78705928e-09,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.35381772e-09, -2.44472798e-09,  0.00000000e+00,\n",
       "         7.43800632e-10,  1.28101141e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.23788646e-09, -2.09094564e-09, -1.64171887e-09,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -6.93243463e-10,  0.00000000e+00,\n",
       "         2.31972130e-09,  0.00000000e+00,  0.00000000e+00, -1.39138701e-09,\n",
       "        -4.52819976e-10, -1.74835835e-09, -6.23103680e-10,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.26016408e-09, -6.33815944e-10, -1.41476375e-09,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.89484800e-09, -6.79400924e-10,\n",
       "         0.00000000e+00, -8.78175532e-10,  1.16159360e-10,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.29989405e-11,  8.22327650e-10, -6.66990185e-10,\n",
       "         0.00000000e+00, -1.11655141e-09,  0.00000000e+00,  9.06469899e-10,\n",
       "         0.00000000e+00, -8.98748076e-10,  2.79394818e-09, -2.66011324e-09,\n",
       "         4.57990562e-10,  1.55733371e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  8.25050805e-10,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         7.61064267e-10,  0.00000000e+00,  1.87344251e-09,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.80722748e-10,  0.00000000e+00,\n",
       "        -1.98685024e-09,  0.00000000e+00, -2.82769275e-09, -9.00104435e-10,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.62257113e-09,  0.00000000e+00,\n",
       "         0.00000000e+00, -2.11121431e-09,  1.42145051e-09,  0.00000000e+00,\n",
       "         0.00000000e+00,  2.31223063e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -9.81672632e-10,\n",
       "         0.00000000e+00,  1.59367974e-09, -2.99283820e-09,  2.16663021e-09,\n",
       "         0.00000000e+00,  0.00000000e+00,  4.05919937e-10,  0.00000000e+00,\n",
       "        -1.10482368e-09, -3.49928286e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         8.67779876e-11,  0.00000000e+00, -1.83004800e-09,  1.33647232e-10,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.08509490e-09,  1.83412573e-12,\n",
       "         5.39773892e-10, -1.20066401e-10, -1.71955772e-09, -6.31929287e-10,\n",
       "         0.00000000e+00, -1.37826928e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -8.26797797e-10,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -5.57396851e-10,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.45196174e-09,\n",
       "         0.00000000e+00,  1.39128731e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00], dtype=float32)>,\n",
       " <tf.Tensor: shape=(250, 100), dtype=float32, numpy=\n",
       " array([[-9.04659160e-12, -6.34077730e-12, -1.12035711e-11, ...,\n",
       "         -1.17289555e-11,  0.00000000e+00,  7.08652408e-12],\n",
       "        [-3.47225894e-11, -2.43371399e-11, -4.30014878e-11, ...,\n",
       "         -4.50180240e-11,  0.00000000e+00,  2.71994632e-11],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       " array([-3.6114938e-09, -2.5313038e-09, -4.4725814e-09,  4.6745536e-09,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         3.6544212e-09, -4.9848263e-09, -2.2050071e-10,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -6.6889527e-10,\n",
       "         0.0000000e+00,  0.0000000e+00, -3.0456328e-11,  4.1828763e-09,\n",
       "        -4.8571192e-09,  2.0371904e-09,  0.0000000e+00,  6.1092387e-10,\n",
       "         7.1936133e-09, -2.3652191e-09,  0.0000000e+00,  0.0000000e+00,\n",
       "        -2.2265767e-09,  1.9849075e-10,  0.0000000e+00,  0.0000000e+00,\n",
       "         1.5364535e-10,  0.0000000e+00,  0.0000000e+00,  7.4992973e-10,\n",
       "         4.9551285e-10,  3.6833323e-09,  0.0000000e+00, -3.1275618e-09,\n",
       "         0.0000000e+00,  0.0000000e+00, -4.3913428e-09,  1.1924273e-09,\n",
       "         0.0000000e+00,  0.0000000e+00, -8.1409972e-09, -2.5693152e-09,\n",
       "         2.1358464e-09,  7.9125879e-09,  0.0000000e+00,  4.0182981e-09,\n",
       "         0.0000000e+00,  0.0000000e+00, -7.2799624e-09,  1.7652394e-09,\n",
       "         7.3572848e-10,  0.0000000e+00,  1.9162152e-09,  2.5534499e-09,\n",
       "        -4.3352109e-09,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         3.1827154e-09,  0.0000000e+00,  0.0000000e+00, -1.3268581e-09,\n",
       "        -6.1656023e-09,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00, -4.1021666e-09,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -5.5308194e-09,\n",
       "         0.0000000e+00,  5.1093370e-09,  0.0000000e+00, -1.0117135e-09,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  3.6136136e-09,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00, -2.4270725e-09, -9.1584899e-11,  0.0000000e+00,\n",
       "         0.0000000e+00, -4.6823208e-09,  0.0000000e+00,  2.8290141e-09],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00, -4.5650550e-10,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00, -4.7192511e-10,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00, -3.8827000e-10,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00, -9.1911805e-11,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00, -1.1756661e-09,  0.0000000e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       " array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.54389979e-09,\n",
       "         0.00000000e+00,  3.81192633e-09,  1.43290029e-08,  0.00000000e+00,\n",
       "         1.42319561e-08, -2.00084754e-10,  5.05548803e-09,  0.00000000e+00,\n",
       "        -5.53804336e-09,  0.00000000e+00, -1.41348213e-08, -1.82440818e-09,\n",
       "        -3.08813225e-10, -2.14282680e-09, -1.11113430e-08,  9.76311476e-09,\n",
       "        -1.19820500e-08,  0.00000000e+00,  0.00000000e+00,  6.97795821e-09,\n",
       "        -4.14394907e-11,  0.00000000e+00,  0.00000000e+00,  1.00392372e-09,\n",
       "         1.31578428e-08,  2.16827178e-09,  0.00000000e+00,  5.89927218e-09,\n",
       "         0.00000000e+00,  1.42574375e-09, -3.29781624e-09, -1.17487700e-08,\n",
       "         0.00000000e+00, -9.81455095e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.25836568e-08, -1.41352929e-08,  0.00000000e+00, -4.54985116e-09,\n",
       "         0.00000000e+00,  1.37345380e-08,  1.38653231e-08, -1.09325793e-08,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.15024159e-08,  0.00000000e+00,  6.56360388e-09,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  5.09320763e-09,\n",
       "        -4.99287456e-09,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -6.81652379e-09, -3.75651377e-09,  9.78377201e-09,  0.00000000e+00,\n",
       "        -1.41382275e-08,  8.49496384e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.43890522e-09,  0.00000000e+00,\n",
       "        -8.68769767e-09,  1.01828901e-08,  9.51200096e-09,  1.16324435e-08,\n",
       "         0.00000000e+00, -1.35002043e-09,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.87401894e-09,\n",
       "         0.00000000e+00,  0.00000000e+00,  6.90042068e-09,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.77986581e-09, -1.60334055e-11, -1.38116798e-08,\n",
       "         1.23766606e-08,  0.00000000e+00, -1.23201387e-08,  0.00000000e+00],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 1), dtype=float32, numpy=\n",
       " array([[ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-6.85796142e-10],\n",
       "        [ 0.00000000e+00],\n",
       "        [-2.77659762e-09],\n",
       "        [-1.05454232e-08],\n",
       "        [ 0.00000000e+00],\n",
       "        [-8.58564775e-09],\n",
       "        [-1.53142174e-08],\n",
       "        [-2.54399701e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.03432685e-08],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.27460380e-08],\n",
       "        [-3.82566911e-09],\n",
       "        [-5.98931926e-09],\n",
       "        [-1.04378302e-08],\n",
       "        [-9.43718703e-09],\n",
       "        [-9.09932485e-09],\n",
       "        [-1.14615872e-08],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-4.21500790e-09],\n",
       "        [-1.19845671e-08],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.34666909e-08],\n",
       "        [-8.01712297e-09],\n",
       "        [-5.71004044e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [-5.16116794e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.74460038e-08],\n",
       "        [-2.53257970e-09],\n",
       "        [-1.18023520e-08],\n",
       "        [ 0.00000000e+00],\n",
       "        [-4.31960778e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.04198206e-08],\n",
       "        [-3.61551761e-10],\n",
       "        [ 0.00000000e+00],\n",
       "        [-9.52601109e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [-8.35958591e-09],\n",
       "        [-4.39421877e-09],\n",
       "        [-3.15032400e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.65753917e-08],\n",
       "        [ 0.00000000e+00],\n",
       "        [-7.04136260e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.11427747e-08],\n",
       "        [-5.09215559e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.13579075e-08],\n",
       "        [-1.22146089e-08],\n",
       "        [-1.53821968e-08],\n",
       "        [ 0.00000000e+00],\n",
       "        [-5.76936587e-09],\n",
       "        [-1.47394834e-08],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-4.66287498e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [-6.25009067e-09],\n",
       "        [-3.13352166e-09],\n",
       "        [-4.55069715e-09],\n",
       "        [-1.05483078e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [-6.50343779e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-3.41037976e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.09116520e-08],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-6.94525104e-09],\n",
       "        [-1.33226008e-08],\n",
       "        [-2.57930144e-09],\n",
       "        [-2.16537166e-09],\n",
       "        [ 0.00000000e+00],\n",
       "        [-6.85334500e-09],\n",
       "        [ 0.00000000e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-1.4409852e-07], dtype=float32)>]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_dtheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
