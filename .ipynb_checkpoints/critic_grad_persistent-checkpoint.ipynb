{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib\n",
    "from environment import Environment\n",
    "from plots import just_plot, profiles_kennedy\n",
    "import misc \n",
    "import nets\n",
    "from buffer import ReplayBuffer\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "amplitude=0.4\n",
    "lr_critic = 0.01\n",
    "lr_actor = 0.0001\n",
    "ep_guess=1\n",
    "dolinar_layers=1\n",
    "number_phases=2\n",
    "buffer_size = 10**6\n",
    "tau = 0.05\n",
    "batch_size=64\n",
    "\n",
    "\n",
    "buffer = ReplayBuffer(buffer_size=buffer_size)\n",
    "\n",
    "critic = nets.Critic(nature=\"primary\", dolinar_layers = 1, number_phases=number_phases)\n",
    "critic_target = nets.Critic(nature=\"target\", dolinar_layers = dolinar_layers, number_phases=number_phases, tau = tau)\n",
    "actor = nets.Actor(nature=\"primary\", dolinar_layers = dolinar_layers,batch_size_info=batch_size )\n",
    "actor_target = nets.Actor(nature=\"target\", dolinar_layers = dolinar_layers, tau = tau)\n",
    "\n",
    "optimizer_critic = tf.keras.optimizers.Adam(lr=lr_critic)\n",
    "optimizer_actor = tf.keras.optimizers.Adam(lr=lr_actor)\n",
    "\n",
    "policy_evaluator = misc.PolicyEvaluator(amplitude = amplitude, dolinar_layers=dolinar_layers, number_phases = number_phases)\n",
    "\n",
    "\n",
    "\n",
    "kk = np.load(\"buffers/1L_stoch_big.npy\")\n",
    "for k in kk:\n",
    "    buffer.add(tuple(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = buffer.sample(batch_size).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_grad_tf(critic, experiences):\n",
    "    #check how this works for L>2\n",
    "    unstacked_exp = tf.unstack(tf.convert_to_tensor(experiences), axis=1)\n",
    "    to_stack = []\n",
    "    actions_wathed_index = []\n",
    "    for index in range(0,experiences.shape[-1]-3,2): # I consider from first outcome to last one (but guess)\n",
    "        actions_wathed_index.append(index)\n",
    "        to_stack.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "    actions_indexed = tf.concat(to_stack,axis=1)\n",
    "\n",
    "    with tf.GradientTape(persistent = True) as tape:\n",
    "        tape.watch(actions_indexed)\n",
    "\n",
    "        index_actions=0\n",
    "        watched_exps=[tf.ones((experiences.shape[0],1,1))*critic.pad_value]\n",
    "        watched_actions_unstacked = tf.unstack(actions_indexed, axis=1)\n",
    "        for index in range(0,experiences.shape[-1]-1):\n",
    "            if index in actions_wathed_index:\n",
    "                watched_exps.append(tf.expand_dims(watched_actions_unstacked[index_actions], axis=2))\n",
    "                index_actions+=1\n",
    "            else:\n",
    "                watched_exps.append(tf.reshape(unstacked_exp[index],(experiences.shape[0],1,1)))\n",
    "\n",
    "        qvals = critic(tf.reshape(tf.concat(watched_exps, axis=2), (experiences.shape[0],critic.dolinar_layers+1,2)))\n",
    "        qvalsunstckd = tf.unstack(qvals, axis=1)\n",
    "        return [tape.gradient(q, actions_indexed) for q in qvalsunstckd]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_grad_tf(actor, dq_da, experiences, optimizer_actor):\n",
    "    finns = [tf.ones((experiences.shape[0], 1,1))*actor.pad_value]\n",
    "    unstacked_exp = tf.unstack(experiences, axis=1)\n",
    "    for index in range(1,2*actor.dolinar_layers-2,2):\n",
    "        finns.append(tf.reshape(unstacked_exp[index], (experiences.shape[0], 1,1)))\n",
    "    final_preds = tf.concat(finns, axis=1)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(actor.trainable_variables)\n",
    "        preds_actor = actor(final_preds)\n",
    "    dq_da_mod = tf.multiply(dq_da, -1/experiences.shape[0])\n",
    "    da_dtheta=tape.gradient(preds_actor, actor.trainable_variables, output_gradients=dq_da_mod) #- because you wanna minimize, and the Q value maximizes..\n",
    "        #/experiences.shape[0] because it's 1/N (this is checked in debugging actor notebook... proof of [...])\n",
    "    optimizer_actor.apply_gradients(zip(da_dtheta, actor.trainable_variables))\n",
    "    return da_dtheta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 4), dtype=float32, numpy=\n",
       "array([[0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49823412, 1.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49823412, 1.        , 1.        , 0.        ],\n",
       "       [0.49823412, 1.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49823412, 1.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actored_experiences = actor.process_sequence_of_experiences_tf(samples)\n",
    "actored_experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(64, 1, 1), dtype=float32, numpy=\n",
       " array([[[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301742]],\n",
       " \n",
       "        [[-0.00301752]],\n",
       " \n",
       "        [[-0.00301752]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 1), dtype=float32, numpy=\n",
       " array([[[-0.00209844]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00254518]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00254518]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00254518]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00254518]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00254518]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00254518]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.00212667]],\n",
       " \n",
       "        [[-0.002534  ]],\n",
       " \n",
       "        [[-0.00209844]]], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq_da = critic_grad_tf(critic, actored_experiences)\n",
    "dq_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 4), dtype=float32, numpy=\n",
       "array([[0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49823412, 1.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49823412, 1.        , 1.        , 0.        ],\n",
       "       [0.49823412, 1.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49823412, 1.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49823412, 1.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 0.        , 0.        ],\n",
       "       [0.49811566, 0.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 1.        ],\n",
       "       [0.49823412, 1.        , 1.        , 0.        ],\n",
       "       [0.49811566, 0.        , 0.        , 1.        ],\n",
       "       [0.49811566, 0.        , 1.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actored_experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 120), dtype=float32, numpy=\n",
       " array([[ 1.18235346e-06,  3.65678147e-07, -4.51264583e-07,\n",
       "         -9.94239429e-08,  2.08102347e-06,  2.81926077e-06,\n",
       "          5.00254146e-07, -3.28564141e-07, -7.03303513e-08,\n",
       "         -9.41521421e-07,  3.25946303e-07, -3.28511391e-07,\n",
       "         -2.62793179e-07, -1.03928380e-06,  1.30799435e-07,\n",
       "          4.22815219e-07,  1.07100107e-06,  1.29702073e-06,\n",
       "         -5.69612325e-07, -1.12160694e-06,  3.57623549e-06,\n",
       "          6.68254017e-07, -4.63241076e-06, -1.07256447e-07,\n",
       "         -9.79036713e-07, -1.80709279e-08,  3.54436452e-07,\n",
       "          3.09304482e-07, -1.08466786e-07,  9.57901420e-07,\n",
       "          4.76359048e-07,  4.10049068e-07, -2.06217507e-07,\n",
       "         -1.14493567e-07,  1.11256793e-06,  1.51822655e-06,\n",
       "          3.73087005e-07, -2.12752667e-07, -4.99566752e-08,\n",
       "         -5.91223795e-07,  1.67092480e-07, -1.72824926e-07,\n",
       "         -5.90238130e-07, -3.73899667e-07,  7.41707638e-08,\n",
       "          6.04610022e-07,  2.02802084e-06,  9.09821040e-07,\n",
       "         -3.22578529e-07, -3.62787574e-07,  1.12142038e-06,\n",
       "          5.24698805e-07, -1.99744022e-06, -2.11483552e-07,\n",
       "         -1.96866790e-06, -2.28274804e-08,  1.67276767e-07,\n",
       "          1.97840450e-07, -8.00000564e-08,  5.02222235e-07,\n",
       "          7.46559863e-07,  6.58365980e-06, -9.27620647e-07,\n",
       "         -7.13502430e-08, -1.28670863e-05, -1.77130096e-06,\n",
       "         -2.31101353e-06,  5.16849195e-06, -6.53320342e-07,\n",
       "          2.78347966e-06, -1.03761010e-07,  5.76641582e-07,\n",
       "          6.04395098e-07,  9.79285687e-07, -1.57980182e-07,\n",
       "         -6.27220686e-07, -1.02529511e-05,  9.72175803e-06,\n",
       "          4.04269031e-07,  2.79734962e-07, -2.74257127e-06,\n",
       "         -9.59352656e-06,  1.51737675e-06,  4.04582988e-06,\n",
       "         -6.40633607e-06, -1.92946132e-07,  1.31601468e-07,\n",
       "          3.08808808e-06,  3.02097135e-07, -2.72234388e-06,\n",
       "          1.02971198e-05,  5.62176126e-07, -4.37832568e-07,\n",
       "         -5.71556848e-06,  5.18964089e-06,  6.11330506e-06,\n",
       "          2.72553348e-06, -7.63650974e-07, -1.83606105e-07,\n",
       "         -1.60250329e-06,  4.82090911e-07, -8.74846228e-06,\n",
       "         -4.73292266e-06, -5.98038525e-07,  6.00218982e-06,\n",
       "          4.21505774e-06,  3.25340716e-06,  1.97640588e-06,\n",
       "         -7.34629020e-06, -2.74507602e-06,  5.75500826e-06,\n",
       "          4.41724160e-06, -4.01746320e-06, -2.55626901e-07,\n",
       "         -6.29093074e-06, -1.16579329e-07,  9.55863925e-07,\n",
       "          9.01394912e-07, -2.78866906e-07,  1.10046869e-06]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(30, 120), dtype=float32, numpy=\n",
       " array([[-5.1939878e-08, -1.6093644e-08,  1.9912305e-08, ...,\n",
       "         -3.9851237e-08,  1.2307349e-08, -4.8583495e-08],\n",
       "        [-2.0311715e-08, -6.2753180e-09,  7.7323303e-09, ...,\n",
       "         -1.5427943e-08,  4.7778350e-09, -1.8850752e-08],\n",
       "        [-1.6875209e-08, -5.2352158e-09,  6.4886234e-09, ...,\n",
       "         -1.3002413e-08,  4.0109436e-09, -1.5836726e-08],\n",
       "        ...,\n",
       "        [-5.0145821e-09, -1.5551984e-09,  1.9267044e-09, ...,\n",
       "         -3.8596508e-09,  1.1909567e-09, -4.7020934e-09],\n",
       "        [ 3.1420978e-08,  9.7285602e-09, -1.2024221e-08, ...,\n",
       "          2.4045821e-08, -7.4313649e-09,  2.9331538e-08],\n",
       "        [ 1.3402476e-08,  4.1524242e-09, -5.1370845e-09, ...,\n",
       "          1.0280132e-08, -3.1750913e-09,  1.2533540e-08]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(120,), dtype=float32, numpy=\n",
       " array([-1.68907462e-07, -5.22397237e-08,  6.44663913e-08,  1.42034295e-08,\n",
       "        -2.97288949e-07, -4.02751283e-07, -7.14649175e-08,  4.69377177e-08,\n",
       "         1.00471871e-08,  1.34503026e-07, -4.65637768e-08,  4.69301753e-08,\n",
       "         3.75418949e-08,  1.48468956e-07, -1.86856397e-08, -6.04021864e-08,\n",
       "        -1.53000045e-07, -1.85288641e-07,  8.13731873e-08,  1.60229561e-07,\n",
       "        -5.10891141e-07, -9.54647703e-08,  6.61772788e-07,  1.53223638e-08,\n",
       "         1.39862493e-07,  2.58156230e-09, -5.06338047e-08, -4.41863186e-08,\n",
       "         1.54952637e-08, -1.36843184e-07, -6.80512429e-08, -5.85784008e-08,\n",
       "         2.94596347e-08,  1.63562213e-08, -1.58938334e-07, -2.16889589e-07,\n",
       "        -5.32981730e-08,  3.03932595e-08,  7.13667170e-09,  8.44605381e-08,\n",
       "        -2.38703421e-08,  2.46892657e-08,  8.43198080e-08,  5.34142295e-08,\n",
       "        -1.05958211e-08, -8.63728502e-08, -2.89717235e-07, -1.29974410e-07,\n",
       "         4.60826328e-08,  5.18267491e-08, -1.60202802e-07, -7.49569935e-08,\n",
       "         2.85348705e-07,  3.02119467e-08,  2.81238130e-07,  3.26106675e-09,\n",
       "        -2.38966873e-08, -2.82629156e-08,  1.14285736e-08, -7.17460793e-08,\n",
       "        -1.06651399e-07, -9.40523989e-07,  1.32517258e-07,  1.01928830e-08,\n",
       "         1.83815428e-06,  2.53043027e-07,  3.30144701e-07, -7.38355993e-07,\n",
       "         9.33314226e-08, -3.97640207e-07,  1.48230201e-08, -8.23774329e-08,\n",
       "        -8.63421903e-08, -1.39897878e-07,  2.25686065e-08,  8.96030485e-08,\n",
       "         1.46470666e-06, -1.38882285e-06, -5.77527572e-08, -3.99621385e-08,\n",
       "         3.91795737e-07,  1.37050313e-06, -2.16768314e-07, -5.77975698e-07,\n",
       "         9.15190810e-07,  2.75637273e-08, -1.88002094e-08, -4.41155692e-07,\n",
       "        -4.31567173e-08,  3.88906074e-07, -1.47101662e-06, -8.03109543e-08,\n",
       "         6.25475280e-08,  8.16510010e-07, -7.41377164e-07, -8.73328815e-07,\n",
       "        -3.89362185e-07,  1.09092966e-07,  2.62294559e-08,  2.28928997e-07,\n",
       "        -6.88701647e-08,  1.24978010e-06,  6.76132061e-07,  8.54340882e-08,\n",
       "        -8.57455746e-07, -6.02151658e-07, -4.64772313e-07, -2.82343535e-07,\n",
       "         1.04946980e-06,  3.92153794e-07, -8.22144386e-07, -6.31034709e-07,\n",
       "         5.73923103e-07,  3.65180988e-08,  8.98705139e-07,  1.66541891e-08,\n",
       "        -1.36551918e-07, -1.28770708e-07,  3.98380990e-08, -1.57209712e-07],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(30, 1), dtype=float32, numpy=\n",
       " array([[ 2.7368098e-04],\n",
       "        [ 1.0194258e-04],\n",
       "        [ 9.1491529e-05],\n",
       "        [ 2.5189205e-04],\n",
       "        [-2.9336900e-04],\n",
       "        [-1.9349101e-04],\n",
       "        [-7.8475787e-05],\n",
       "        [-4.2376738e-05],\n",
       "        [ 2.5727852e-05],\n",
       "        [-1.1923215e-04],\n",
       "        [-1.5183361e-04],\n",
       "        [-2.3344082e-04],\n",
       "        [-2.8842251e-04],\n",
       "        [-1.2123676e-04],\n",
       "        [-2.0884351e-04],\n",
       "        [-1.1648037e-04],\n",
       "        [-3.2327519e-04],\n",
       "        [ 1.0613646e-04],\n",
       "        [-5.0796033e-04],\n",
       "        [-2.7767202e-04],\n",
       "        [-4.3162750e-04],\n",
       "        [-1.9604152e-04],\n",
       "        [-1.4866659e-04],\n",
       "        [-2.8883820e-05],\n",
       "        [ 3.1519309e-04],\n",
       "        [ 7.7760807e-05],\n",
       "        [ 4.1741954e-05],\n",
       "        [ 2.8208469e-05],\n",
       "        [-1.7975378e-04],\n",
       "        [-6.8765839e-05]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00075435], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_grad_tf(actor, dq_da, samples, optimizer_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = nets.Critic(nature=\"primary\", dolinar_layers = 2, number_phases=number_phases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"buffers/2L_probs.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq_da = critic_grad_tf(critic,tf.random.uniform((10,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(actor.trainable_variables)\n",
    "    preds = actor(tf.random.uniform((10,2,1)))\n",
    "    dac = tape.gradient(preds, actor.trainable_variables, output_gradients=dq_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(10, 2, 1), dtype=float32, numpy=\n",
       " array([[[0.00203225],\n",
       "         [0.        ]],\n",
       " \n",
       "        [[0.0019928 ],\n",
       "         [0.        ]],\n",
       " \n",
       "        [[0.00194717],\n",
       "         [0.        ]],\n",
       " \n",
       "        [[0.00194762],\n",
       "         [0.        ]],\n",
       " \n",
       "        [[0.00201457],\n",
       "         [0.        ]],\n",
       " \n",
       "        [[0.00203077],\n",
       "         [0.        ]],\n",
       " \n",
       "        [[0.0020448 ],\n",
       "         [0.        ]],\n",
       " \n",
       "        [[0.0020346 ],\n",
       "         [0.        ]],\n",
       " \n",
       "        [[0.00204778],\n",
       "         [0.        ]],\n",
       " \n",
       "        [[0.00195935],\n",
       "         [0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 2, 1), dtype=float32, numpy=\n",
       " array([[[0.00129191],\n",
       "         [0.00211496]],\n",
       " \n",
       "        [[0.00131658],\n",
       "         [0.00219718]],\n",
       " \n",
       "        [[0.00128186],\n",
       "         [0.0021686 ]],\n",
       " \n",
       "        [[0.00127316],\n",
       "         [0.00214996]],\n",
       " \n",
       "        [[0.00130076],\n",
       "         [0.00213865]],\n",
       " \n",
       "        [[0.00126769],\n",
       "         [0.00204486]],\n",
       " \n",
       "        [[0.00125532],\n",
       "         [0.00200104]],\n",
       " \n",
       "        [[0.00132727],\n",
       "         [0.00219071]],\n",
       " \n",
       "        [[0.00129665],\n",
       "         [0.00209913]],\n",
       " \n",
       "        [[0.00129166],\n",
       "         [0.00215094]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 2, 1), dtype=float32, numpy=\n",
       " array([[[0.00072861],\n",
       "         [0.00129522]],\n",
       " \n",
       "        [[0.00076435],\n",
       "         [0.00135433]],\n",
       " \n",
       "        [[0.00075769],\n",
       "         [0.00138293]],\n",
       " \n",
       "        [[0.00072848],\n",
       "         [0.00134762]],\n",
       " \n",
       "        [[0.00078705],\n",
       "         [0.00135194]],\n",
       " \n",
       "        [[0.00081352],\n",
       "         [0.00134447]],\n",
       " \n",
       "        [[0.00073168],\n",
       "         [0.001273  ]],\n",
       " \n",
       "        [[0.00077989],\n",
       "         [0.00135618]],\n",
       " \n",
       "        [[0.00081796],\n",
       "         [0.00135791]],\n",
       " \n",
       "        [[0.00075305],\n",
       "         [0.00131879]]], dtype=float32)>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "total_episodes = 10**4\n",
    "evolution_loss=[]\n",
    "history_predictions={\"final_episode_info\":total_episodes}\n",
    "buffsam = buffer.sample(buffer.count)[:,0]\n",
    "bbbs = np.arange(min(buffsam),max(buffsam),.05)\n",
    "inps = np.stack([np.ones(len(bbbs))*critic.pad_value, bbbs], axis=1)\n",
    "inps = np.reshape(inps, (len(bbbs),1,2))\n",
    "\n",
    "betas_would=[]\n",
    "dqs = []\n",
    "for iteration in tqdm(range(total_episodes)):\n",
    "\n",
    "    sampled_dataset = buffer.sample(batch_size).astype(np.float32)\n",
    "    batched_sampled_dataset, rews_per_layer = critic.process_sequence_tf(sampled_dataset)\n",
    "    td_errors = critic_target.give_td_errors_tf(batched_sampled_dataset, rews_per_layer)\n",
    "    loss = critic.step_critic_tf(batched_sampled_dataset, td_errors, optimizer_critic)\n",
    "    evolution_loss.append(loss.numpy())\n",
    "    critic_target.update_target_parameters(critic)\n",
    "    if iteration>10**3:\n",
    "        actored_experiences = actor.process_sequence_of_experiences_tf(sampled_dataset)\n",
    "        dq_da = tf.clip_by_value(critic.critic_grad_tf(actored_experiences)[0], -10e-5,10e-5)\n",
    "        actor.actor_grad_tf(dq_da, sampled_dataset, optimizer_actor)\n",
    "    betas_would.append(np.squeeze(actor(tf.random.uniform((batch_size,1,1))))[0])\n",
    "    if iteration%(int(total_episodes/5)) == 0:\n",
    "        history_predictions[str(iteration)] = {\"[]\":[], \"00\":[],\"01\":[],\"11\":[],\"10\":[]}\n",
    "        history_predictions[str(iteration)][\"[]\"] = np.squeeze(critic(inps))\n",
    "        for outcome in [0.,1.]:\n",
    "           for guess_index in [0.,1.]:\n",
    "                m=[]\n",
    "                for k in tf.unstack(inps):\n",
    "                    m.append(tf.concat([k, np.reshape(np.array([outcome,guess_index]), (1,2))], axis=0))\n",
    "                history_predictions[str(iteration)][str(outcome)+str(guess_index)] = np.squeeze(critic(tf.stack(m, axis=0)))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_beta= 0.7499999999999993\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(betas_would)\n",
    "plt.plot(np.ones(len(betas_would))*optimal_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " profiles_kennedy(critic, history_predictions, bbbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
