{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import *\n",
    "import numpy as np\n",
    "import cmath\n",
    "\n",
    "def P(a,b,et,n):\n",
    "\n",
    "    p0=np.exp(-abs((et*a)+b)**2)\n",
    "\n",
    "    if n ==0:\n",
    "        return p0\n",
    "    else:\n",
    "        return 1-(p0)\n",
    "    \n",
    "def outcomes_universe(L):\n",
    "    \"\"\"\n",
    "    Takes L (# of photodetections in the experiment) and returns\n",
    "    all possible outcomes in a matrix of 2**L rows by L columns,\n",
    "    which are all possible sequence of outcomes you can ever get.\n",
    "    \"\"\"\n",
    "    a = np.array([0,1])\n",
    "    two_outcomes = np.array([[0,0],[0,1],[1,0],[1,1]]).astype(int)\n",
    "    if L<2:\n",
    "        return np.array([0,1]).astype(int)\n",
    "    elif L==2:\n",
    "        return two_outcomes\n",
    "    else:\n",
    "        x = insert(a,two_outcomes)\n",
    "        for i in range(L-3):\n",
    "            x = insert(a,x)\n",
    "        return x.astype(int)\n",
    "\n",
    "def make_attenuations(layers):\n",
    "    if layers == 1:\n",
    "        return [0]\n",
    "    else:\n",
    "        ats=[0]\n",
    "        for i in range(layers-1):\n",
    "            ats.append(np.arctan(1/np.cos(ats[i])))\n",
    "        return np.flip(ats)\n",
    "\n",
    "    \n",
    "def prob_2L(actions_tree, at): #\n",
    "    #at = make_attenuations(2)\n",
    "    p=0\n",
    "    for ot in outcomes_universe(2):\n",
    "        p += P(actions_tree[\"2\"][str(ot[:2])]*0.4, actions_tree[\"0\"][\"[]\"], np.sin(at[0]), ot[0])*P(actions_tree[\"2\"][str(ot[:2])]*0.4,\n",
    "                                                                                                    actions_tree[\"1\"][str(ot[:1])], np.cos(at[0]), ot[1])\n",
    "    return p/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = make_attenuations(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1, b2 = -.4, .5\n",
    "guesses = {}\n",
    "for n in outcomes_universe(2):\n",
    "    guesses[str(n)] = np.random.choice([-1,1],1)[0]\n",
    "seconds = {\"[0]\": b1, \"[1]\": b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions():\n",
    "    def __init__(self, number_layers=2):\n",
    "        self.number_layers = number_layers\n",
    "        actions = {}\n",
    "        for layer in range(number_layers+1):\n",
    "            actions[str(layer)] = {}\n",
    "\n",
    "        for k in outcomes_universe(number_layers):\n",
    "            for layer in range(number_layers+1):\n",
    "                actions[str(layer)][str(k[:layer])] = 0\n",
    "                \n",
    "        self.actions = actions\n",
    "        \n",
    "    def random_tree(self):\n",
    "        actions = self.actions.copy()\n",
    "        for k in outcomes_universe(self.number_layers):\n",
    "            for layer in range(self.number_layers+1):\n",
    "                actions[str(layer)][str(k[:layer])] = np.random.random()\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'[]': 0.09536316655133259},\n",
       " '1': {'[0]': 0.9805776651934801, '[1]': 0.3924997874180116},\n",
       " '2': {'[0 0]': 0.9592507899371683,\n",
       "  '[0 1]': 0.00824808420342682,\n",
       "  '[1 0]': 0.7874987939807336,\n",
       "  '[1 1]': 0.33579160486351634}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'[]': 0},\n",
       " '1': {'[0]': 0, '[1]': 0},\n",
       " '2': {'[0 0]': 0, '[0 1]': 0, '[1 0]': 0, '[1 1]': 0}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2L(tree.actions, at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'[]': [0.032962484545468684,\n",
       "   0.6863144184684542,\n",
       "   0.7392691047949408,\n",
       "   0.6578099746897761]},\n",
       " '1': {'[0]': [0.5110449637454709, 0.002096637870309781],\n",
       "  '[1]': [0.3504688649073524, 0.08617097607361901]},\n",
       " '2': {'[0 0]': [0.24777983301229067],\n",
       "  '[0 1]': [0.8778730352077802],\n",
       "  '[1 0]': [0.2266544423264727],\n",
       "  '[1 1]': [0.8117419775022194]}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Critic()\n",
    "inps = np.random.randn(1,8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer critic is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8, 1), dtype=float32, numpy=\n",
       "array([[[0.6358925 ],\n",
       "        [0.63168585],\n",
       "        [0.6304481 ],\n",
       "        [0.64474213],\n",
       "        [0.6384484 ],\n",
       "        [0.62755436],\n",
       "        [0.6376362 ],\n",
       "        [0.63068944]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic(inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### ACTOR CLASSS ####\n",
    "class Actor(tf.keras.Model):\n",
    "    #input_dim: 1 if layer=0, 3 if layer= 2, for the Kennedy receiver ##\n",
    "    def __init__(self, input_dim=1, valreg=0.01, seed_val=0.1, pad_value = -7.,\n",
    "                 dolinar_layers=2, nature=\"primary\"):\n",
    "        super(Actor,self).__init__()\n",
    "        self.dolinar_layers = dolinar_layers\n",
    "        self.pad_value = pad_value\n",
    "        self.nature = nature\n",
    "        self.mask = tf.keras.layers.Masking(mask_value=pad_value,\n",
    "                                  input_shape=(1, 1))\n",
    "        if nature == \"primary\":\n",
    "            self.lstm = tf.keras.layers.LSTM(500, return_sequences=True, stateful=True)\n",
    "        elif nature == \"target\":\n",
    "            self.lstm = tf.keras.layers.LSTM(500, return_sequences=True, stateful=False)\n",
    "        else:\n",
    "            print(\"Hey! the character is either primary or target\")\n",
    "        self.l1 = Dense(250,kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg))\n",
    "\n",
    "        self.l2 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l3 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l4 = Dense(1, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "\n",
    "\n",
    "    def update_target_parameters(self,primary_net, tau=0.01):\n",
    "        #### only\n",
    "        # for i,j in zip(self.get_weights(), primary_net.get_weights()):\n",
    "        #     tf.assign(i, tau*j + (i-tau)*i )\n",
    "        prim_weights = primary_net.get_weights()\n",
    "        targ_weights = self.get_weights()\n",
    "        weights = []\n",
    "        for i in tf.range(len(prim_weights)):\n",
    "            weights.append(tau * prim_weights[i] + (1 - tau) * targ_weights[i])\n",
    "        self.set_weights(weights)\n",
    "        return\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feat = self.mask(inputs)\n",
    "        feat= self.lstm(feat)\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l1(feat))\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        feat = tf.nn.relu(self.l3(feat))\n",
    "        feat = tf.nn.sigmoid(self.l4(feat))\n",
    "\n",
    "        return feat\n",
    "\n",
    "    def targeted_sequence(self, experiences_vector):\n",
    "\n",
    "        #This function takes a vector of experiences:\n",
    "        #vector = (\\beta1, o1, \\beta2, o2, \\beta3, o3,...,o_L, guess)\n",
    "        #and retrieves\n",
    "        #(\\beta1, o1, \\beta2_target, o2, \\beta3_target, o3, \\beta4_target,... ,o_L, guess)\n",
    "        #actor_target.lstm.reset_states() NO! \n",
    "        if self.nature != \"target\":\n",
    "            raise AttributeError(\"check the lstm memory of actor target, stateful == True ?\")\n",
    "            return\n",
    "        export = experiences_vector.copy()\n",
    "        for index in range(1,2*self.dolinar_layers-1,2): # I consider from first outcome to last one (but guess)\n",
    "            export[:,index+1] = np.squeeze(self(np.reshape(np.array(export[:,index]),\n",
    "                                                                 (experiences_vector.shape[0],1,1))))\n",
    "        return export\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array([actor.pad_value])\n",
    "inp = np.reshape(inp, (1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[0.47883806]]], shape=(1, 1, 1), dtype=float32)\n",
      "tf.Tensor([[[0.47883806]]], shape=(1, 1, 1), dtype=float32)\n",
      "tf.Tensor([[[0.47883806]]], shape=(1, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for k in range(3):\n",
    "    print(actor(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[0.4708976]]], shape=(1, 1, 1), dtype=float32)\n",
      "tf.Tensor([[[0.469261]]], shape=(1, 1, 1), dtype=float32)\n",
      "tf.Tensor([[[0.46807468]]], shape=(1, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for k in range(3):\n",
    "    print(actor(inp + np.reshape(np.array(-1.),(1,1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'actor_3/lstm_4/Variable:0' shape=(1, 500) dtype=float32, numpy=\n",
       " array([[-1.14967205e-01,  2.07302809e-01, -1.50902703e-01,\n",
       "         -1.80431888e-01, -1.65166214e-01,  2.91105248e-02,\n",
       "         -1.59782320e-01, -2.47169985e-04,  2.26949424e-01,\n",
       "          1.36741713e-01, -1.16445042e-01,  2.86793765e-02,\n",
       "          5.73190413e-02,  8.74600261e-02,  8.25699866e-02,\n",
       "         -5.34274727e-02,  1.87864751e-01, -5.02619073e-02,\n",
       "          2.43400067e-01, -2.86729224e-02, -1.66121349e-01,\n",
       "          6.70780241e-02,  3.10184322e-02, -8.43979195e-02,\n",
       "         -1.92845851e-01, -1.89841986e-01, -2.72434056e-01,\n",
       "         -6.83001801e-02, -9.96095240e-02, -1.26970783e-01,\n",
       "          7.12318197e-02, -1.94747880e-01, -2.19760448e-01,\n",
       "          1.58407703e-01, -2.05468416e-01,  1.73184738e-01,\n",
       "          3.02557703e-02, -3.75555293e-03,  1.28477858e-03,\n",
       "          1.15694858e-01, -5.42933568e-02, -1.26794139e-02,\n",
       "          1.94115683e-01,  1.01883449e-01,  8.05953890e-02,\n",
       "          1.72015861e-01,  1.46250382e-01,  6.52227029e-02,\n",
       "          6.79526627e-02,  1.34785652e-01, -4.47452329e-02,\n",
       "         -7.28290379e-02,  1.06806241e-01, -4.88406904e-02,\n",
       "         -1.35473892e-01, -1.20136075e-01,  1.87164932e-01,\n",
       "         -1.12241149e-01,  2.05610529e-01, -2.16511726e-01,\n",
       "          4.06997185e-03,  1.03595361e-01, -6.83551952e-02,\n",
       "         -2.21792549e-01,  1.93938836e-01,  1.64953575e-01,\n",
       "          9.25951749e-02,  1.10636361e-01, -1.52984098e-01,\n",
       "          1.01232938e-01, -1.91726893e-01,  3.30810994e-02,\n",
       "          2.13158146e-01,  6.07566312e-02,  1.89197183e-01,\n",
       "         -9.16157514e-02, -8.29897374e-02, -1.02025583e-01,\n",
       "         -2.09449634e-01, -1.43186718e-01,  3.51567715e-02,\n",
       "          1.66801624e-02, -1.14487998e-01, -1.03748642e-01,\n",
       "         -7.95632508e-03,  5.35999052e-02,  2.81595718e-02,\n",
       "          1.62607476e-01,  4.28798608e-02,  1.81139171e-01,\n",
       "         -1.91738442e-01, -2.52158521e-03,  3.30896862e-02,\n",
       "          1.23950340e-01, -4.39043157e-02, -1.11135133e-01,\n",
       "          1.51304044e-02,  1.46375924e-01,  3.55320387e-02,\n",
       "         -7.92748481e-02, -1.34020448e-01, -4.14323620e-02,\n",
       "          1.25091448e-01, -2.22101510e-01, -9.17600766e-02,\n",
       "          1.83400720e-01,  1.92403642e-03, -1.34181485e-01,\n",
       "          1.46267399e-01,  1.72755212e-01,  1.84454963e-01,\n",
       "         -1.68995976e-01,  1.88220918e-01,  3.90108954e-03,\n",
       "          3.24529335e-02,  3.53499278e-02,  2.07607940e-01,\n",
       "          1.79354995e-01, -5.17496467e-02, -8.39360878e-02,\n",
       "         -1.83736637e-01, -1.79778397e-01,  1.20656058e-01,\n",
       "         -1.59327045e-01, -1.01651579e-01, -1.88393220e-01,\n",
       "          5.83993979e-02, -1.65251151e-01,  9.36546847e-02,\n",
       "         -2.02906758e-01, -1.83988154e-01,  4.04010639e-02,\n",
       "         -1.77773118e-01,  1.12037612e-02,  1.97119802e-01,\n",
       "          5.57366125e-02, -1.24904104e-01, -2.73992568e-01,\n",
       "         -1.55553505e-01, -2.27350205e-01, -4.66475300e-02,\n",
       "          2.70524565e-02, -1.80925742e-01,  1.87724113e-01,\n",
       "         -4.93076816e-02,  2.53695786e-01,  1.04432158e-01,\n",
       "          2.70527741e-03,  9.55519825e-03, -1.13544755e-01,\n",
       "          9.58098248e-02, -7.59467185e-02,  4.52211797e-02,\n",
       "         -1.31636500e-01, -1.40653342e-01,  1.26455858e-01,\n",
       "         -1.83459282e-01,  1.20240733e-01,  1.77981138e-01,\n",
       "         -1.38470501e-01,  4.12984528e-02, -4.56815511e-02,\n",
       "         -1.34004191e-01,  1.70560986e-01, -1.46056145e-01,\n",
       "         -8.97419602e-02, -3.46857011e-02,  1.48646593e-01,\n",
       "         -7.13469237e-02,  1.69266984e-01, -1.06724957e-02,\n",
       "          2.62415619e-03, -5.29875495e-02,  1.45510405e-01,\n",
       "         -1.11371562e-01, -2.22720206e-01, -1.01388529e-01,\n",
       "         -7.90873468e-02,  5.83259426e-02,  4.71862443e-02,\n",
       "         -1.55033961e-01,  1.32470215e-02,  1.73868030e-01,\n",
       "          1.97550699e-01,  7.23773390e-02,  1.44047104e-02,\n",
       "          1.39493821e-02, -1.90244913e-01,  3.71487811e-02,\n",
       "         -4.19344753e-02,  8.89064819e-02, -1.90910846e-01,\n",
       "          1.77281678e-01, -1.69157714e-01,  1.53769285e-03,\n",
       "          1.42861575e-01,  2.53423080e-02,  1.29439250e-01,\n",
       "          1.37371023e-03,  7.39489570e-02,  3.32043692e-02,\n",
       "         -1.01623327e-01, -1.05817676e-01,  1.30198613e-01,\n",
       "         -6.80757239e-02, -3.65167595e-02,  4.93764840e-02,\n",
       "          4.42512669e-02,  1.50817916e-01, -1.85967460e-01,\n",
       "          1.93871081e-01,  2.07312122e-01,  9.69411060e-02,\n",
       "          2.07254738e-01, -2.51518078e-02,  1.28165245e-01,\n",
       "         -2.69679576e-02,  1.64560035e-01,  2.56847707e-03,\n",
       "         -4.26069759e-02,  3.68034616e-02,  1.65284917e-01,\n",
       "          1.91915661e-01, -6.68328851e-02,  6.07854351e-02,\n",
       "          1.39846593e-01, -9.86163020e-02,  2.01049343e-01,\n",
       "         -1.75172314e-01,  1.12320594e-01,  8.32842290e-02,\n",
       "         -1.65611073e-01,  1.52335063e-01,  1.64708212e-01,\n",
       "         -1.47606423e-02,  5.54470383e-02, -1.17898338e-01,\n",
       "          2.75683925e-02,  3.87836210e-02,  1.45432651e-01,\n",
       "          6.51848540e-02,  1.25547647e-01,  6.00563437e-02,\n",
       "         -9.13498849e-02, -6.74368441e-02,  1.09221995e-01,\n",
       "         -9.06283706e-02,  1.22568890e-01, -2.53434777e-01,\n",
       "         -1.79376334e-01, -2.70597249e-01, -9.27678123e-02,\n",
       "          2.45095581e-01, -5.01670428e-02,  2.68010676e-01,\n",
       "          1.69379905e-01,  4.24704105e-02,  2.20099390e-01,\n",
       "          7.89864510e-02, -1.48173034e-01,  1.37562767e-01,\n",
       "         -9.25394446e-02,  1.03742242e-01, -1.67782336e-01,\n",
       "          1.39558986e-01,  2.34452948e-01,  3.73626337e-03,\n",
       "          1.93440631e-01,  1.53526708e-01, -9.03924853e-02,\n",
       "         -6.25513867e-02, -2.67168522e-01, -8.68746117e-02,\n",
       "         -5.07235825e-02, -2.36011278e-02, -1.17443837e-01,\n",
       "          2.23609254e-01,  2.92219147e-02,  6.11547381e-02,\n",
       "          4.26546186e-02, -1.12732388e-01,  1.67477354e-01,\n",
       "         -1.44788206e-01,  2.59801745e-01, -1.69994757e-01,\n",
       "          1.18421689e-01,  1.17590077e-01,  1.39989778e-01,\n",
       "         -1.46062478e-01,  2.29759943e-02, -1.12585708e-01,\n",
       "          9.79642272e-02,  6.42198995e-02, -1.12759791e-01,\n",
       "          8.76794979e-02,  8.41108933e-02, -9.72522199e-02,\n",
       "          1.12093151e-01, -5.20799309e-02,  2.32915510e-03,\n",
       "         -2.51764171e-02,  1.47675261e-01, -5.02121542e-03,\n",
       "         -1.66392997e-01, -1.80730477e-01, -5.02368957e-02,\n",
       "          1.59606308e-01, -1.08448826e-01, -1.96140528e-01,\n",
       "          1.76388517e-01,  7.60719329e-02, -1.32379150e-02,\n",
       "         -9.05629247e-02, -4.14412245e-02,  2.40669414e-01,\n",
       "         -1.50075570e-01,  2.37479001e-01, -2.32674956e-01,\n",
       "         -9.87022668e-02,  1.56531200e-01,  4.85503934e-02,\n",
       "         -1.38801172e-01,  2.10788175e-02,  5.61718047e-02,\n",
       "         -1.95870787e-01,  2.28754673e-02,  7.84741938e-02,\n",
       "          3.33266258e-02, -3.09338514e-02,  5.29169291e-02,\n",
       "          8.10541362e-02,  1.90699652e-01,  6.18850589e-02,\n",
       "          9.12799910e-02,  2.37229988e-01, -1.10010765e-01,\n",
       "         -1.23977266e-01,  1.86323598e-01, -1.38968855e-01,\n",
       "         -6.63324911e-03,  1.00382887e-01, -6.06193580e-02,\n",
       "         -9.05852914e-02,  1.14034735e-01, -1.19357426e-02,\n",
       "         -1.59375072e-01,  6.52910024e-02, -8.00466985e-02,\n",
       "          1.66103706e-01, -1.14181921e-01,  1.63018480e-01,\n",
       "          5.11109903e-02,  1.96043029e-02,  1.55722746e-03,\n",
       "         -9.51481685e-02,  2.27310225e-01,  2.10276604e-01,\n",
       "         -6.35918041e-05,  9.80993882e-02, -9.33233425e-02,\n",
       "          1.91957057e-01, -7.80116469e-02, -3.64570469e-02,\n",
       "          7.95740858e-02, -2.66804416e-02, -6.56916797e-02,\n",
       "          1.61209386e-02,  1.85580775e-02,  1.22754291e-01,\n",
       "         -8.79161507e-02,  1.66987002e-01,  1.21493511e-01,\n",
       "          2.39005223e-01, -1.16826124e-01,  2.35364154e-01,\n",
       "         -6.12417758e-02, -6.87364936e-02, -7.64540806e-02,\n",
       "         -2.47774735e-01,  1.39761001e-01, -2.03291606e-02,\n",
       "         -1.75977319e-01, -2.25165635e-02, -1.45774007e-01,\n",
       "          1.60392240e-01, -2.04186618e-01,  9.51594394e-03,\n",
       "         -1.23982601e-01, -1.99311569e-01, -1.30687669e-01,\n",
       "          1.75178841e-01, -9.47066210e-03,  1.11782938e-01,\n",
       "         -1.48372367e-01,  1.58689320e-01, -1.71384886e-01,\n",
       "          1.47320017e-01,  7.76585937e-02, -1.44608885e-01,\n",
       "         -5.59764616e-02, -6.74208924e-02, -1.97109550e-01,\n",
       "          1.73629716e-01, -1.41099289e-01, -1.73844501e-01,\n",
       "          3.24725583e-02,  2.39185378e-01, -6.27364367e-02,\n",
       "         -1.13509722e-01, -1.67612553e-01,  1.69820845e-01,\n",
       "         -1.15737990e-02,  4.69087102e-02,  6.66357204e-02,\n",
       "          6.33245409e-02, -2.20432550e-01,  2.30600294e-02,\n",
       "         -2.44154289e-01, -1.75316602e-01, -2.13655010e-01,\n",
       "          7.07267001e-02, -1.26603022e-01,  1.30687758e-01,\n",
       "          2.78399121e-02, -5.75806722e-02, -1.29595131e-01,\n",
       "          5.12732379e-03,  1.60497315e-02,  1.74346730e-01,\n",
       "          3.96036878e-02, -1.11961318e-02, -1.45897493e-01,\n",
       "         -1.47696808e-01,  2.53798753e-01, -9.62726474e-02,\n",
       "          1.63443908e-01, -4.70071323e-02,  3.93491089e-02,\n",
       "          1.06294893e-01,  1.14123911e-01,  2.08928995e-02,\n",
       "         -1.16574809e-01, -7.99779743e-02, -2.16693487e-02,\n",
       "         -2.01072112e-01,  1.51657730e-01,  3.61898984e-03,\n",
       "         -1.69595405e-01, -1.68053031e-01, -7.22335801e-02,\n",
       "         -3.04564387e-02, -2.15873063e-01, -1.33549914e-01,\n",
       "          1.59438699e-01,  7.85842463e-02, -7.43838623e-02,\n",
       "          1.41243858e-03,  3.87612097e-02,  6.21998962e-03,\n",
       "         -1.27243353e-02, -8.39605257e-02, -9.25890729e-02,\n",
       "          1.71089113e-01,  1.55796990e-01, -1.31121740e-01,\n",
       "         -1.55548900e-01, -6.10385388e-02,  1.01306200e-01,\n",
       "          5.20760454e-02, -7.03796297e-02,  1.01357907e-01,\n",
       "          1.52830660e-01,  5.25977649e-02, -6.65444285e-02,\n",
       "          5.57469986e-02, -2.56858438e-01,  1.36484325e-01,\n",
       "          2.85917968e-02,  4.80410270e-03, -1.36131287e-01,\n",
       "         -2.33069565e-02,  1.34183943e-01,  5.86022660e-02,\n",
       "         -1.05322301e-01, -5.03741652e-02,  1.80589274e-01,\n",
       "          6.31294698e-02, -2.66547054e-01, -1.30012587e-01,\n",
       "          2.12673545e-01,  2.19514128e-02, -1.16725909e-02,\n",
       "          2.81679463e-02,  1.47892967e-01,  4.90923934e-02,\n",
       "         -7.85303339e-02,  8.95011500e-02,  2.88779587e-02,\n",
       "         -7.70547464e-02, -2.29178622e-01]], dtype=float32)>,\n",
       " <tf.Variable 'actor_3/lstm_4/Variable:0' shape=(1, 500) dtype=float32, numpy=\n",
       " array([[-2.83613533e-01,  4.15290475e-01, -2.94170201e-01,\n",
       "         -3.47568810e-01, -4.25172627e-01,  7.11932853e-02,\n",
       "         -2.76247561e-01, -4.43957746e-04,  4.96681541e-01,\n",
       "          2.58083612e-01, -2.00077608e-01,  4.89859059e-02,\n",
       "          1.04338944e-01,  2.06036448e-01,  1.59379154e-01,\n",
       "         -1.28288910e-01,  4.97541070e-01, -1.00680649e-01,\n",
       "          4.42400783e-01, -7.26501495e-02, -3.30316514e-01,\n",
       "          1.29391357e-01,  6.14832677e-02, -1.90416545e-01,\n",
       "         -3.57123971e-01, -3.26817513e-01, -4.77393150e-01,\n",
       "         -1.30757228e-01, -1.97119892e-01, -2.99195409e-01,\n",
       "          1.35358647e-01, -4.83284950e-01, -4.25386131e-01,\n",
       "          2.85805136e-01, -4.33629751e-01,  3.10657442e-01,\n",
       "          6.38703853e-02, -7.06257764e-03,  2.54742615e-03,\n",
       "          2.77774572e-01, -1.02297306e-01, -3.25831473e-02,\n",
       "          3.38840604e-01,  1.76618278e-01,  1.79669529e-01,\n",
       "          4.50921178e-01,  3.28605533e-01,  1.45358771e-01,\n",
       "          1.59769177e-01,  2.43750483e-01, -1.07491851e-01,\n",
       "         -1.24466404e-01,  1.98351473e-01, -9.62863117e-02,\n",
       "         -2.54234195e-01, -2.69736379e-01,  3.78419757e-01,\n",
       "         -1.91452742e-01,  4.90921855e-01, -3.87107104e-01,\n",
       "          9.93718021e-03,  2.08922490e-01, -1.26949906e-01,\n",
       "         -5.40083885e-01,  3.57542455e-01,  3.18208992e-01,\n",
       "          2.19392076e-01,  2.36607030e-01, -3.53899568e-01,\n",
       "          2.46832788e-01, -4.41091746e-01,  5.59101179e-02,\n",
       "          3.81207824e-01,  1.08231768e-01,  4.46990550e-01,\n",
       "         -1.52380943e-01, -1.67443275e-01, -2.57255614e-01,\n",
       "         -3.98370057e-01, -3.43029559e-01,  9.07843336e-02,\n",
       "          3.50223035e-02, -2.64218271e-01, -2.56880015e-01,\n",
       "         -2.04150006e-02,  1.25506729e-01,  7.22327381e-02,\n",
       "          3.22482169e-01,  9.42742676e-02,  3.85171711e-01,\n",
       "         -5.49474597e-01, -5.16263768e-03,  7.07411766e-02,\n",
       "          2.16994539e-01, -8.05047527e-02, -1.85639188e-01,\n",
       "          2.86870096e-02,  2.76215136e-01,  7.34810308e-02,\n",
       "         -1.76566452e-01, -2.35721737e-01, -8.51352289e-02,\n",
       "          2.93880254e-01, -4.89019126e-01, -1.86200738e-01,\n",
       "          4.64450955e-01,  3.52328038e-03, -2.85705388e-01,\n",
       "          3.34009528e-01,  3.48609269e-01,  3.96124840e-01,\n",
       "         -4.57086265e-01,  3.20618361e-01,  6.79569505e-03,\n",
       "          7.91064203e-02,  6.17229342e-02,  3.67466927e-01,\n",
       "          4.00589883e-01, -1.27529502e-01, -1.40425637e-01,\n",
       "         -4.27779496e-01, -3.07658494e-01,  2.64805496e-01,\n",
       "         -3.91648620e-01, -1.77616149e-01, -3.94572973e-01,\n",
       "          1.33403599e-01, -3.13091546e-01,  1.70608371e-01,\n",
       "         -4.28108305e-01, -4.23073232e-01,  7.98836127e-02,\n",
       "         -4.79283810e-01,  2.01890394e-02,  4.18881655e-01,\n",
       "          1.25323117e-01, -2.78988779e-01, -5.31634688e-01,\n",
       "         -2.66943574e-01, -4.38345402e-01, -1.13739297e-01,\n",
       "          6.49289563e-02, -3.67088675e-01,  4.34915036e-01,\n",
       "         -8.28706026e-02,  5.14203608e-01,  2.06451565e-01,\n",
       "          6.15070667e-03,  2.19563749e-02, -2.57068455e-01,\n",
       "          1.75983697e-01, -1.26612276e-01,  1.06077194e-01,\n",
       "         -3.18506956e-01, -3.55439633e-01,  2.19282851e-01,\n",
       "         -3.94269258e-01,  2.64843732e-01,  3.09413254e-01,\n",
       "         -2.32568771e-01,  8.24141353e-02, -8.45000669e-02,\n",
       "         -2.40565896e-01,  3.04984033e-01, -2.70045757e-01,\n",
       "         -1.83244109e-01, -7.26031512e-02,  3.36034805e-01,\n",
       "         -1.46284401e-01,  3.37022841e-01, -2.04960518e-02,\n",
       "          4.46511433e-03, -1.02701247e-01,  3.15744132e-01,\n",
       "         -2.36504436e-01, -4.13754046e-01, -1.76631808e-01,\n",
       "         -1.43874824e-01,  1.50622681e-01,  8.82160813e-02,\n",
       "         -4.05727059e-01,  3.25973965e-02,  3.16784501e-01,\n",
       "          4.17336762e-01,  1.43427297e-01,  3.34473290e-02,\n",
       "          2.92937402e-02, -3.59834254e-01,  8.36060718e-02,\n",
       "         -7.54050016e-02,  2.13902131e-01, -3.83241892e-01,\n",
       "          3.46266836e-01, -3.30039591e-01,  2.63613719e-03,\n",
       "          2.85539627e-01,  6.20121136e-02,  2.98316538e-01,\n",
       "          3.00693256e-03,  1.29065797e-01,  6.82264045e-02,\n",
       "         -1.69213727e-01, -2.12139770e-01,  2.33597577e-01,\n",
       "         -1.68209508e-01, -7.17689618e-02,  8.55957717e-02,\n",
       "          1.04323663e-01,  2.72419274e-01, -3.47918868e-01,\n",
       "          3.66965711e-01,  3.98625940e-01,  1.78127676e-01,\n",
       "          3.81934941e-01, -4.98738401e-02,  2.83292294e-01,\n",
       "         -4.52756733e-02,  3.37864339e-01,  4.20223828e-03,\n",
       "         -9.00534466e-02,  6.64173067e-02,  3.46603215e-01,\n",
       "          3.62719297e-01, -1.38156116e-01,  1.43432677e-01,\n",
       "          2.46699214e-01, -2.44556651e-01,  4.00051713e-01,\n",
       "         -4.36384499e-01,  2.17992082e-01,  1.69259593e-01,\n",
       "         -4.08623457e-01,  2.57190615e-01,  2.87288785e-01,\n",
       "         -2.52069794e-02,  1.11274377e-01, -2.46140137e-01,\n",
       "          4.98426631e-02,  6.84499294e-02,  2.60167003e-01,\n",
       "          1.07254058e-01,  2.31853738e-01,  1.33118391e-01,\n",
       "         -2.26072162e-01, -1.19824179e-01,  2.85803467e-01,\n",
       "         -2.14798599e-01,  2.37208217e-01, -4.71380532e-01,\n",
       "         -4.33201969e-01, -5.03367305e-01, -2.05669537e-01,\n",
       "          4.12536502e-01, -1.21284276e-01,  5.38734078e-01,\n",
       "          3.97837549e-01,  8.44252482e-02,  4.14668679e-01,\n",
       "          1.34354785e-01, -3.87191892e-01,  3.28209341e-01,\n",
       "         -1.82648882e-01,  1.98607534e-01, -3.95195842e-01,\n",
       "          3.33759129e-01,  4.83710945e-01,  9.09899734e-03,\n",
       "          3.23320985e-01,  3.15697789e-01, -2.22256154e-01,\n",
       "         -1.37610942e-01, -4.96971667e-01, -1.74399137e-01,\n",
       "         -1.12868540e-01, -4.43808585e-02, -2.34290421e-01,\n",
       "          4.34217393e-01,  5.14557138e-02,  1.31350398e-01,\n",
       "          8.30096751e-02, -2.82086372e-01,  2.91157901e-01,\n",
       "         -2.86917597e-01,  5.18254519e-01, -3.82387817e-01,\n",
       "          2.35781133e-01,  2.91656345e-01,  2.51583308e-01,\n",
       "         -3.71766388e-01,  5.28958514e-02, -1.98714659e-01,\n",
       "          1.80447489e-01,  1.25948593e-01, -2.42767245e-01,\n",
       "          2.05103248e-01,  1.68033138e-01, -1.77394181e-01,\n",
       "          1.97861761e-01, -1.23852611e-01,  4.04976215e-03,\n",
       "         -5.06214276e-02,  2.65789211e-01, -9.96063091e-03,\n",
       "         -2.92377949e-01, -3.29992086e-01, -9.66422111e-02,\n",
       "          2.86838770e-01, -2.26796031e-01, -3.41153502e-01,\n",
       "          3.75733018e-01,  1.44267559e-01, -2.95001455e-02,\n",
       "         -2.12267011e-01, -9.32615548e-02,  5.31047344e-01,\n",
       "         -3.15172195e-01,  5.07126749e-01, -4.00654793e-01,\n",
       "         -1.90095901e-01,  3.74611616e-01,  8.56179446e-02,\n",
       "         -3.58902216e-01,  5.24638519e-02,  1.08213194e-01,\n",
       "         -4.44616526e-01,  4.26548645e-02,  1.62608981e-01,\n",
       "          7.13816509e-02, -6.52097315e-02,  1.28733903e-01,\n",
       "          1.34524122e-01,  3.61431181e-01,  1.27962023e-01,\n",
       "          1.73353195e-01,  4.20824647e-01, -2.06276864e-01,\n",
       "         -2.15835989e-01,  3.55571330e-01, -2.87591398e-01,\n",
       "         -1.23918299e-02,  1.82335794e-01, -1.59602106e-01,\n",
       "         -1.68130696e-01,  2.23302424e-01, -2.04093494e-02,\n",
       "         -3.74371439e-01,  1.44938827e-01, -1.91340387e-01,\n",
       "          3.16154301e-01, -2.71013200e-01,  3.12749445e-01,\n",
       "          9.97999758e-02,  3.44772190e-02,  2.51295324e-03,\n",
       "         -1.74518913e-01,  4.68081117e-01,  3.89403909e-01,\n",
       "         -1.48208812e-04,  1.95776939e-01, -1.83792427e-01,\n",
       "          3.32214803e-01, -1.43145919e-01, -7.76465386e-02,\n",
       "          1.88957974e-01, -6.51066527e-02, -1.16522036e-01,\n",
       "          3.51004377e-02,  3.35185193e-02,  2.18831807e-01,\n",
       "         -1.99430987e-01,  4.29155707e-01,  2.00265333e-01,\n",
       "          4.95425045e-01, -2.11214781e-01,  4.19621348e-01,\n",
       "         -1.19514160e-01, -1.39005110e-01, -1.27117544e-01,\n",
       "         -4.70873535e-01,  2.34933704e-01, -4.93475422e-02,\n",
       "         -3.50272715e-01, -4.53780182e-02, -2.81925321e-01,\n",
       "          2.94085383e-01, -3.86567771e-01,  1.94304604e-02,\n",
       "         -2.87249237e-01, -4.36381608e-01, -2.89839268e-01,\n",
       "          3.38534176e-01, -1.84083264e-02,  2.12027520e-01,\n",
       "         -2.54686683e-01,  2.72449970e-01, -3.84710491e-01,\n",
       "          3.05013299e-01,  1.33584619e-01, -2.71027893e-01,\n",
       "         -1.44671053e-01, -1.52021974e-01, -5.20778656e-01,\n",
       "          4.31022286e-01, -3.75813872e-01, -4.51635718e-01,\n",
       "          7.79207274e-02,  4.20453966e-01, -1.11388847e-01,\n",
       "         -2.62791663e-01, -4.29332495e-01,  2.90155470e-01,\n",
       "         -2.25984175e-02,  8.17627311e-02,  1.50302023e-01,\n",
       "          1.50725245e-01, -4.68440533e-01,  5.56491241e-02,\n",
       "         -5.19806564e-01, -4.49389219e-01, -4.84025478e-01,\n",
       "          1.41582400e-01, -2.93688178e-01,  2.52326667e-01,\n",
       "          5.12564331e-02, -1.34075880e-01, -2.44964927e-01,\n",
       "          8.88797455e-03,  3.21989655e-02,  3.27264845e-01,\n",
       "          8.09621215e-02, -2.60702502e-02, -2.53798842e-01,\n",
       "         -2.77527094e-01,  4.65076476e-01, -2.21371710e-01,\n",
       "          3.01040828e-01, -8.60374868e-02,  7.24492669e-02,\n",
       "          2.10088044e-01,  2.55596399e-01,  5.00682183e-02,\n",
       "         -2.44774997e-01, -1.98485076e-01, -3.58118564e-02,\n",
       "         -3.98423165e-01,  2.61495560e-01,  8.72097164e-03,\n",
       "         -3.00618589e-01, -3.18414271e-01, -1.45336419e-01,\n",
       "         -7.05000758e-02, -4.14844900e-01, -2.63944477e-01,\n",
       "          2.75539100e-01,  1.82487518e-01, -1.33840546e-01,\n",
       "          3.45754740e-03,  7.97715187e-02,  1.09522082e-02,\n",
       "         -2.77901292e-02, -1.49406895e-01, -1.83741823e-01,\n",
       "          2.99825698e-01,  2.65252203e-01, -2.65155554e-01,\n",
       "         -2.96717823e-01, -1.15550645e-01,  2.17292845e-01,\n",
       "          1.05593778e-01, -1.19197868e-01,  2.63793379e-01,\n",
       "          3.59452754e-01,  1.18138447e-01, -1.39311761e-01,\n",
       "          9.93081480e-02, -4.51106012e-01,  2.45622769e-01,\n",
       "          4.83843796e-02,  1.24438973e-02, -2.92313278e-01,\n",
       "         -5.90824932e-02,  3.20797265e-01,  1.05304912e-01,\n",
       "         -2.52404153e-01, -1.09676391e-01,  3.53234142e-01,\n",
       "          1.66149914e-01, -4.77375329e-01, -3.13287973e-01,\n",
       "          4.39804733e-01,  3.64489593e-02, -1.94173772e-02,\n",
       "          6.01613335e-02,  3.63109440e-01,  1.17454730e-01,\n",
       "         -1.66741192e-01,  1.93494558e-01,  5.70817962e-02,\n",
       "         -1.89337045e-01, -5.22501886e-01]], dtype=float32)>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.lstm.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = {}\n",
    "for layer in range(3):\n",
    "    actions[str(layer)] = {}\n",
    "\n",
    "for k in outcomes_universe(2):\n",
    "    for layer in range(3):\n",
    "        actions[str(layer)][str(k[:layer])] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4354973512141521"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2L(tree.random_tree(),at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor(np.array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    #input_dim: 1 if layer=0, 3 if layer= 2, for the Kennedy receiver ##\n",
    "    def __init__(self, valreg=0.01, seed_val=0.3, pad_value=-7., dolinar_layers=2):\n",
    "        '''\n",
    "        dolinar_layers= number of photodetections\n",
    "        pad_value: value not considered by the lstm\n",
    "        valreg: regularisation value\n",
    "        seed_val: interval of random parameter inizialitaion.\n",
    "        '''\n",
    "        super(Critic,self).__init__()\n",
    "\n",
    "        self.pad_value = pad_value\n",
    "        self.dolinar_layers = dolinar_layers\n",
    "        self.mask = tf.keras.layers.Masking(mask_value=pad_value,\n",
    "                                  input_shape=(3, 2)) #(beta1, pad), (n1, beta2), (n2, guess). In general i will have (layer+1)\n",
    "        self.lstm = tf.keras.layers.LSTM(500, return_sequences=True)\n",
    "\n",
    "        self.l1 = Dense(250,kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg))\n",
    "\n",
    "        self.l2 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l3 = Dense(100, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l4 = Dense(1, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "\n",
    "\n",
    "    def update_target_parameters(self,primary_net, tau=0.01):\n",
    "        #### only\n",
    "        # for i,j in zip(self.get_weights(), primary_net.get_weights()):\n",
    "        #     tf.assign(i, tau*j + (i-tau)*i )\n",
    "        prim_weights = primary_net.get_weights()\n",
    "        targ_weights = self.get_weights()\n",
    "        weights = []\n",
    "        for i in tf.range(len(prim_weights)):\n",
    "            weights.append(tau * prim_weights[i] + (1 - tau) * targ_weights[i])\n",
    "        self.set_weights(weights)\n",
    "        return\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feat = self.mask(inputs)\n",
    "        feat= self.lstm(feat)\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l1(feat))\n",
    "        # feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        feat = tf.nn.relu(self.l3(feat))\n",
    "        feat = tf.nn.sigmoid(self.l4(feat))\n",
    "        return feat\n",
    "\n",
    "\n",
    "    def process_sequence(self,sample_buffer):\n",
    "        \"\"\"\" \n",
    "        sample_buffer: array of shape (N,2*self.layers +1), N>1\n",
    "        \n",
    "        gets data obtained from N experiments: data.shape = (N, 2L+1),\n",
    "        where +1 accounts for the guess and 2L for (beta, outcome).\n",
    "\n",
    "        [[a0, o1, a1, o2, a2, o3, a4]\n",
    "         [same but other experiment]\n",
    "        ]\n",
    "\n",
    "        and returns an array of shape (experiments, self.layers, 2 ), as accepted by an RNN\n",
    "        \"\"\"\n",
    "        batch_size = sample_buffer.shape[0]\n",
    "        data = sample_buffer[:,0:(self.dolinar_layers+1+1)]\n",
    "        padded_data = np.ones((batch_size,self.dolinar_layers+1, 2))*self.pad_value\n",
    "        padded_data[:,0][:,0] = data[:,0]\n",
    "        for k in range(1,LAYERS+1):\n",
    "            padded_data[:,k] = data[:,[k,k+1]]\n",
    "\n",
    "        rewards_obtained = np.zeros((batch_size, self.dolinar_layers+1))\n",
    "        rewards_obtained[:,-1] = sample_buffer[:,-1]\n",
    "        return padded_data, rewards_obtained\n",
    "\n",
    "\n",
    "    def pad_single_sequence(self, seq, LAYERS=1):\n",
    "        \"\"\"\"\n",
    "        input: [a0, o1, a1, o2, a2, o3, a4]\n",
    "\n",
    "        output: [[a0, pad], [o1, a1], [...]]\n",
    "\n",
    "        the cool thing is that then you can put this to predict the greedy guess/action.\n",
    "        \"\"\"\n",
    "        padded_data = np.ones((1,LAYERS+1, 2))*self.pad_value\n",
    "        padded_data[0][0][0] = seq[0]\n",
    "        #padded_data[0][0] = data[0]\n",
    "        for k in range(1,LAYERS+1):\n",
    "            padded_data[0][k] = seq[k:(k+2)]\n",
    "        return padded_data\n",
    "\n",
    "    def give_td_error_Kennedy_guess(self,batched_input,sequential_rews_with_zeros):\n",
    "        # this function takes as input the actions as given by the target actor (but the first one!)\n",
    "        #and outpus the correspoindg TD-errors for DDPG! To obtain them from sample of buffer\n",
    "        #you call the method targeted_sequence from the actor_target and then the process_sequence\n",
    "        #of this critic network.\n",
    "        if self.nature != \"target\":\n",
    "            raise AttributeError(\"I'm not the target!\")\n",
    "            return\n",
    "        b = batched_input.copy()\n",
    "        ll = sequential_rews_with_zeros.copy()\n",
    "        for k in range(0,self.dolinar_layers-1):\n",
    "            print(k)\n",
    "            ll[:,k] = np.squeeze(self(b))[:,k+1] + ll[:,k]\n",
    "\n",
    "        preds1 = self(b)\n",
    "        b[:,-1][:,-1] = -b[:,1][:,1]\n",
    "        preds2 = self(b)\n",
    "        both = tf.concat([preds1,preds2],2)\n",
    "        maxs = np.squeeze(tf.math.reduce_max(both,axis=2).numpy())\n",
    "        ll[:,-2] = maxs[:,1] # This is the last befre the guess.. so the label is max_g Q(h-L, g)\n",
    "        ll = np.expand_dims(ll,axis=1)\n",
    "        return ll\n",
    "\n",
    "\n",
    "    def give_favourite_guess(self,sequence_with_plus):\n",
    "        \"\"\"\"\n",
    "            important !! the 1!\n",
    "        sequence should be [[beta, pad], [outcome, 1]] \"\"\"\n",
    "        pred_1 = self(sequence_with_plus)\n",
    "        sequence_with_plus[:,1][:,1] = -sequence_with_plus[:,1][:,1]\n",
    "        pred_2 = self(sequence_with_plus)\n",
    "        both = tf.concat([pred_1,pred_2],2)\n",
    "        maxs = np.squeeze(tf.argmax(both,axis=2).numpy())[1]\n",
    "\n",
    "        guess = (-1)**maxs\n",
    "        return  guess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Critic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = np.random.randn(1,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer critic_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 1), dtype=float32, numpy=\n",
       "array([[[0.51881504],\n",
       "        [0.5235726 ],\n",
       "        [0.5387318 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic(inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 1., -7.],\n",
       "         [ 2.,  3.],\n",
       "         [ 3.,  4.]],\n",
       " \n",
       "        [[ 7., -7.],\n",
       "         [ 8.,  9.],\n",
       "         [ 9., 10.]]]),\n",
       " array([[ 0.,  0.,  6.],\n",
       "        [ 0.,  0., 12.]]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_buffer = np.array([[1,2,3,4,5,6],[7,8,9,10,11,12]])\n",
    "critic.process_sequence(sample_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_td_error_Kennedy_guess(critic,batched_input,sequential_rews_with_zeros):\n",
    "    b = batched_input.copy()\n",
    "    ll = sequential_rews_with_zeros.copy()\n",
    "    preds1 = critic(b)\n",
    "    b[:,1][:,1] = -b[:,1][:,1]\n",
    "    preds2 = critic(b)\n",
    "    both = tf.concat([preds1,preds2],2)\n",
    "    maxs = np.squeeze(tf.math.reduce_max(both,axis=2).numpy())\n",
    "    ll[:,0] = maxs[:,1] + ll[:,0]\n",
    "    ll = np.expand_dims(ll,axis=1)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbd, rrws = critic.process_sequence(sample_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 1), dtype=float32, numpy=\n",
       "array([[[0.62175477],\n",
       "        [0.59714985],\n",
       "        [0.6186216 ]],\n",
       "\n",
       "       [[0.53024596],\n",
       "        [0.75999266],\n",
       "        [0.8607184 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic(bbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_target = Actor(nature=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps_actor = np.random.randn(1,actor_target.dolinar_layers,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_target = actor_target(inps_actor) #(\\beta1, \\beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1), dtype=float32, numpy=array([[[0.4731382]]], dtype=float32)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_target(np.reshape(np.array(2.),(1,1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1.,2.,3.,4.,5.], [1.,2.,3.,4.,5.]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_sequence = actor_target.targeted_sequence(np.array([[1.,2.,3.,4.,5.], [1.,2.,3.,4.,5.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs, rrs = critic.process_sequence(targeted_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_td_error_Kennedy_guess(self,batched_input,sequential_rews_with_zeros):\n",
    "    # this function takes as input the actions as given by the target actor (but the first one!)\n",
    "    #and outpus the correspoindg TD-errors for DDPG! \n",
    "    if self.nature != \"target\":\n",
    "        raise AttributeError(\"I'm not the target!\")\n",
    "        return\n",
    "    b = batched_input.copy()\n",
    "    ll = sequential_rews_with_zeros.copy()\n",
    "    for k in range(0,self.dolinar_layers-1):\n",
    "        print(k)\n",
    "        ll[:,k] = np.squeeze(self(b))[:,k+1] + ll[:,k]\n",
    "    \n",
    "    preds1 = self(b)\n",
    "    b[:,-1][:,-1] = -b[:,1][:,1]\n",
    "    preds2 = self(b)\n",
    "    both = tf.concat([preds1,preds2],2)\n",
    "    maxs = np.squeeze(tf.math.reduce_max(both,axis=2).numpy())\n",
    "    ll[:,-2] = maxs[:,1] # This is the last befre the guess.. so the label is max_g Q(h-L, g)\n",
    "    ll = np.expand_dims(ll,axis=1)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.60952461, 0.60952461, 5.        ]],\n",
       "\n",
       "       [[0.60952461, 0.60952461, 5.        ]]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_td_error_Kennedy_guess(critic, bbs, rrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 1), dtype=float32, numpy=\n",
       "array([[[0.62175477],\n",
       "        [0.6095246 ],\n",
       "        [0.5792907 ]],\n",
       "\n",
       "       [[0.62175477],\n",
       "        [0.6095246 ],\n",
       "        [0.5792907 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic(bbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4.])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs[:,-1][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
