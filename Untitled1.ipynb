{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beggining to train! \n",
      " \n",
      "\n",
      "tau: 0.005, repetitions per optimization step (would be like epochs): 1\n",
      " \n",
      "**** optimizers ***\n",
      "optimizer_critic_guess: {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False} \n",
      "Optimizer_actor_l0: {'name': 'Adam', 'learning_rate': 0.01, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "\n",
      "*** BUFFER ***\n",
      "Buffer_size: 500\n",
      " Batch_size for sampling: 64\n",
      "\n",
      "\n",
      "\n",
      " *** NOISE PARAMETERS *** \n",
      "epsilon-guess: 0.1\n",
      "epsilon_displacement_noise: 0.5\n",
      "starting time: 20200512-135857\n",
      "saving results in results/run_11\n",
      "WARNING:tensorflow:Layer actor_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer critic_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer critic_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Episode 1, \\Rt: 0.0, \\Pt: 0.5, Train loss: 0.1072700023651123, Test loss: 0.0\n",
      "\n",
      "\n",
      "Episode 2, \\Rt: 0.5, \\Pt: 0.5, Train loss: 0.1834300011396408, Test loss: 0.0\n",
      "\n",
      "\n",
      "Episode 3, \\Rt: 0.3333333333333333, \\Pt: 0.5, Train loss: 0.1841599941253662, Test loss: 0.0\n",
      "\n",
      "\n",
      "Episode 4, \\Rt: 0.5, \\Pt: 0.5, Train loss: 0.18791000545024872, Test loss: 0.0\n",
      "\n",
      "\n",
      "Episode 5, \\Rt: 0.6, \\Pt: 0.5, Train loss: 0.18339000642299652, Test loss: 0.0\n",
      "\n",
      "\n",
      "Episode 6, \\Rt: 0.6666666666666666, \\Pt: 0.5, Train loss: 0.17447000741958618, Test loss: 0.0\n",
      "\n",
      "\n",
      "Episode 7, \\Rt: 0.7142857142857143, \\Pt: 0.5, Train loss: 0.16593000292778015, Test loss: 0.0\n",
      "\n",
      "\n",
      "Episode 8, \\Rt: 0.75, \\Pt: 0.5, Train loss: 0.15907999873161316, Test loss: 0.0\n",
      "\n",
      "\n",
      "Episode 9, \\Rt: 0.7777777777777778, \\Pt: 0.5, Train loss: 0.1532900035381317, Test loss: 0.0\n",
      "\n",
      "\n",
      "Episode 10, \\Rt: 0.8, \\Pt: 0.5, Train loss: 0.1480800062417984, Test loss: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib\n",
    "\n",
    "from plots import *\n",
    "from misc import Prob, ps_maxlik, qval, record\n",
    "from nets import *\n",
    "from buffer import ReplayBuffer\n",
    "\n",
    "def optimization_step(experiences,critic, critic_target, actor, optimizer_critic, optimizer_actor, train_loss):\n",
    "    sequences, zeroed_rews = critic.process_sequence(experiences)\n",
    "    labels_critic = critic_target.give_td_error_Kennedy_guess( sequences, zeroed_rews)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(critic.trainable_variables)\n",
    "        preds_critic = critic(sequences)\n",
    "        loss_critic = tf.keras.losses.MSE(labels_critic, preds_critic)\n",
    "        loss_critic = tf.reduce_mean(loss_critic)\n",
    "        grads = tape.gradient(loss_critic, critic.trainable_variables)\n",
    "        optimizer_critic.apply_gradients(zip(grads, critic.trainable_variables))\n",
    "        train_loss(loss_critic)\n",
    "\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        ones = tf.ones(shape=(experiences.shape[0],1))*critic.pad_value\n",
    "        actions = actor(np.expand_dims(np.zeros(len(experiences)),axis=1))   #This can be improved i think!! (the conversion... )\n",
    "\n",
    "        tape.watch(actions)\n",
    "        qvals = critic(tf.expand_dims(tf.concat([actions, ones], axis=1),axis=1))\n",
    "        dq_da = tape.gradient(qvals, actions)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        actionss = actor(np.expand_dims(np.zeros(len(experiences)),axis=1))\n",
    "        da_dtheta = tape.gradient(actionss, actor.trainable_variables, output_gradients=-dq_da)\n",
    "\n",
    "    optimizer_actor.apply_gradients(zip(da_dtheta, actor.trainable_variables))\n",
    "    return\n",
    "        ###### END OF OPTIMIZATION STEP ######\n",
    "    ###### END OF OPTIMIZATION STEP ######\n",
    "\n",
    "\n",
    "special_name=\"\"\n",
    "total_episodes = 10**1\n",
    "buffer_size=500\n",
    "batch_size=64\n",
    "ep_guess=0.1\n",
    "noise_displacement=0.5\n",
    "lr_actor=0.01\n",
    "lr_critic=0.001\n",
    "tau=0.005\n",
    "repetitions=1\n",
    "plots=True\n",
    "\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.makedirs(\"results\")\n",
    "\n",
    "amplitude = 0.4\n",
    "buffer = ReplayBuffer(buffer_size=buffer_size)\n",
    "\n",
    "critic = Critic(valreg=0.0)\n",
    "critic_target = Critic()\n",
    "actor = Actor(input_dim=1)\n",
    "# actor_target = Actor(input_dim=1) THIS IS NOT REQUIRED FOR THE FIRST LAYER ONLY\n",
    "\n",
    "actor(np.array([[0.]]).astype(np.float32)) #initialize the network 0, arbitrary inputs.\n",
    "#\n",
    "optimizer_critic = tf.keras.optimizers.Adam(lr=lr_critic)\n",
    "optimizer_actor = tf.keras.optimizers.Adam(lr=lr_actor)\n",
    "\n",
    "\n",
    "rt = []\n",
    "pt = []\n",
    "\n",
    "#define this global so i use them in a function defined above... optimizatin step and testing()\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "\n",
    "\n",
    "if special_name == \"\":\n",
    "    # current_run_and_time = \"results/{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
    "    numb = record()\n",
    "    current_run_and_time =\"results/run_\" + str(numb)\n",
    "else:\n",
    "    current_run_and_time = \"results/\"+special_name\n",
    "\n",
    "directory = current_run_and_time\n",
    "train_log =  current_run_and_time + '/train_l0'\n",
    "test_log =   current_run_and_time + '/test_l0'\n",
    "\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log)\n",
    "test_summary_writer_0 = tf.summary.create_file_writer(test_log)\n",
    "\n",
    "info_optimizers = \"optimizer_critic_guess: {} \\nOptimizer_actor_l0: {}\\n\".format(optimizer_critic.get_config(), optimizer_actor.get_config())\n",
    "infor_buffer = \"Buffer_size: {}\\n Batch_size for sampling: {}\\n\".format(buffer.buffer_size, batch_size)\n",
    "info_epsilons= \"epsilon-guess: {}\\nepsilon_displacement_noise: {}\".format(ep_guess,noise_displacement)\n",
    "\n",
    "data = \"tau: {}, repetitions per optimization step (would be like epochs): {}\".format(tau,repetitions) + \"\\n \\n**** optimizers ***\\n\"+info_optimizers+\"\\n\\n\\n*** BUFFER ***\\n\"+infor_buffer+\"\\n\\n\\n *** NOISE PARAMETERS *** \\n\"+info_epsilons\n",
    "with open(directory+\"/info.txt\", 'w') as f:\n",
    "    f.write(data)\n",
    "    f.close()\n",
    "\n",
    "print(\"Beggining to train! \\n \\n\")\n",
    "print(data)\n",
    "print(\"starting time: {}\".format(datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
    "print(\"saving results in \" + str(directory))\n",
    "avg_train = []\n",
    "avg_test = []\n",
    "\n",
    "history_betas = [] #to put in histogram\n",
    "history_betas_would_have_done=[] #to put in histogram\n",
    "histo_preds = {\"layer0\":{}, \"layer1\":{}} #here i save the predictions to plot in a \"straightforward way\"\n",
    "\n",
    "#######\n",
    "for episode in range(total_episodes):\n",
    "\n",
    "    alice_phase = np.random.choice([-1.,1.],1)[0]\n",
    "    beta_would_do = actor(np.array([[0.]])).numpy()[0][0]\n",
    "    beta =  beta_would_do + np.random.uniform(-noise_displacement, noise_displacement)\n",
    "    proboutcome = Prob(alice_phase*amplitude,beta,0)\n",
    "    outcome = np.random.choice([0.,1.],1,p=[proboutcome, 1-proboutcome])[0]\n",
    "\n",
    "    history_betas.append(beta)\n",
    "    history_betas_would_have_done.append(beta_would_do)\n",
    "\n",
    "#\n",
    "    if np.random.random()< ep_guess:\n",
    "        guess = np.random.choice([-1.,1.],1)[0]\n",
    "    else:\n",
    "        sequence = np.array([[ [beta, critic.pad_value], [outcome, -1.]]  ]).astype(np.float32)\n",
    "        guess = critic.give_favourite_guess(sequence)\n",
    "    if guess == alice_phase:\n",
    "        reward = 1.\n",
    "    else:\n",
    "        reward = 0.\n",
    "    # reward = qval(beta, outcome, guess)\n",
    "    buffer.add(beta, outcome, guess, reward)\n",
    "\n",
    "\n",
    "    ###### OPTIMIZATION STEP ######\n",
    "    ###### OPTIMIZATION STEP ######\n",
    "\n",
    "    experiences = buffer.sample(batch_size)\n",
    "    if buffer.buffer_size>batch_size:\n",
    "        optimization_step(experiences,critic, critic_target, actor, optimizer_critic, optimizer_actor, train_loss)\n",
    "        critic_target.update_target_parameters(critic, tau=tau)\n",
    "\n",
    "\n",
    "#####\n",
    "    avg_train.append(train_loss.result().numpy())\n",
    "    avg_test.append(0.)\n",
    "    # avg_test.append(test_loss.result().numpy())\n",
    "#\n",
    "    rt.append(reward)\n",
    "#\n",
    "\n",
    "    ########################################################################\n",
    "    ### calculate success probability if the agent went greedy ###########\n",
    "    p=0\n",
    "    for outcome in [0.,1.]:\n",
    "        guess = critic.give_favourite_guess(critic.pad_single_sequence([beta_would_do, outcome, 1.]))\n",
    "        # print(guess, outcome)\n",
    "        p+=Prob(guess*amplitude, beta_would_do,outcome) #Notice it's very very important that the sequence has the 1. and not -1!!! TO DO in a better way!\n",
    "    p/=2\n",
    "    pt.append(p)\n",
    "    ################\n",
    "\n",
    "    if episode%(total_episodes/10) == 0: #this is for showing 10 results in total.\n",
    "\n",
    "        template = 'Episode {}, \\Rt: {}, \\Pt: {}, Train loss: {}, Test loss: {}\\n\\n'\n",
    "        print(template.format(episode+1,\n",
    "                            np.sum(rt)/(episode+1),\n",
    "                              pt[-1],\n",
    "                             np.round(train_loss.result().numpy(),5),\n",
    "                             np.round(test_loss.result().numpy(),5))\n",
    "              )\n",
    "\n",
    "\n",
    "        for layer in [\"layer0\",\"layer1\"]: #net_0 will be critic_q0, net_1 will be critic_qguess\n",
    "\n",
    "            histo_preds[layer][str(episode)] ={}\n",
    "            histo_preds[layer][str(episode)][\"episode\"] = episode\n",
    "            histo_preds[layer][str(episode)][\"values\"] = {}\n",
    "\n",
    "        simp = np.random.randn(len(buffer.betas),4)\n",
    "        simp[:,0] =buffer.betas\n",
    "        qvals0 = np.squeeze(critic(critic.process_sequence(simp)[0]).numpy()[:,0])\n",
    "        histo_preds[\"layer0\"][str(episode)][\"values\"] = qvals0\n",
    "\n",
    "        index=0\n",
    "        for n1 in [0.,1.]:\n",
    "            for guess in [-1.,1.]:\n",
    "                simp[:,1] = n1\n",
    "                simp[:,2] = guess\n",
    "                qvals1 = np.squeeze(critic(critic.process_sequence(simp)[0]).numpy()[:,1])\n",
    "                histo_preds[\"layer1\"][str(episode)][\"values\"][str(index)] = qvals1\n",
    "                index+=1\n",
    "\n",
    "\n",
    "\n",
    "rt = [np.sum(rt[:k]) for k in range(len(rt))]\n",
    "rt = rt/np.arange(1,len(rt)+1)\n",
    "\n",
    "losses = [avg_train, avg_test]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58293796, 0.5522172 , 0.52330124, 0.50476223, 0.53214157,\n",
       "       0.52820003, 0.5146649 , 0.5019516 , 0.5043244 , 0.5049933 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_maxlik(history_betas_would_have_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0\n",
      "0.8571059736657678\n",
      "1 1.0\n",
      "0.1428940263342322\n"
     ]
    }
   ],
   "source": [
    "p=0\n",
    "for outcome in [0.,1.]:\n",
    "    guess = critic.give_favourite_guess(critic.pad_single_sequence([beta_would_do, outcome, 1.]))\n",
    "    print(guess, outcome)\n",
    "    p+=Prob(guess*amplitude, beta_would_do,outcome) \n",
    "    print(Prob(guess*amplitude, beta_would_do,outcome) )#Notice it's very very important that the sequence has the 1. and not -1!!! TO DO in a better way!\n",
    "p/=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.74346685]\n",
      "  [0.6486715 ]]], shape=(1, 2, 1), dtype=float32)\n",
      "[[[ 0.00732493 -7.        ]\n",
      "  [ 1.         -1.        ]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.74346685]\n",
      "  [0.6486715 ]]], shape=(1, 2, 1), dtype=float32)\n",
      "***\n",
      "tf.Tensor(\n",
      "[[[0.74346685]\n",
      "  [0.6340661 ]]], shape=(1, 2, 1), dtype=float32)\n",
      "¨¨\n",
      "tf.Tensor(\n",
      "[[[0.74346685 0.74346685]\n",
      "  [0.6486715  0.6340661 ]]], shape=(1, 2, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_favourite_guess(critic, critic.pad_single_sequence([beta_would_do, 1, -1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = np.load(\"experiences.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, exp = critic.process_sequence(experiences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_td_error_Kennedy_guess(self,batched_input,sequential_rews_with_zeros):\n",
    "    b = batched_input.copy()\n",
    "    ll = sequential_rews_with_zeros.copy()\n",
    "    preds1 = self(b)\n",
    "    b[:,1][:,1] = -b[:,1][:,1]\n",
    "    preds2 = self(b)\n",
    "    both = tf.concat([preds1,preds2],2)\n",
    "    maxs = np.squeeze(tf.math.reduce_max(both,axis=2).numpy())\n",
    "    ll[:,0] = maxs[:,1] + ll[:,0]\n",
    "    ll = np.expand_dims(ll,axis=1)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.74256027]\n",
      "  [0.6538779 ]]\n",
      "\n",
      " [[0.7441431 ]\n",
      "  [0.6550068 ]]\n",
      "\n",
      " [[0.7456921 ]\n",
      "  [0.6556933 ]]], shape=(3, 2, 1), dtype=float32) tf.Tensor(\n",
      "[[[0.74256027]\n",
      "  [0.62913597]]\n",
      "\n",
      " [[0.7441431 ]\n",
      "  [0.6291358 ]]\n",
      "\n",
      " [[0.7456921 ]\n",
      "  [0.6295572 ]]], shape=(3, 2, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.74256027 0.74256027]\n",
      "  [0.6538779  0.62913597]]\n",
      "\n",
      " [[0.7441431  0.7441431 ]\n",
      "  [0.6550068  0.6291358 ]]\n",
      "\n",
      " [[0.7456921  0.7456921 ]\n",
      "  [0.6556933  0.6295572 ]]], shape=(3, 2, 2), dtype=float32)\n",
      "[[0.74256027 0.6538779 ]\n",
      " [0.7441431  0.6550068 ]\n",
      " [0.7456921  0.6556933 ]]\n",
      "[0.6538779 0.6550068 0.6556933]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.6538779, 0.       ]],\n",
       "\n",
       "       [[0.6550068, 1.       ]],\n",
       "\n",
       "       [[0.6556933, 1.       ]]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_td_error_Kennedy_guess(critic, b, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
